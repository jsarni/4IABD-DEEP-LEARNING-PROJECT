{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des resultats des test de différentes structures de Rsnet sur le dataset Cifar-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous allons analyser les resultats obtenus sur la première vague de tests de différentes structures et hyperparametres de Rsnet. Pour les tests menés, pour chaque nombre de couches cachées de 3 à 9, le modèle est testé sans regularisation et sans dropout, avec deux filtre à chaque fois (32 ou 64), puis avec regularisation, avec dropout et enfin dropout et regularisation sur le modèle, en plus de quelques modèles testés avec du Maxpoolin. En vue de la grande quantité d'architectures testées, nous allons mettre suelement un ou deux exemples do nos méthodes d'analyse des résultats à titre explicatif, et présenter les résultats définitifs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation des outils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rsnet Sans régularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests réalisés :\n",
    "    Pour ce début de tests, nous avons essayé d'entrainer différents Rsnet en jouant sur le nombre de couches ainsi que leur filtres. Pour cela, on a lancé des tests comme suit (plusieurs fois sur la même structure) :\n",
    "    - Des modèles de 3 à 4 couches, avec filtres entre 32 et 64.\n",
    "    - Des modèles de 5 à 6 couches, avec filtres entre 32 et 64.\n",
    "    - Des modèles de 7 à 8 couches, avec filtres entre 32 et 64.\n",
    " \n",
    "    \n",
    "    Nous avons ensuite enregistré les résultats obtenus dans des fichiers CSV, en plus des logs générés par tensorflow, pour étudier les résultats obtenus.\n",
    "    \n",
    "    Nous allons donc charger ces statistiques et voir ce que ce genre de modèles peut donner sur le Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image illustrant un resnet de 5 couches avec un skip connexion de 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rsnet Model](Rsnet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des résultats obtenus pour chaque configuration de modèle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframes_list = []\n",
    "results_dataframes_desc = []\n",
    "root_csv_folder = \"..\\\\historique_tests\\\\\"\n",
    "\n",
    "\n",
    "# Rsnet without regularisation results  3 to 4 layers.\n",
    "for i in [32,64]:\n",
    "    df = pd.read_csv(\"{}tested_rsnet_3_to_4_{}_history.csv\".format(root_csv_folder,i), sep=\";\")\n",
    "    results_dataframes_list.append(df)\n",
    "    results_dataframes_desc.append(\"rsnet_3_to_4_{}\".format(i))\n",
    "\n",
    "# Rsnet without regularisation results  5 to 6 layers.\n",
    "for i in [32,64]:\n",
    "    df = pd.read_csv(\"{}tested_rsnet_5_to_6_{}_history.csv\".format(root_csv_folder,i), sep=\";\")\n",
    "    results_dataframes_list.append(df)\n",
    "    results_dataframes_desc.append(\"rsnet_5_to_6_{}\".format(i))\n",
    "\n",
    "# Rsnet without regularisation results  7 to 8 layers.\n",
    "for i in [32,64]:\n",
    "    df = pd.read_csv(\"{}tested_rsnet_7_to_8_{}_history.csv\".format(root_csv_folder,i), sep=\";\")\n",
    "    results_dataframes_list.append(df)\n",
    "    results_dataframes_desc.append(\"rsnet_7_to_8_{}\".format(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des informations interessantes :\n",
    "- Pire résultat sur le train\n",
    "- Pire résultat sur la val\n",
    "- Meilleur résultat sur le train\n",
    "- Meilleur résultat sur la val \n",
    "- Moyenne des résultats sur le train \n",
    "- Moyenne des résultats sur la val \n",
    "- Mediane des résultat sur le train \n",
    "- Mediane des résultat sur la val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(history_df, history_df_desc):\n",
    "    # Calculating statistics on all models\n",
    "    if(not history_df.empty):\n",
    "        sorted_train_accuracy = np.sort(history_df.train_accuracy)\n",
    "        sorted_val_accuracy = np.sort(history_df.val_accuracy)\n",
    "\n",
    "        max_val_accuracy = sorted_val_accuracy[-1]\n",
    "#         second_max_val_accuracy = sorted_val_accuracy[-2]\n",
    "        min_val_accuracy = history_df.val_accuracy.min()\n",
    "        mean_val_accuracy = history_df.val_accuracy.mean()\n",
    "        median_val_accuracy = history_df.val_accuracy.median()\n",
    "\n",
    "        max_train_accuracy = sorted_train_accuracy[-1]\n",
    "#         second_max_train_accuracy = sorted_train_accuracy[-2]\n",
    "        min_train_accuracy = history_df.train_accuracy.min()\n",
    "        mean_train_accuracy = history_df.train_accuracy.mean()\n",
    "        median_train_accuracy = history_df.train_accuracy.median()\n",
    "\n",
    "        # Printing models statistics\n",
    "        print()\n",
    "        print(\"########### Models {} ###########\".format(history_df_desc))\n",
    "        print(history_df.shape)\n",
    "        print(\"Pire résultat sur le train : \", min_train_accuracy)\n",
    "        print(\"Pire Résultat sur la val : \", min_val_accuracy)\n",
    "\n",
    "        print(\"Meilleur résultat sur le train : \", max_train_accuracy)\n",
    "        print(\"Meilleur résultat sur la val : \", max_val_accuracy)\n",
    "\n",
    "        print(\"Moyenne des résultats sur le train : \", mean_train_accuracy)\n",
    "        print(\"Moyenne des résultats sur la val : \", mean_val_accuracy)\n",
    "\n",
    "        print(\"Mediane des résultat sur le train : \", median_train_accuracy)\n",
    "        print(\"Mediane des résultat sur la val : \", median_val_accuracy)\n",
    "\n",
    "def filter_on_mean_val_accuracy(results_dataframes_list):\n",
    "    filtered_results_dataframes = []\n",
    "    \n",
    "    for i in range(len(results_dataframes_list)):\n",
    "\n",
    "        # Calculating statistics on all models\n",
    "        history_df = results_dataframes_list[i]\n",
    "        history_df_desc = results_dataframes_desc[i]\n",
    "\n",
    "        median_val_accuracy = history_df.val_accuracy.median()\n",
    "        mean_val_accuracy = history_df.val_accuracy.mean()\n",
    "        # Filtering models to get the best ones (those whose val accuracy is higher then the median)\n",
    "        \n",
    "        # Si la médiane est inférieure à la moyenne on enlève cette archi, car la majorité des modèles on une mauvaise\n",
    "        # accuracy, et la moyenne est gonflée par seulement une petite partie des modèles. Ce qui indique que que l'archi\n",
    "        # choisie n'est pas interessante\n",
    "#         if(mean_val_accuracy < median_val_accuracy):\n",
    "        filtered_history = history_df[history_df.val_accuracy >= mean_val_accuracy]\n",
    "#         else:\n",
    "#         filtered_history = pd.DataFrame(columns=history_df.columns)\n",
    "        filtered_results_dataframes.append(filtered_history)\n",
    "        \n",
    "    \n",
    "    return filtered_results_dataframes\n",
    "\n",
    "\n",
    "def filter_on_mean_train_accuracy(results_dataframes_list):\n",
    "    filtered_results_dataframes = []\n",
    "    \n",
    "    for i in range(len(results_dataframes_list)):\n",
    "\n",
    "        # Calculating statistics on all models\n",
    "        history_df = results_dataframes_list[i]\n",
    "        history_df_desc = results_dataframes_desc[i]\n",
    "\n",
    "#         median_train_accuracy = history_df.train_accuracy.median()\n",
    "        mean_train_accuracy = history_df.train_accuracy.mean()\n",
    "        # Filtering models to get the best ones (those whose val accuracy is higher then the median)\n",
    "        \n",
    "        # Si la médiane est inférieure à la moyenne on enlève cette archi, car la majorité des modèles on une mauvaise\n",
    "        # accuracy, et la moyenne est gonflée par seulement une petite partie des modèles. Ce qui indique que que l'archi\n",
    "        # choisie n'est pas interessante\n",
    "        filtered_history = history_df[history_df.train_accuracy > mean_train_accuracy]\n",
    "        filtered_results_dataframes.append(filtered_history)\n",
    "        \n",
    "    \n",
    "    return filtered_results_dataframes\n",
    "\n",
    "def concat_list_of_dataframes(list_df):\n",
    "    return pd.concat(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models rsnet_3_to_4_32 ###########\n",
      "(6, 26)\n",
      "Pire résultat sur le train :  0.79602\n",
      "Pire Résultat sur la val :  0.4105\n",
      "Meilleur résultat sur le train :  0.9412\n",
      "Meilleur résultat sur la val :  0.5181\n",
      "Moyenne des résultats sur le train :  0.8457\n",
      "Moyenne des résultats sur la val :  0.4708666666666667\n",
      "Mediane des résultat sur le train :  0.8299300000000001\n",
      "Mediane des résultat sur la val :  0.4709\n",
      "\n",
      "########### Models rsnet_3_to_4_64 ###########\n",
      "(6, 26)\n",
      "Pire résultat sur le train :  0.67818\n",
      "Pire Résultat sur la val :  0.3798\n",
      "Meilleur résultat sur le train :  0.8758799999999999\n",
      "Meilleur résultat sur la val :  0.5403\n",
      "Moyenne des résultats sur le train :  0.8202166666666667\n",
      "Moyenne des résultats sur la val :  0.4602833333333334\n",
      "Mediane des résultat sur le train :  0.84825\n",
      "Mediane des résultat sur la val :  0.46085\n",
      "\n",
      "########### Models rsnet_5_to_6_32 ###########\n",
      "(8, 26)\n",
      "Pire résultat sur le train :  0.2551\n",
      "Pire Résultat sur la val :  0.2447\n",
      "Meilleur résultat sur le train :  0.9703799999999999\n",
      "Meilleur résultat sur la val :  0.5873\n",
      "Moyenne des résultats sur le train :  0.5569875\n",
      "Moyenne des résultats sur la val :  0.409775\n",
      "Mediane des résultat sur le train :  0.38144999999999996\n",
      "Mediane des résultat sur la val :  0.38005\n",
      "\n",
      "########### Models rsnet_5_to_6_64 ###########\n",
      "(6, 26)\n",
      "Pire résultat sur le train :  0.30338000000000004\n",
      "Pire Résultat sur la val :  0.309\n",
      "Meilleur résultat sur le train :  0.97262\n",
      "Meilleur résultat sur la val :  0.6023\n",
      "Moyenne des résultats sur le train :  0.6425900000000001\n",
      "Moyenne des résultats sur la val :  0.4319333333333333\n",
      "Mediane des résultat sur le train :  0.6545099999999999\n",
      "Mediane des résultat sur la val :  0.39715\n",
      "\n",
      "########### Models rsnet_7_to_8_32 ###########\n",
      "(5, 26)\n",
      "Pire résultat sur le train :  0.34056\n",
      "Pire Résultat sur la val :  0.3399\n",
      "Meilleur résultat sur le train :  0.9648200000000001\n",
      "Meilleur résultat sur la val :  0.5398\n",
      "Moyenne des résultats sur le train :  0.71844\n",
      "Moyenne des résultats sur la val :  0.47454\n",
      "Mediane des résultat sur le train :  0.8793\n",
      "Mediane des résultat sur la val :  0.5101\n",
      "\n",
      "########### Models rsnet_7_to_8_64 ###########\n",
      "(9, 26)\n",
      "Pire résultat sur le train :  0.20856\n",
      "Pire Résultat sur la val :  0.2112\n",
      "Meilleur résultat sur le train :  0.9838600000000001\n",
      "Meilleur résultat sur la val :  0.5969\n",
      "Moyenne des résultats sur le train :  0.6560444444444444\n",
      "Moyenne des résultats sur la val :  0.47419999999999995\n",
      "Mediane des résultat sur le train :  0.7682\n",
      "Mediane des résultat sur la val :  0.5281\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results_dataframes_list)):\n",
    "    history = results_dataframes_list[i]\n",
    "    history_desc = results_dataframes_desc[i]\n",
    "    print_statistics(history, history_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On ne garde que les modèles dont les résultats sur la validations sont supérieurs à la moyenne des résultats de tous les modèles (d'une même architecture) testés "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_results_dataframes = filter_on_mean_val_accuracy(results_dataframes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models rsnet_3_to_4_32 ###########\n",
      "(3, 26)\n",
      "Pire résultat sur le train :  0.80794\n",
      "Pire Résultat sur la val :  0.48\n",
      "Meilleur résultat sur le train :  0.8313200000000001\n",
      "Meilleur résultat sur la val :  0.5181\n",
      "Moyenne des résultats sur le train :  0.8226\n",
      "Moyenne des résultats sur la val :  0.5000666666666667\n",
      "Mediane des résultat sur le train :  0.8285399999999999\n",
      "Mediane des résultat sur la val :  0.5021\n",
      "\n",
      "########### Models rsnet_3_to_4_64 ###########\n",
      "(3, 26)\n",
      "Pire résultat sur le train :  0.79588\n",
      "Pire Résultat sur la val :  0.4929\n",
      "Meilleur résultat sur le train :  0.8758799999999999\n",
      "Meilleur résultat sur la val :  0.5403\n",
      "Moyenne des résultats sur le train :  0.8442866666666666\n",
      "Moyenne des résultats sur la val :  0.5111\n",
      "Mediane des résultat sur le train :  0.8611\n",
      "Mediane des résultat sur la val :  0.5001\n",
      "\n",
      "########### Models rsnet_5_to_6_32 ###########\n",
      "(4, 26)\n",
      "Pire résultat sur le train :  0.41758\n",
      "Pire Résultat sur la val :  0.4159\n",
      "Meilleur résultat sur le train :  0.9703799999999999\n",
      "Meilleur résultat sur la val :  0.5873\n",
      "Moyenne des résultats sur le train :  0.823145\n",
      "Moyenne des résultats sur la val :  0.531775\n",
      "Mediane des résultat sur le train :  0.95231\n",
      "Mediane des résultat sur la val :  0.56195\n",
      "\n",
      "########### Models rsnet_5_to_6_64 ###########\n",
      "(3, 26)\n",
      "Pire résultat sur le train :  0.95868\n",
      "Pire Résultat sur la val :  0.4488\n",
      "Meilleur résultat sur le train :  0.97262\n",
      "Meilleur résultat sur la val :  0.6023\n",
      "Moyenne des résultats sur le train :  0.9654533333333334\n",
      "Moyenne des résultats sur la val :  0.5402999999999999\n",
      "Mediane des résultat sur le train :  0.96506\n",
      "Mediane des résultat sur la val :  0.5698\n",
      "\n",
      "########### Models rsnet_7_to_8_32 ###########\n",
      "(3, 26)\n",
      "Pire résultat sur le train :  0.8793\n",
      "Pire Résultat sur la val :  0.5101\n",
      "Meilleur résultat sur le train :  0.9648200000000001\n",
      "Meilleur résultat sur la val :  0.5398\n",
      "Moyenne des résultats sur le train :  0.9328333333333333\n",
      "Moyenne des résultats sur la val :  0.5295333333333333\n",
      "Mediane des résultat sur le train :  0.9543799999999999\n",
      "Mediane des résultat sur la val :  0.5387\n",
      "\n",
      "########### Models rsnet_7_to_8_64 ###########\n",
      "(5, 26)\n",
      "Pire résultat sur le train :  0.7682\n",
      "Pire Résultat sur la val :  0.5281\n",
      "Meilleur résultat sur le train :  0.9838600000000001\n",
      "Meilleur résultat sur la val :  0.5969\n",
      "Moyenne des résultats sur le train :  0.8961159999999999\n",
      "Moyenne des résultats sur la val :  0.5779400000000001\n",
      "Mediane des résultat sur le train :  0.97346\n",
      "Mediane des résultat sur la val :  0.5875\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(filtered_results_dataframes)):\n",
    "    filtered_history = filtered_results_dataframes[i]\n",
    "    filtered_history_desc = results_dataframes_desc[i]\n",
    "    print_statistics(filtered_history, filtered_history_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On fusionne tous les dataframes en une seule (étant donné qu'il y en a une par structure de modèle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = concat_list_of_dataframes(filtered_results_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models Rsnet_without_regularisation ###########\n",
      "(21, 26)\n",
      "Pire résultat sur le train :  0.41758\n",
      "Pire Résultat sur la val :  0.4159\n",
      "Meilleur résultat sur le train :  0.9838600000000001\n",
      "Meilleur résultat sur la val :  0.6023\n",
      "Moyenne des résultats sur le train :  0.8794609523809525\n",
      "Moyenne des résultats sur la val :  0.5361809523809524\n",
      "Mediane des résultat sur le train :  0.9395\n",
      "Mediane des résultat sur la val :  0.5398\n"
     ]
    }
   ],
   "source": [
    "print_statistics(merged_df, \"Rsnet_without_regularisation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Première analyse des résultats obtenus :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nous remarquons donc sur les 19 meilleurs modèles, nous tournons autours des 60% de résultat sur la validation, et 97% sur le train. De plus, nous avons atteint une limite de taille à lancer, étant donné que nos fits crashent pour manque de mémoire GPU quand on essaye de s'attaquer à des modèles avec trop couches cachées et un batch size importatnt. \n",
    "\n",
    "#### Ces résultats nous montrent que les meilleurs modèles overfittent. Nous allons donc essayer d'appliquer des techniques de régularisation dessus, en prenant les meilleurs sur les modèles selectionnés. Mais avant cela, nous allons essayer de réduire le nombre de modèles à tester on ne prenant que les plus intéressants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image representant un overfiting sur un Rsnet :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rsnet_overfiting](Overfit_Rsnet.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection des meilleurs modèles sur la val sur les modèles selectionnés:\n",
    "    Pour cela, nous n'allons prendre que les modèles dont les résultats sur l'entraînement sont supérieurs à la médiane des résultats de tous les modèles compris (toutes arachitectures confondues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models Best Rsnet models ###########\n",
      "(12, 26)\n",
      "Pire résultat sur le train :  0.7682\n",
      "Pire Résultat sur la val :  0.5387\n",
      "Meilleur résultat sur le train :  0.97862\n",
      "Meilleur résultat sur la val :  0.6023\n",
      "Moyenne des résultats sur le train :  0.9164833333333334\n",
      "Moyenne des résultats sur la val :  0.571975\n",
      "Mediane des résultat sur le train :  0.9565299999999999\n",
      "Mediane des résultat sur la val :  0.5767\n"
     ]
    }
   ],
   "source": [
    "best_val_models = filter_on_mean_val_accuracy([merged_df])[0]\n",
    "best_val_models = best_val_models.sort_values('val_accuracy', ascending=False)\n",
    "print_statistics(best_val_models, \"Best Rsnet models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les modèle dont la val est > à la moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_hidden_layers</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>layers_activation</th>\n",
       "      <th>output_activation</th>\n",
       "      <th>use_skip</th>\n",
       "      <th>nb_skip</th>\n",
       "      <th>use_dropout</th>\n",
       "      <th>...</th>\n",
       "      <th>regulization_indexes</th>\n",
       "      <th>loss</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>metrics</th>\n",
       "      <th>padding</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>dossier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>64</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>4288707</td>\n",
       "      <td>0.97262</td>\n",
       "      <td>0.6023</td>\n",
       "      <td>20200128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>4 6</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>7460384</td>\n",
       "      <td>0.77644</td>\n",
       "      <td>0.5969</td>\n",
       "      <td>20200205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>64</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>2747992</td>\n",
       "      <td>0.97862</td>\n",
       "      <td>0.5944</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>64</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>9276555</td>\n",
       "      <td>0.97346</td>\n",
       "      <td>0.5875</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>64</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>5239202</td>\n",
       "      <td>0.97038</td>\n",
       "      <td>0.5873</td>\n",
       "      <td>20200128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>1345159</td>\n",
       "      <td>0.76820</td>\n",
       "      <td>0.5828</td>\n",
       "      <td>20200205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>64</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>5627949</td>\n",
       "      <td>0.96512</td>\n",
       "      <td>0.5706</td>\n",
       "      <td>20200128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>64</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>360263</td>\n",
       "      <td>0.95868</td>\n",
       "      <td>0.5698</td>\n",
       "      <td>20200128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>64</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>5333719</td>\n",
       "      <td>0.93950</td>\n",
       "      <td>0.5533</td>\n",
       "      <td>20200128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>256</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>30</td>\n",
       "      <td>9861705</td>\n",
       "      <td>0.86110</td>\n",
       "      <td>0.5403</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>64</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>5077276</td>\n",
       "      <td>0.95438</td>\n",
       "      <td>0.5398</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>64</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>7340360</td>\n",
       "      <td>0.87930</td>\n",
       "      <td>0.5387</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_hidden_layers  filters kernel_size  batch_size input_shape  \\\n",
       "3                 6       64         3 3          64     32 32 3   \n",
       "8                 8       64         3 3         128     32 32 3   \n",
       "4                 8       64         3 3          64     32 32 3   \n",
       "3                 8       64         3 3          64     32 32 3   \n",
       "4                 6       32         3 3          64     32 32 3   \n",
       "7                 8       64         3 3         128     32 32 3   \n",
       "2                 6       32         3 3          64     32 32 3   \n",
       "2                 6       64         3 3          64     32 32 3   \n",
       "3                 6       32         3 3          64     32 32 3   \n",
       "3                 4       64         3 3         256     32 32 3   \n",
       "2                 8       32         3 3          64     32 32 3   \n",
       "4                 8       32         3 3          64     32 32 3   \n",
       "\n",
       "  layers_activation output_activation  use_skip  nb_skip  use_dropout  ...  \\\n",
       "3              relu           softmax      True        2        False  ...   \n",
       "8              relu           softmax      True        2         True  ...   \n",
       "4              relu           softmax      True        2        False  ...   \n",
       "3              selu           softmax      True        2        False  ...   \n",
       "4           softmax           softmax      True        2        False  ...   \n",
       "7              relu           softmax      True        2         True  ...   \n",
       "2              relu           softmax      True        2        False  ...   \n",
       "2           softmax           softmax      True        2        False  ...   \n",
       "3           softmax           softmax      True        2        False  ...   \n",
       "3              relu           softmax      True        2        False  ...   \n",
       "2              selu           softmax      True        2        False  ...   \n",
       "4              relu           softmax      True        2        False  ...   \n",
       "\n",
       "  regulization_indexes                      loss  optimizer  \\\n",
       "3                  NaN  categorical_crossentropy       Adam   \n",
       "8                  4 6  categorical_crossentropy       Adam   \n",
       "4                  NaN  categorical_crossentropy       Adam   \n",
       "3                  NaN  categorical_crossentropy       Adam   \n",
       "4                  NaN  categorical_crossentropy       Adam   \n",
       "7                    4  categorical_crossentropy       Adam   \n",
       "2                  NaN  categorical_crossentropy       Adam   \n",
       "2                  NaN  categorical_crossentropy       Adam   \n",
       "3                  NaN  categorical_crossentropy       Adam   \n",
       "3                  NaN  categorical_crossentropy       Adam   \n",
       "2                  NaN  categorical_crossentropy       Adam   \n",
       "4                  NaN  categorical_crossentropy       Adam   \n",
       "\n",
       "                metrics  padding  epochs model_id train_accuracy val_accuracy  \\\n",
       "3  categorical_accuracy     same      50  4288707        0.97262       0.6023   \n",
       "8  categorical_accuracy     same      50  7460384        0.77644       0.5969   \n",
       "4  categorical_accuracy     same      50  2747992        0.97862       0.5944   \n",
       "3  categorical_accuracy     same      50  9276555        0.97346       0.5875   \n",
       "4  categorical_accuracy     same      50  5239202        0.97038       0.5873   \n",
       "7  categorical_accuracy     same      50  1345159        0.76820       0.5828   \n",
       "2  categorical_accuracy     same      50  5627949        0.96512       0.5706   \n",
       "2  categorical_accuracy     same      50   360263        0.95868       0.5698   \n",
       "3  categorical_accuracy     same      50  5333719        0.93950       0.5533   \n",
       "3  categorical_accuracy     same      30  9861705        0.86110       0.5403   \n",
       "2  categorical_accuracy     same      50  5077276        0.95438       0.5398   \n",
       "4  categorical_accuracy     same      50  7340360        0.87930       0.5387   \n",
       "\n",
       "    dossier  \n",
       "3  20200128  \n",
       "8  20200205  \n",
       "4  20200127  \n",
       "3  20200127  \n",
       "4  20200128  \n",
       "7  20200205  \n",
       "2  20200128  \n",
       "2  20200128  \n",
       "3  20200128  \n",
       "3  20200126  \n",
       "2  20200127  \n",
       "4  20200127  \n",
       "\n",
       "[12 rows x 26 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On voit donc que nous avons 10 modèles qui pourrait être intéressants sur la validation, mais nous allons maintenant en selectionné, entre ceux là, les meilleurs sur le train. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection des meilleurs modèles sur la val sur les 10 restants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_models.to_csv(\"{}best_Rsnet_without_regularisation.csv\".format(root_csv_folder), sep=';',header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions premiers tests:\n",
    "\n",
    "##### Avec cette première vague de tests, nous avons vu que des Rsnet, avec différents nombres de couches cachées, ne dépasent pas les 60% sur la val .\n",
    "\n",
    "##### Cependant, on a aussi remarqué que tous ces modèles on tendance à beacoup overfitter. Du coup on va essayer d'appliquer des techniques de régulatisation pour voir si on peu tirer de meilleurs résultats avec les meilleurs modèles qu'on a réussi à avoir.\n",
    "\n",
    "##### Nous avons selectionnés deux modèles pour poursuivre les tests : le meilleur modèle qu'on a obtenu (6 couches avec un filtre de 64  avec une relu pour l'activation des couches cachées et une softmax pour l'output) et un modèle qui overfitte beaucoup  (6 couches avec un filtre de 64  avec une relu pour les couches cachées et la softmax pour l'output). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rsnet Avec régularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Pour la suite de nos tests, nous avons lancer une nouvelle vague de tests avec régularisation, suite au constat de l'overfiting sur les tests précédents, sur différents Rsnet en jouant sur le nombre de couches ainsi que leur filtres. Pour cela, on a lancé des tests comme suit (plusieurs fois sur la même structure) :\n",
    "    - Des modèles de 3 à 4 couches, avec filtres entre 32 et 64.\n",
    "    - Des modèles de 5 à 6 couches, avec filtres entre 32 et 64.\n",
    "    - Des modèles de 7 à 8 couches, avec filtres entre 32 et 64.\n",
    " \n",
    "    \n",
    "    Nous avons ensuite enregistré les résultats obtenus dans des fichiers CSV, en plus des logs générés par tensorflow, pour étudier les résultats obtenus.\n",
    "    \n",
    "    Nous allons donc charger ces statistiques et voir ce que ce genre de modèles peut donner sur le Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout régularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframes_list = []\n",
    "results_dataframes_desc = []\n",
    "root_csv_folder = \"..\\\\historique_tests\\\\\"\n",
    "\n",
    "\n",
    "# Rsnet with regularisation dropout results  3 to 4 layers.\n",
    "for i in [32,64]:\n",
    "    df = pd.read_csv(\"{}tested_rsnet_dropout_3_to_4_{}_history.csv\".format(root_csv_folder,i), sep=\";\")\n",
    "    results_dataframes_list.append(df)\n",
    "    results_dataframes_desc.append(\"rsnet_dropout_3_to_4_{}\".format(i))\n",
    "\n",
    "#Rsnet with regularisation dropout results  5 to 6 layers.\n",
    "for i in [32,64]:\n",
    "    df = pd.read_csv(\"{}tested_rsnet_dropout_5_to_6_{}_history.csv\".format(root_csv_folder,i), sep=\";\")\n",
    "    results_dataframes_list.append(df)\n",
    "    results_dataframes_desc.append(\"rsnet_dropout_5_to_6_{}\".format(i))\n",
    "\n",
    "# Rsnet with regularisation dropout results  7 to 8 layers.\n",
    "for i in [32,64]:\n",
    "    df = pd.read_csv(\"{}tested_rsnet_dropout_7_to_8_{}_history.csv\".format(root_csv_folder,i), sep=\";\")\n",
    "    results_dataframes_list.append(df)\n",
    "    results_dataframes_desc.append(\"rsnet_dropout_7_to_8_{}\".format(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models rsnet_dropout_3_to_4_32 ###########\n",
      "(6, 26)\n",
      "Pire résultat sur le train :  0.4397\n",
      "Pire Résultat sur la val :  0.4036\n",
      "Meilleur résultat sur le train :  0.85782\n",
      "Meilleur résultat sur la val :  0.5846\n",
      "Moyenne des résultats sur le train :  0.6423233333333332\n",
      "Moyenne des résultats sur la val :  0.48100000000000004\n",
      "Mediane des résultat sur le train :  0.63984\n",
      "Mediane des résultat sur la val :  0.4798\n",
      "\n",
      "########### Models rsnet_dropout_3_to_4_64 ###########\n",
      "(8, 26)\n",
      "Pire résultat sur le train :  0.29814\n",
      "Pire Résultat sur la val :  0.2536\n",
      "Meilleur résultat sur le train :  0.6977\n",
      "Meilleur résultat sur la val :  0.5185\n",
      "Moyenne des résultats sur le train :  0.5182775\n",
      "Moyenne des résultats sur la val :  0.42691250000000003\n",
      "Mediane des résultat sur le train :  0.50337\n",
      "Mediane des résultat sur la val :  0.4334\n",
      "\n",
      "########### Models rsnet_dropout_5_to_6_32 ###########\n",
      "(3, 26)\n",
      "Pire résultat sur le train :  0.65422\n",
      "Pire Résultat sur la val :  0.5008\n",
      "Meilleur résultat sur le train :  0.98716\n",
      "Meilleur résultat sur la val :  0.6014\n",
      "Moyenne des résultats sur le train :  0.84512\n",
      "Moyenne des résultats sur la val :  0.5417333333333333\n",
      "Mediane des résultat sur le train :  0.8939799999999999\n",
      "Mediane des résultat sur la val :  0.523\n",
      "\n",
      "########### Models rsnet_dropout_5_to_6_64 ###########\n",
      "(4, 26)\n",
      "Pire résultat sur le train :  0.47631999999999997\n",
      "Pire Résultat sur la val :  0.4113\n",
      "Meilleur résultat sur le train :  0.9605600000000001\n",
      "Meilleur résultat sur la val :  0.5847\n",
      "Moyenne des résultats sur le train :  0.821855\n",
      "Moyenne des résultats sur la val :  0.5198\n",
      "Mediane des résultat sur le train :  0.92527\n",
      "Mediane des résultat sur la val :  0.5416000000000001\n",
      "\n",
      "########### Models rsnet_dropout_7_to_8_32 ###########\n",
      "(3, 26)\n",
      "Pire résultat sur le train :  0.59958\n",
      "Pire Résultat sur la val :  0.4165\n",
      "Meilleur résultat sur le train :  0.6915600000000001\n",
      "Meilleur résultat sur la val :  0.4928\n",
      "Moyenne des résultats sur le train :  0.6302599999999999\n",
      "Moyenne des résultats sur la val :  0.4579\n",
      "Mediane des résultat sur le train :  0.59964\n",
      "Mediane des résultat sur la val :  0.4644\n",
      "\n",
      "########### Models rsnet_dropout_7_to_8_64 ###########\n",
      "(3, 26)\n",
      "Pire résultat sur le train :  0.7198\n",
      "Pire Résultat sur la val :  0.435\n",
      "Meilleur résultat sur le train :  0.97288\n",
      "Meilleur résultat sur la val :  0.5942\n",
      "Moyenne des résultats sur le train :  0.8710333333333334\n",
      "Moyenne des résultats sur la val :  0.5101666666666667\n",
      "Mediane des résultat sur le train :  0.9204200000000001\n",
      "Mediane des résultat sur la val :  0.5013\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results_dataframes_list)):\n",
    "    history = results_dataframes_list[i]\n",
    "    history_desc = results_dataframes_desc[i]\n",
    "    print_statistics(history, history_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On constate toujours un overfitting même aprés un dropout, et aussi quand la valeur du dropout est trop inportante, la val et la train accuracy sont toutes deux basses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On ne garde que les modèles dont les résultats sur la validations sont supérieurs à la moyenne des résultats de tous les modèles (d'une même architecture) testés "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_results_dataframes = filter_on_mean_val_accuracy(results_dataframes_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection des meilleurs modèles sur la val sur les modèles selectionnés:\n",
    "    Pour cela, nous n'allons prendre que les modèles dont les résultats sur l'entraînement sont supérieurs à la moyenne des résultats de tous les modèles compris (toutes arachitectures confondues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models rsnet_dropout_3_to_4_32 ###########\n",
      "(2, 26)\n",
      "Pire résultat sur le train :  0.5826399999999999\n",
      "Pire Résultat sur la val :  0.5226\n",
      "Meilleur résultat sur le train :  0.85782\n",
      "Meilleur résultat sur la val :  0.5846\n",
      "Moyenne des résultats sur le train :  0.7202299999999999\n",
      "Moyenne des résultats sur la val :  0.5536\n",
      "Mediane des résultat sur le train :  0.7202299999999999\n",
      "Mediane des résultat sur la val :  0.5536\n",
      "\n",
      "########### Models rsnet_dropout_3_to_4_64 ###########\n",
      "(4, 26)\n",
      "Pire résultat sur le train :  0.5492199999999999\n",
      "Pire Résultat sur la val :  0.4492\n",
      "Meilleur résultat sur le train :  0.6977\n",
      "Meilleur résultat sur la val :  0.5185\n",
      "Moyenne des résultats sur le train :  0.636185\n",
      "Moyenne des résultats sur la val :  0.49215\n",
      "Mediane des résultat sur le train :  0.64891\n",
      "Mediane des résultat sur la val :  0.5004500000000001\n",
      "\n",
      "########### Models rsnet_dropout_5_to_6_32 ###########\n",
      "(1, 26)\n",
      "Pire résultat sur le train :  0.98716\n",
      "Pire Résultat sur la val :  0.6014\n",
      "Meilleur résultat sur le train :  0.98716\n",
      "Meilleur résultat sur la val :  0.6014\n",
      "Moyenne des résultats sur le train :  0.98716\n",
      "Moyenne des résultats sur la val :  0.6014\n",
      "Mediane des résultat sur le train :  0.98716\n",
      "Mediane des résultat sur la val :  0.6014\n",
      "\n",
      "########### Models rsnet_dropout_5_to_6_64 ###########\n",
      "(3, 26)\n",
      "Pire résultat sur le train :  0.9152\n",
      "Pire Résultat sur la val :  0.5231\n",
      "Meilleur résultat sur le train :  0.9605600000000001\n",
      "Meilleur résultat sur la val :  0.5847\n",
      "Moyenne des résultats sur le train :  0.9370333333333334\n",
      "Moyenne des résultats sur la val :  0.5559666666666667\n",
      "Mediane des résultat sur le train :  0.93534\n",
      "Mediane des résultat sur la val :  0.5601\n",
      "\n",
      "########### Models rsnet_dropout_7_to_8_32 ###########\n",
      "(2, 26)\n",
      "Pire résultat sur le train :  0.59964\n",
      "Pire Résultat sur la val :  0.4644\n",
      "Meilleur résultat sur le train :  0.6915600000000001\n",
      "Meilleur résultat sur la val :  0.4928\n",
      "Moyenne des résultats sur le train :  0.6456\n",
      "Moyenne des résultats sur la val :  0.4786\n",
      "Mediane des résultat sur le train :  0.6456\n",
      "Mediane des résultat sur la val :  0.4786\n",
      "\n",
      "########### Models rsnet_dropout_7_to_8_64 ###########\n",
      "(1, 26)\n",
      "Pire résultat sur le train :  0.97288\n",
      "Pire Résultat sur la val :  0.5942\n",
      "Meilleur résultat sur le train :  0.97288\n",
      "Meilleur résultat sur la val :  0.5942\n",
      "Moyenne des résultats sur le train :  0.97288\n",
      "Moyenne des résultats sur la val :  0.5942\n",
      "Mediane des résultat sur le train :  0.97288\n",
      "Mediane des résultat sur la val :  0.5942\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(filtered_results_dataframes)):\n",
    "    filtered_history = filtered_results_dataframes[i]\n",
    "    filtered_history_desc = results_dataframes_desc[i]\n",
    "    print_statistics(filtered_history, filtered_history_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On fusionne tous les dataframes en une seule (étant donné qu'il y en a une par structure de modèle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = concat_list_of_dataframes(filtered_results_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models Rsnet_with_dropout_regularisation ###########\n",
      "(13, 26)\n",
      "Pire résultat sur le train :  0.5492199999999999\n",
      "Pire Résultat sur la val :  0.4492\n",
      "Meilleur résultat sur le train :  0.98716\n",
      "Meilleur résultat sur la val :  0.6014\n",
      "Moyenne des résultats sur le train :  0.7728876923076923\n",
      "Moyenne des résultats sur la val :  0.5305000000000001\n",
      "Mediane des résultat sur le train :  0.6977\n",
      "Mediane des résultat sur la val :  0.5226\n"
     ]
    }
   ],
   "source": [
    "print_statistics(merged_df, \"Rsnet_with_dropout_regularisation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models Best Rsnet Dropout models ###########\n",
      "(5, 26)\n",
      "Pire résultat sur le train :  0.85782\n",
      "Pire Résultat sur la val :  0.5601\n",
      "Meilleur résultat sur le train :  0.98716\n",
      "Meilleur résultat sur la val :  0.6014\n",
      "Moyenne des résultats sur le train :  0.9387240000000002\n",
      "Moyenne des résultats sur la val :  0.585\n",
      "Mediane des résultat sur le train :  0.9605600000000001\n",
      "Mediane des résultat sur la val :  0.5847\n"
     ]
    }
   ],
   "source": [
    "best_val_models = filter_on_mean_val_accuracy([merged_df])[0]\n",
    "best_val_models = best_val_models.sort_values('val_accuracy', ascending=False)\n",
    "print_statistics(best_val_models, \"Best Rsnet Dropout models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les modèle dont la val est > à la moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_hidden_layers</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>layers_activation</th>\n",
       "      <th>output_activation</th>\n",
       "      <th>use_skip</th>\n",
       "      <th>nb_skip</th>\n",
       "      <th>use_dropout</th>\n",
       "      <th>...</th>\n",
       "      <th>regulization_indexes</th>\n",
       "      <th>loss</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>metrics</th>\n",
       "      <th>padding</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>dossier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>4 4</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>6251911</td>\n",
       "      <td>0.98716</td>\n",
       "      <td>0.6014</td>\n",
       "      <td>20200208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>64</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>2201654</td>\n",
       "      <td>0.97288</td>\n",
       "      <td>0.5942</td>\n",
       "      <td>20200128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>4 4</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>4949333</td>\n",
       "      <td>0.96056</td>\n",
       "      <td>0.5847</td>\n",
       "      <td>20200208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>256</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>30</td>\n",
       "      <td>6932724</td>\n",
       "      <td>0.85782</td>\n",
       "      <td>0.5846</td>\n",
       "      <td>20200125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>8863967</td>\n",
       "      <td>0.91520</td>\n",
       "      <td>0.5601</td>\n",
       "      <td>20200208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_hidden_layers  filters kernel_size  batch_size input_shape  \\\n",
       "0                 6       32         4 4         128     32 32 3   \n",
       "0                 8       64         3 3          64     32 32 3   \n",
       "3                 6       64         4 4         128     32 32 3   \n",
       "0                 3       64         3 3         256     32 32 3   \n",
       "0                 6       64         3 3         128     32 32 3   \n",
       "\n",
       "  layers_activation output_activation  use_skip  nb_skip  use_dropout  ...  \\\n",
       "0           softmax           softmax      True        2         True  ...   \n",
       "0              relu           softmax      True        2         True  ...   \n",
       "3              selu           softmax      True        2         True  ...   \n",
       "0           softmax           softmax      True        2         True  ...   \n",
       "0           softmax           softmax      True        2         True  ...   \n",
       "\n",
       "  regulization_indexes                      loss  optimizer  \\\n",
       "0                  NaN  categorical_crossentropy       Adam   \n",
       "0                  NaN  categorical_crossentropy       Adam   \n",
       "3                  NaN  categorical_crossentropy       Adam   \n",
       "0                  NaN  categorical_crossentropy       Adam   \n",
       "0                  NaN  categorical_crossentropy       Adam   \n",
       "\n",
       "                metrics  padding  epochs  model_id train_accuracy  \\\n",
       "0  categorical_accuracy     same      50   6251911        0.98716   \n",
       "0  categorical_accuracy     same      50   2201654        0.97288   \n",
       "3  categorical_accuracy     same      50   4949333        0.96056   \n",
       "0  categorical_accuracy     same      30   6932724        0.85782   \n",
       "0  categorical_accuracy     same      50   8863967        0.91520   \n",
       "\n",
       "  val_accuracy   dossier  \n",
       "0       0.6014  20200208  \n",
       "0       0.5942  20200128  \n",
       "3       0.5847  20200208  \n",
       "0       0.5846  20200125  \n",
       "0       0.5601  20200208  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_models.to_csv(\"{}best_Rsnet_with_dropout_regularisation.csv\".format(root_csv_folder), sep=';',header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple Rnset Dropout:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rsnet Dropout](Rsnet_Dropout.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maintenant nous allons essayer La L1L2 régularisation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1L2 régularisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframes_list = []\n",
    "results_dataframes_desc = []\n",
    "root_csv_folder = \"..\\\\historique_tests\\\\\"\n",
    "\n",
    "\n",
    "# Rsnet with regularisation L1L2 results  3 to 4 layers.\n",
    "for i in [32,64]:\n",
    "    df = pd.read_csv(\"{}tested_rsnet_regul_3_to_4_{}_history.csv\".format(root_csv_folder,i), sep=\";\")\n",
    "    results_dataframes_list.append(df)\n",
    "    results_dataframes_desc.append(\"rsnet_regul_3_to_4_{}\".format(i))\n",
    "\n",
    "#Rsnet with regularisation L1L2 results  5 to 6 layers.\n",
    "for i in [32,64]:\n",
    "    df = pd.read_csv(\"{}tested_rsnet_regul_5_to_6_{}_history.csv\".format(root_csv_folder,i), sep=\";\")\n",
    "    results_dataframes_list.append(df)\n",
    "    results_dataframes_desc.append(\"rsnet_regul_5_to_6_{}\".format(i))\n",
    "\n",
    "# Rsnet with regularisation L1L2 results  7 to 8 layers.\n",
    "for i in [32,64]:\n",
    "    df = pd.read_csv(\"{}tested_rsnet_regul_7_to_8_{}_history.csv\".format(root_csv_folder,i), sep=\";\")\n",
    "    results_dataframes_list.append(df)\n",
    "    results_dataframes_desc.append(\"rsnet_regul_7_to_8_{}\".format(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models rsnet_regul_3_to_4_32 ###########\n",
      "(8, 26)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.4411\n",
      "Meilleur résultat sur la val :  0.4357\n",
      "Moyenne des résultats sur le train :  0.324335\n",
      "Moyenne des résultats sur la val :  0.3206625\n",
      "Mediane des résultat sur le train :  0.34986999999999996\n",
      "Mediane des résultat sur la val :  0.34295\n",
      "\n",
      "########### Models rsnet_regul_3_to_4_64 ###########\n",
      "(7, 26)\n",
      "Pire résultat sur le train :  0.12868\n",
      "Pire Résultat sur la val :  0.1266\n",
      "Meilleur résultat sur le train :  0.36582\n",
      "Meilleur résultat sur la val :  0.3588\n",
      "Moyenne des résultats sur le train :  0.28935714285714287\n",
      "Moyenne des résultats sur la val :  0.28452857142857146\n",
      "Mediane des résultat sur le train :  0.35266\n",
      "Mediane des résultat sur la val :  0.3446\n",
      "\n",
      "########### Models rsnet_regul_5_to_6_32 ###########\n",
      "(5, 26)\n",
      "Pire résultat sur le train :  0.26542\n",
      "Pire Résultat sur la val :  0.2682\n",
      "Meilleur résultat sur le train :  0.6153\n",
      "Meilleur résultat sur la val :  0.5876\n",
      "Moyenne des résultats sur le train :  0.45408399999999993\n",
      "Moyenne des résultats sur la val :  0.43742000000000003\n",
      "Mediane des résultat sur le train :  0.4084\n",
      "Mediane des résultat sur la val :  0.3995\n",
      "\n",
      "########### Models rsnet_regul_5_to_6_64 ###########\n",
      "(4, 26)\n",
      "Pire résultat sur le train :  0.25438\n",
      "Pire Résultat sur la val :  0.2553\n",
      "Meilleur résultat sur le train :  0.37942\n",
      "Meilleur résultat sur la val :  0.3635\n",
      "Moyenne des résultats sur le train :  0.34372\n",
      "Moyenne des résultats sur la val :  0.33405\n",
      "Mediane des résultat sur le train :  0.37054\n",
      "Mediane des résultat sur la val :  0.3587\n",
      "\n",
      "########### Models rsnet_regul_7_to_8_32 ###########\n",
      "(6, 26)\n",
      "Pire résultat sur le train :  0.19438\n",
      "Pire Résultat sur la val :  0.193\n",
      "Meilleur résultat sur le train :  0.67912\n",
      "Meilleur résultat sur la val :  0.6259\n",
      "Moyenne des résultats sur le train :  0.3908766666666667\n",
      "Moyenne des résultats sur la val :  0.3774666666666667\n",
      "Mediane des résultat sur le train :  0.33731999999999995\n",
      "Mediane des résultat sur la val :  0.33545\n",
      "\n",
      "########### Models rsnet_regul_7_to_8_64 ###########\n",
      "(3, 26)\n",
      "Pire résultat sur le train :  0.22496\n",
      "Pire Résultat sur la val :  0.2273\n",
      "Meilleur résultat sur le train :  0.2948\n",
      "Meilleur résultat sur la val :  0.2993\n",
      "Moyenne des résultats sur le train :  0.26392\n",
      "Moyenne des résultats sur la val :  0.2659666666666667\n",
      "Mediane des résultat sur le train :  0.272\n",
      "Mediane des résultat sur la val :  0.2713\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results_dataframes_list)):\n",
    "    history = results_dataframes_list[i]\n",
    "    history_desc = results_dataframes_desc[i]\n",
    "    print_statistics(history, history_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ici on ne constate le cas d'overfiting et le % de la val et du train est très bas, car la valeur de la L1L2 est trop importante. Car au depart on a lancé des tests random du coup les valeurs de la L1L2 retournées ont fais que les modèles n'arrivent pas à dépasser l'intervale 30 à 40 %. En suite on a ajuster les valeurs de la L1L2 (moins elevées) pour avoir de mielleurs résultats d'accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On ne garde que les modèles dont les résultats sur la validations sont supérieurs à la moyenne des résultats de tous les modèles (d'une même architecture) testés "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_results_dataframes = filter_on_mean_val_accuracy(results_dataframes_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection des meilleurs modèles sur la val sur les modèles selectionnés:\n",
    "    Pour cela, nous n'allons prendre que les modèles dont les résultats sur l'entraînement sont supérieurs à la moyenne des résultats de tous les modèles compris (toutes arachitectures confondues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models rsnet_regul_3_to_4_32 ###########\n",
      "(5, 26)\n",
      "Pire résultat sur le train :  0.34431999999999996\n",
      "Pire Résultat sur la val :  0.3361\n",
      "Meilleur résultat sur le train :  0.4411\n",
      "Meilleur résultat sur la val :  0.4357\n",
      "Moyenne des résultats sur le train :  0.38769200000000004\n",
      "Moyenne des résultats sur la val :  0.38306\n",
      "Mediane des résultat sur le train :  0.36404000000000003\n",
      "Mediane des résultat sur la val :  0.3649\n",
      "\n",
      "########### Models rsnet_regul_3_to_4_64 ###########\n",
      "(5, 26)\n",
      "Pire résultat sur le train :  0.28665999999999997\n",
      "Pire Résultat sur la val :  0.2912\n",
      "Meilleur résultat sur le train :  0.36582\n",
      "Meilleur résultat sur la val :  0.3588\n",
      "Moyenne des résultats sur le train :  0.346748\n",
      "Moyenne des résultats sur la val :  0.34030000000000005\n",
      "Mediane des résultat sur le train :  0.36401999999999995\n",
      "Mediane des résultat sur la val :  0.3533\n",
      "\n",
      "########### Models rsnet_regul_5_to_6_32 ###########\n",
      "(2, 26)\n",
      "Pire résultat sur le train :  0.60044\n",
      "Pire Résultat sur la val :  0.5635\n",
      "Meilleur résultat sur le train :  0.6153\n",
      "Meilleur résultat sur la val :  0.5876\n",
      "Moyenne des résultats sur le train :  0.6078699999999999\n",
      "Moyenne des résultats sur la val :  0.57555\n",
      "Mediane des résultat sur le train :  0.6078699999999999\n",
      "Mediane des résultat sur la val :  0.57555\n",
      "\n",
      "########### Models rsnet_regul_5_to_6_64 ###########\n",
      "(3, 26)\n",
      "Pire résultat sur le train :  0.36858\n",
      "Pire Résultat sur la val :  0.355\n",
      "Meilleur résultat sur le train :  0.37942\n",
      "Meilleur résultat sur la val :  0.3635\n",
      "Moyenne des résultats sur le train :  0.37349999999999994\n",
      "Moyenne des résultats sur la val :  0.3603\n",
      "Mediane des résultat sur le train :  0.3725\n",
      "Mediane des résultat sur la val :  0.3624\n",
      "\n",
      "########### Models rsnet_regul_7_to_8_32 ###########\n",
      "(2, 26)\n",
      "Pire résultat sur le train :  0.48596000000000006\n",
      "Pire Résultat sur la val :  0.4729\n",
      "Meilleur résultat sur le train :  0.67912\n",
      "Meilleur résultat sur la val :  0.6259\n",
      "Moyenne des résultats sur le train :  0.5825400000000001\n",
      "Moyenne des résultats sur la val :  0.5494\n",
      "Mediane des résultat sur le train :  0.5825400000000001\n",
      "Mediane des résultat sur la val :  0.5494\n",
      "\n",
      "########### Models rsnet_regul_7_to_8_64 ###########\n",
      "(2, 26)\n",
      "Pire résultat sur le train :  0.272\n",
      "Pire Résultat sur la val :  0.2713\n",
      "Meilleur résultat sur le train :  0.2948\n",
      "Meilleur résultat sur la val :  0.2993\n",
      "Moyenne des résultats sur le train :  0.2834\n",
      "Moyenne des résultats sur la val :  0.2853\n",
      "Mediane des résultat sur le train :  0.2834\n",
      "Mediane des résultat sur la val :  0.2853\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(filtered_results_dataframes)):\n",
    "    filtered_history = filtered_results_dataframes[i]\n",
    "    filtered_history_desc = results_dataframes_desc[i]\n",
    "    print_statistics(filtered_history, filtered_history_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On fusionne tous les dataframes en une seule (étant donné qu'il y en a une par structure de modèle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = concat_list_of_dataframes(filtered_results_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models Rsnet_with_L1L2_regularisation ###########\n",
      "(19, 26)\n",
      "Pire résultat sur le train :  0.272\n",
      "Pire Résultat sur la val :  0.2713\n",
      "Meilleur résultat sur le train :  0.67912\n",
      "Meilleur résultat sur la val :  0.6259\n",
      "Moyenne des résultats sur le train :  0.40738526315789475\n",
      "Moyenne des résultats sur la val :  0.39569473684210527\n",
      "Mediane des résultat sur le train :  0.36582\n",
      "Mediane des résultat sur la val :  0.3588\n"
     ]
    }
   ],
   "source": [
    "print_statistics(merged_df, \"Rsnet_with_L1L2_regularisation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models Best Rsnet L1L2 models ###########\n",
      "(6, 26)\n",
      "Pire résultat sur le train :  0.43358\n",
      "Pire Résultat sur la val :  0.4288\n",
      "Meilleur résultat sur le train :  0.67912\n",
      "Meilleur résultat sur la val :  0.6259\n",
      "Moyenne des résultats sur le train :  0.5425833333333333\n",
      "Moyenne des résultats sur la val :  0.5190666666666667\n",
      "Mediane des résultat sur le train :  0.5432\n",
      "Mediane des résultat sur la val :  0.5182\n"
     ]
    }
   ],
   "source": [
    "best_val_models = filter_on_mean_val_accuracy([merged_df])[0]\n",
    "best_val_models = best_val_models.sort_values('val_accuracy', ascending=False)\n",
    "print_statistics(best_val_models, \"Best Rsnet L1L2 models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_hidden_layers</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>layers_activation</th>\n",
       "      <th>output_activation</th>\n",
       "      <th>use_skip</th>\n",
       "      <th>nb_skip</th>\n",
       "      <th>use_dropout</th>\n",
       "      <th>...</th>\n",
       "      <th>regulization_indexes</th>\n",
       "      <th>loss</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>metrics</th>\n",
       "      <th>padding</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>dossier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>1477028</td>\n",
       "      <td>0.67912</td>\n",
       "      <td>0.6259</td>\n",
       "      <td>20200209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>3162669</td>\n",
       "      <td>0.61530</td>\n",
       "      <td>0.5876</td>\n",
       "      <td>20200209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>4359082</td>\n",
       "      <td>0.60044</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>20200209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>6 5</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>7466498</td>\n",
       "      <td>0.48596</td>\n",
       "      <td>0.4729</td>\n",
       "      <td>20200209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>3333723</td>\n",
       "      <td>0.43358</td>\n",
       "      <td>0.4357</td>\n",
       "      <td>20200209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>3787713</td>\n",
       "      <td>0.44110</td>\n",
       "      <td>0.4288</td>\n",
       "      <td>20200209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_hidden_layers  filters kernel_size  batch_size input_shape  \\\n",
       "3                 8       32         3 3         128     32 32 3   \n",
       "3                 5       32         3 3         128     32 32 3   \n",
       "4                 6       32         3 3         128     32 32 3   \n",
       "5                 7       32         3 3         128     32 32 3   \n",
       "7                 4       32         3 3         128     32 32 3   \n",
       "6                 3       32         3 3         128     32 32 3   \n",
       "\n",
       "  layers_activation output_activation  use_skip  nb_skip  use_dropout  ...  \\\n",
       "3              relu           softmax      True        2        False  ...   \n",
       "3              selu           softmax      True        2        False  ...   \n",
       "4              relu           softmax      True        2        False  ...   \n",
       "5           softmax           softmax      True        2        False  ...   \n",
       "7           softmax           softmax      True        2        False  ...   \n",
       "6              relu           softmax      True        2        False  ...   \n",
       "\n",
       "   regulization_indexes                      loss  optimizer  \\\n",
       "3                     5  categorical_crossentropy       Adam   \n",
       "3                     3  categorical_crossentropy       Adam   \n",
       "4                   NaN  categorical_crossentropy       Adam   \n",
       "5                   6 5  categorical_crossentropy       Adam   \n",
       "7                   NaN  categorical_crossentropy       Adam   \n",
       "6                     2  categorical_crossentropy       Adam   \n",
       "\n",
       "                metrics  padding  epochs model_id train_accuracy val_accuracy  \\\n",
       "3  categorical_accuracy     same      50  1477028        0.67912       0.6259   \n",
       "3  categorical_accuracy     same      50  3162669        0.61530       0.5876   \n",
       "4  categorical_accuracy     same      50  4359082        0.60044       0.5635   \n",
       "5  categorical_accuracy     same      50  7466498        0.48596       0.4729   \n",
       "7  categorical_accuracy     same      50  3333723        0.43358       0.4357   \n",
       "6  categorical_accuracy     same      50  3787713        0.44110       0.4288   \n",
       "\n",
       "    dossier  \n",
       "3  20200209  \n",
       "3  20200209  \n",
       "4  20200209  \n",
       "5  20200209  \n",
       "7  20200209  \n",
       "6  20200209  \n",
       "\n",
       "[6 rows x 26 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_models.to_csv(\"{}best_Rsnet_with_L1L2_regularisation.csv\".format(root_csv_folder), sep=';',header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de progression du loss et de l'accuracy avec L1L2 regularisation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorbord L1L2](Rsnet_Regul.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple d'un Rsnet avec L1L2 regularisation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rsnet L1L2](Rsnet_regul.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maintenant nous allons combiner les deux techniques de regularisations; L1L2 et Dropout:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1L2 and Dropout régularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframes_list = []\n",
    "results_dataframes_desc = []\n",
    "root_csv_folder = \"..\\\\historique_tests\\\\\"\n",
    "\n",
    "\n",
    "# Rsnet with regularisation L1L2 and dropout results  3 to 4 layers.\n",
    "for i in [32,64]:\n",
    "    df = pd.read_csv(\"{}tested_rsnet_rg_dr_3_to_4_{}_history.csv\".format(root_csv_folder,i), sep=\";\")\n",
    "    results_dataframes_list.append(df)\n",
    "    results_dataframes_desc.append(\"rsnet_rg_dr_3_to_4_{}\".format(i))\n",
    "\n",
    "#Rsnet with regularisation L1L2 and dropout results  5 to 6 layers.\n",
    "for i in [32,64]:\n",
    "    df = pd.read_csv(\"{}tested_rsnet_rg_dr_5_to_6_{}_history.csv\".format(root_csv_folder,i), sep=\";\")\n",
    "    results_dataframes_list.append(df)\n",
    "    results_dataframes_desc.append(\"rsnet_rg_dr_5_to_6_{}\".format(i))\n",
    "\n",
    "# Rsnet with regularisation L1L2 and dropout results  7 to 8 layers.\n",
    "for i in [32,64]:\n",
    "    df = pd.read_csv(\"{}tested_rsnet_rg_dr_7_to_8_{}_history.csv\".format(root_csv_folder,i), sep=\";\")\n",
    "    results_dataframes_list.append(df)\n",
    "    results_dataframes_desc.append(\"rsnet_rg_dr_7_to_8_{}\".format(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models rsnet_rg_dr_3_to_4_32 ###########\n",
      "(6, 26)\n",
      "Pire résultat sur le train :  0.11606\n",
      "Pire Résultat sur la val :  0.114\n",
      "Meilleur résultat sur le train :  0.4722\n",
      "Meilleur résultat sur la val :  0.4629\n",
      "Moyenne des résultats sur le train :  0.25787\n",
      "Moyenne des résultats sur la val :  0.2558666666666667\n",
      "Mediane des résultat sur le train :  0.23465\n",
      "Mediane des résultat sur la val :  0.2353\n",
      "\n",
      "########### Models rsnet_rg_dr_3_to_4_64 ###########\n",
      "(6, 26)\n",
      "Pire résultat sur le train :  0.11027999999999999\n",
      "Pire Résultat sur la val :  0.1111\n",
      "Meilleur résultat sur le train :  0.43648000000000003\n",
      "Meilleur résultat sur la val :  0.4241\n",
      "Moyenne des résultats sur le train :  0.2891933333333333\n",
      "Moyenne des résultats sur la val :  0.2855\n",
      "Mediane des résultat sur le train :  0.30627\n",
      "Mediane des résultat sur la val :  0.30265\n",
      "\n",
      "########### Models rsnet_rg_dr_5_to_6_32 ###########\n",
      "(3, 26)\n",
      "Pire résultat sur le train :  0.1333\n",
      "Pire Résultat sur la val :  0.1314\n",
      "Meilleur résultat sur le train :  0.21975999999999998\n",
      "Meilleur résultat sur la val :  0.2246\n",
      "Moyenne des résultats sur le train :  0.16932\n",
      "Moyenne des résultats sur la val :  0.17043333333333333\n",
      "Mediane des résultat sur le train :  0.1549\n",
      "Mediane des résultat sur la val :  0.1553\n",
      "\n",
      "########### Models rsnet_rg_dr_5_to_6_64 ###########\n",
      "(23, 26)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.9707600000000001\n",
      "Meilleur résultat sur la val :  0.6438\n",
      "Moyenne des résultats sur le train :  0.6356869565217391\n",
      "Moyenne des résultats sur la val :  0.4948695652173913\n",
      "Mediane des résultat sur le train :  0.71738\n",
      "Mediane des résultat sur la val :  0.5432\n",
      "\n",
      "########### Models rsnet_rg_dr_7_to_8_32 ###########\n",
      "(4, 26)\n",
      "Pire résultat sur le train :  0.13294\n",
      "Pire Résultat sur la val :  0.1333\n",
      "Meilleur résultat sur le train :  0.54138\n",
      "Meilleur résultat sur la val :  0.5274\n",
      "Moyenne des résultats sur le train :  0.298915\n",
      "Moyenne des résultats sur la val :  0.29700000000000004\n",
      "Mediane des résultat sur le train :  0.26067\n",
      "Mediane des résultat sur la val :  0.26365\n",
      "\n",
      "########### Models rsnet_rg_dr_7_to_8_64 ###########\n",
      "(2, 26)\n",
      "Pire résultat sur le train :  0.8750399999999999\n",
      "Pire Résultat sur la val :  0.606\n",
      "Meilleur résultat sur le train :  0.9324\n",
      "Meilleur résultat sur la val :  0.6512\n",
      "Moyenne des résultats sur le train :  0.90372\n",
      "Moyenne des résultats sur la val :  0.6286\n",
      "Mediane des résultat sur le train :  0.90372\n",
      "Mediane des résultat sur la val :  0.6286\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results_dataframes_list)):\n",
    "    history = results_dataframes_list[i]\n",
    "    history_desc = results_dataframes_desc[i]\n",
    "    print_statistics(history, history_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On constate qu'avec les deux methodes de regularisation ensemles que la val et le train ne sont pas très grand, mais on constate que l'overfiting est moins imporant ( mise à part quelques cas ) car le jeux de tests lancé est fait avec des random sur les valeurs de regularisation et les couches ciblees, puis on ajuste les valeurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On ne garde que les modèles dont les résultats sur la validations sont supérieurs à la moyenne des résultats de tous les modèles (d'une même architecture) testés "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_results_dataframes = filter_on_mean_val_accuracy(results_dataframes_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection des meilleurs modèles sur la val sur les modèles selectionnés:\n",
    "    Pour cela, nous n'allons prendre que les modèles dont les résultats sur l'entraînement sont supérieurs à la moyenne des résultats de tous les modèles compris (toutes arachitectures confondues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models rsnet_rg_dr_3_to_4_32 ###########\n",
      "(2, 26)\n",
      "Pire résultat sur le train :  0.30201999999999996\n",
      "Pire Résultat sur la val :  0.2998\n",
      "Meilleur résultat sur le train :  0.4722\n",
      "Meilleur résultat sur la val :  0.4629\n",
      "Moyenne des résultats sur le train :  0.38710999999999995\n",
      "Moyenne des résultats sur la val :  0.38134999999999997\n",
      "Mediane des résultat sur le train :  0.38710999999999995\n",
      "Mediane des résultat sur la val :  0.38134999999999997\n",
      "\n",
      "########### Models rsnet_rg_dr_3_to_4_64 ###########\n",
      "(4, 26)\n",
      "Pire résultat sur le train :  0.29334\n",
      "Pire Résultat sur la val :  0.2922\n",
      "Meilleur résultat sur le train :  0.43648000000000003\n",
      "Meilleur résultat sur la val :  0.4241\n",
      "Moyenne des résultats sur le train :  0.362135\n",
      "Moyenne des résultats sur la val :  0.355575\n",
      "Mediane des résultat sur le train :  0.35936\n",
      "Mediane des résultat sur la val :  0.353\n",
      "\n",
      "########### Models rsnet_rg_dr_5_to_6_32 ###########\n",
      "(1, 26)\n",
      "Pire résultat sur le train :  0.21975999999999998\n",
      "Pire Résultat sur la val :  0.2246\n",
      "Meilleur résultat sur le train :  0.21975999999999998\n",
      "Meilleur résultat sur la val :  0.2246\n",
      "Moyenne des résultats sur le train :  0.21975999999999998\n",
      "Moyenne des résultats sur la val :  0.2246\n",
      "Mediane des résultat sur le train :  0.21975999999999998\n",
      "Mediane des résultat sur la val :  0.2246\n",
      "\n",
      "########### Models rsnet_rg_dr_5_to_6_64 ###########\n",
      "(15, 26)\n",
      "Pire résultat sur le train :  0.6177199999999999\n",
      "Pire Résultat sur la val :  0.4976\n",
      "Meilleur résultat sur le train :  0.9707600000000001\n",
      "Meilleur résultat sur la val :  0.6438\n",
      "Moyenne des résultats sur le train :  0.7535973333333335\n",
      "Moyenne des résultats sur la val :  0.5779933333333334\n",
      "Mediane des résultat sur le train :  0.7324\n",
      "Mediane des résultat sur la val :  0.5742\n",
      "\n",
      "########### Models rsnet_rg_dr_7_to_8_32 ###########\n",
      "(1, 26)\n",
      "Pire résultat sur le train :  0.54138\n",
      "Pire Résultat sur la val :  0.5274\n",
      "Meilleur résultat sur le train :  0.54138\n",
      "Meilleur résultat sur la val :  0.5274\n",
      "Moyenne des résultats sur le train :  0.54138\n",
      "Moyenne des résultats sur la val :  0.5274\n",
      "Mediane des résultat sur le train :  0.54138\n",
      "Mediane des résultat sur la val :  0.5274\n",
      "\n",
      "########### Models rsnet_rg_dr_7_to_8_64 ###########\n",
      "(1, 26)\n",
      "Pire résultat sur le train :  0.8750399999999999\n",
      "Pire Résultat sur la val :  0.6512\n",
      "Meilleur résultat sur le train :  0.8750399999999999\n",
      "Meilleur résultat sur la val :  0.6512\n",
      "Moyenne des résultats sur le train :  0.8750399999999999\n",
      "Moyenne des résultats sur la val :  0.6512\n",
      "Mediane des résultat sur le train :  0.8750399999999999\n",
      "Mediane des résultat sur la val :  0.6512\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(filtered_results_dataframes)):\n",
    "    filtered_history = filtered_results_dataframes[i]\n",
    "    filtered_history_desc = results_dataframes_desc[i]\n",
    "    print_statistics(filtered_history, filtered_history_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On fusionne tous les dataframes en une seule (étant donné qu'il y en a une par structure de modèle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = concat_list_of_dataframes(filtered_results_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models Rsnet_with_droupout_L1L2_regularisation ###########\n",
      "(24, 26)\n",
      "Pire résultat sur le train :  0.21975999999999998\n",
      "Pire Résultat sur la val :  0.2246\n",
      "Meilleur résultat sur le train :  0.9707600000000001\n",
      "Meilleur résultat sur la val :  0.6512\n",
      "Moyenne des résultats sur le train :  0.6317875000000001\n",
      "Moyenne des résultats sur la val :  0.5107541666666667\n",
      "Mediane des résultat sur le train :  0.71773\n",
      "Mediane des résultat sur la val :  0.5559000000000001\n"
     ]
    }
   ],
   "source": [
    "print_statistics(merged_df, \"Rsnet_with_droupout_L1L2_regularisation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models Best Rsnet Dropout L1L2 models ###########\n",
      "(15, 26)\n",
      "Pire résultat sur le train :  0.54138\n",
      "Pire Résultat sur la val :  0.5274\n",
      "Meilleur résultat sur le train :  0.9707600000000001\n",
      "Meilleur résultat sur la val :  0.6512\n",
      "Moyenne des résultats sur le train :  0.762348\n",
      "Moyenne des résultats sur la val :  0.5899666666666668\n",
      "Mediane des résultat sur le train :  0.75864\n",
      "Mediane des résultat sur la val :  0.5894\n"
     ]
    }
   ],
   "source": [
    "best_val_models = filter_on_mean_val_accuracy([merged_df])[0]\n",
    "best_val_models = best_val_models.sort_values('val_accuracy', ascending=False)\n",
    "print_statistics(best_val_models, \"Best Rsnet Dropout L1L2 models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_hidden_layers</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>layers_activation</th>\n",
       "      <th>output_activation</th>\n",
       "      <th>use_skip</th>\n",
       "      <th>nb_skip</th>\n",
       "      <th>use_dropout</th>\n",
       "      <th>...</th>\n",
       "      <th>regulization_indexes</th>\n",
       "      <th>loss</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>metrics</th>\n",
       "      <th>padding</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>dossier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2 4</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>45286</td>\n",
       "      <td>0.87504</td>\n",
       "      <td>0.6512</td>\n",
       "      <td>20200209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>2599981</td>\n",
       "      <td>0.76114</td>\n",
       "      <td>0.6438</td>\n",
       "      <td>20200203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>7171554</td>\n",
       "      <td>0.77956</td>\n",
       "      <td>0.6382</td>\n",
       "      <td>20200203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>3 6</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>4893841</td>\n",
       "      <td>0.72964</td>\n",
       "      <td>0.6380</td>\n",
       "      <td>20200202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>2775255</td>\n",
       "      <td>0.73240</td>\n",
       "      <td>0.6187</td>\n",
       "      <td>20200203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>3 6</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>5325785</td>\n",
       "      <td>0.71808</td>\n",
       "      <td>0.5922</td>\n",
       "      <td>20200202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2 5</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>5165771</td>\n",
       "      <td>0.97076</td>\n",
       "      <td>0.5905</td>\n",
       "      <td>20200203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>3 6</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>2349585</td>\n",
       "      <td>0.71738</td>\n",
       "      <td>0.5894</td>\n",
       "      <td>20200202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>4113825</td>\n",
       "      <td>0.78162</td>\n",
       "      <td>0.5742</td>\n",
       "      <td>20200204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>8176707</td>\n",
       "      <td>0.72282</td>\n",
       "      <td>0.5711</td>\n",
       "      <td>20200203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>283349</td>\n",
       "      <td>0.75864</td>\n",
       "      <td>0.5696</td>\n",
       "      <td>20200204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>5940036</td>\n",
       "      <td>0.76198</td>\n",
       "      <td>0.5686</td>\n",
       "      <td>20200204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2 5</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>8442418</td>\n",
       "      <td>0.89460</td>\n",
       "      <td>0.5432</td>\n",
       "      <td>20200203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2 5</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>7034994</td>\n",
       "      <td>0.69018</td>\n",
       "      <td>0.5334</td>\n",
       "      <td>20200203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>64</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2 8</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>9287685</td>\n",
       "      <td>0.54138</td>\n",
       "      <td>0.5274</td>\n",
       "      <td>20200129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_hidden_layers  filters kernel_size  batch_size input_shape  \\\n",
       "0                  8       64         3 3         128     32 32 3   \n",
       "13                 6      128         3 3         128     32 32 3   \n",
       "11                 6      128         3 3         128     32 32 3   \n",
       "22                 6      128         3 3         128     32 32 3   \n",
       "14                 6      128         3 3         128     32 32 3   \n",
       "20                 6      128         3 3         128     32 32 3   \n",
       "5                  6       64         3 3         128     32 32 3   \n",
       "21                 6      128         3 3         128     32 32 3   \n",
       "15                 5      128         3 3         128     32 32 3   \n",
       "12                 6      128         3 3         128     32 32 3   \n",
       "17                 5      128         3 3         128     32 32 3   \n",
       "16                 5      128         3 3         128     32 32 3   \n",
       "8                  6       64         3 3         128     32 32 3   \n",
       "7                  6       64         3 3         128     32 32 3   \n",
       "3                  8       32         3 3          64     32 32 3   \n",
       "\n",
       "   layers_activation output_activation  use_skip  nb_skip  use_dropout  ...  \\\n",
       "0               relu           softmax      True        2         True  ...   \n",
       "13              relu           softmax      True        2         True  ...   \n",
       "11              relu           softmax      True        2         True  ...   \n",
       "22              relu           softmax      True        2         True  ...   \n",
       "14              relu           softmax      True        2         True  ...   \n",
       "20              relu           softmax      True        2         True  ...   \n",
       "5               selu           softmax      True        2         True  ...   \n",
       "21              relu           softmax      True        2         True  ...   \n",
       "15              relu           softmax      True        2         True  ...   \n",
       "12              relu           softmax      True        2         True  ...   \n",
       "17              relu           softmax      True        2         True  ...   \n",
       "16              relu           softmax      True        2         True  ...   \n",
       "8               selu           softmax      True        2         True  ...   \n",
       "7               selu           softmax      True        2         True  ...   \n",
       "3               selu           softmax      True        2         True  ...   \n",
       "\n",
       "   regulization_indexes                      loss  optimizer  \\\n",
       "0                   2 4  categorical_crossentropy       Adam   \n",
       "13                    2  categorical_crossentropy       Adam   \n",
       "11                    2  categorical_crossentropy       Adam   \n",
       "22                  3 6  categorical_crossentropy       Adam   \n",
       "14                    2  categorical_crossentropy       Adam   \n",
       "20                  3 6  categorical_crossentropy       Adam   \n",
       "5                   2 5  categorical_crossentropy       Adam   \n",
       "21                  3 6  categorical_crossentropy       Adam   \n",
       "15                    4  categorical_crossentropy       Adam   \n",
       "12                    2  categorical_crossentropy       Adam   \n",
       "17                    4  categorical_crossentropy       Adam   \n",
       "16                    4  categorical_crossentropy       Adam   \n",
       "8                   2 5  categorical_crossentropy       Adam   \n",
       "7                   2 5  categorical_crossentropy       Adam   \n",
       "3                   2 8  categorical_crossentropy       Adam   \n",
       "\n",
       "                 metrics  padding  epochs model_id train_accuracy  \\\n",
       "0   categorical_accuracy     same      50    45286        0.87504   \n",
       "13  categorical_accuracy     same      50  2599981        0.76114   \n",
       "11  categorical_accuracy     same      50  7171554        0.77956   \n",
       "22  categorical_accuracy     same      50  4893841        0.72964   \n",
       "14  categorical_accuracy     same      50  2775255        0.73240   \n",
       "20  categorical_accuracy     same      50  5325785        0.71808   \n",
       "5   categorical_accuracy     same      50  5165771        0.97076   \n",
       "21  categorical_accuracy     same      50  2349585        0.71738   \n",
       "15  categorical_accuracy     same      50  4113825        0.78162   \n",
       "12  categorical_accuracy     same      50  8176707        0.72282   \n",
       "17  categorical_accuracy     same      50   283349        0.75864   \n",
       "16  categorical_accuracy     same      50  5940036        0.76198   \n",
       "8   categorical_accuracy     same      50  8442418        0.89460   \n",
       "7   categorical_accuracy     same      50  7034994        0.69018   \n",
       "3   categorical_accuracy     same      50  9287685        0.54138   \n",
       "\n",
       "   val_accuracy   dossier  \n",
       "0        0.6512  20200209  \n",
       "13       0.6438  20200203  \n",
       "11       0.6382  20200203  \n",
       "22       0.6380  20200202  \n",
       "14       0.6187  20200203  \n",
       "20       0.5922  20200202  \n",
       "5        0.5905  20200203  \n",
       "21       0.5894  20200202  \n",
       "15       0.5742  20200204  \n",
       "12       0.5711  20200203  \n",
       "17       0.5696  20200204  \n",
       "16       0.5686  20200204  \n",
       "8        0.5432  20200203  \n",
       "7        0.5334  20200203  \n",
       "3        0.5274  20200129  \n",
       "\n",
       "[15 rows x 26 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_models.to_csv(\"{}best_Rsnet_with_Dropout_L1L2_regularisation.csv\".format(root_csv_folder), sep=';',header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On constate que la régularisation à bien amoindri l'overfiting, on constate que l'ecart entre la val et le train et de plus en plus petit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorbord Rsnet Dropout et L1L2:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Dropout_L1L2](Dropout_L1L2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exemple Rsnet Dropout et L1L2 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rsnet Dropout L1L2](Rsnet_Dropout_L1L2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Après avoir fait divers tests, on a constaté que la val n'arrivait pas à depasser les 65% environs et cela malgré les diverses techniques utilisées. Il nous restait à tester les Rsnet avec les Maxpooling combiné avec Dropout et L1L2 regularisation ( mission jugée un peut délicate au début en vue de l'utilisation des add() donc problèmes de shapes, mais ça a pu se faire en utilisant un UpSampling2D avant le add() ) afin de voir si on pouvais amméliorer la val accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Maxpoolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframes_list = []\n",
    "results_dataframes_desc = []\n",
    "root_csv_folder = \"..\\\\historique_tests\\\\\"\n",
    "\n",
    "\n",
    "# Rsnet with Maxpooling results 5 to 6 layers.\n",
    "for i in [32,64]:\n",
    "    df = pd.read_csv(\"{}tested_rsnet_maxpool_5_to_6_{}_history.csv\".format(root_csv_folder,i), sep=\";\")\n",
    "    results_dataframes_list.append(df)\n",
    "    results_dataframes_desc.append(\"rsnet_maxpool_5_to_6_{}\".format(i))\n",
    "\n",
    "#Rsnet with Maxpooling results  7 to 8 layers.\n",
    "for i in [32,64]:\n",
    "    df = pd.read_csv(\"{}tested_rsnet_maxpool_7_to_8_{}_history.csv\".format(root_csv_folder,i), sep=\";\")\n",
    "    results_dataframes_list.append(df)\n",
    "    results_dataframes_desc.append(\"rsnet_maxpool_7_to_8_{}\".format(i))\n",
    "\n",
    "# Rsnet with Maxpooling results  9 layers.\n",
    "for i in [32,64]:\n",
    "    df = pd.read_csv(\"{}tested_rsnet_maxpool_9_{}_history.csv\".format(root_csv_folder,i), sep=\";\")\n",
    "    results_dataframes_list.append(df)\n",
    "    results_dataframes_desc.append(\"rsnet_maxpool_9_{}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models rsnet_maxpool_5_to_6_32 ###########\n",
      "(6, 26)\n",
      "Pire résultat sur le train :  0.45364\n",
      "Pire Résultat sur la val :  0.4476\n",
      "Meilleur résultat sur le train :  0.8593799999999999\n",
      "Meilleur résultat sur la val :  0.6222\n",
      "Moyenne des résultats sur le train :  0.6746833333333333\n",
      "Moyenne des résultats sur la val :  0.5539833333333333\n",
      "Mediane des résultat sur le train :  0.69415\n",
      "Mediane des résultat sur la val :  0.57315\n",
      "\n",
      "########### Models rsnet_maxpool_5_to_6_64 ###########\n",
      "(3, 26)\n",
      "Pire résultat sur le train :  0.41648\n",
      "Pire Résultat sur la val :  0.3992\n",
      "Meilleur résultat sur le train :  0.8658600000000001\n",
      "Meilleur résultat sur la val :  0.6229\n",
      "Moyenne des résultats sur le train :  0.6055133333333333\n",
      "Moyenne des résultats sur la val :  0.5109\n",
      "Mediane des résultat sur le train :  0.5342\n",
      "Mediane des résultat sur la val :  0.5106\n",
      "\n",
      "########### Models rsnet_maxpool_7_to_8_32 ###########\n",
      "(4, 26)\n",
      "Pire résultat sur le train :  0.49928\n",
      "Pire Résultat sur la val :  0.4856\n",
      "Meilleur résultat sur le train :  0.8873200000000001\n",
      "Meilleur résultat sur la val :  0.6757\n",
      "Moyenne des résultats sur le train :  0.7261500000000001\n",
      "Moyenne des résultats sur la val :  0.615325\n",
      "Mediane des résultat sur le train :  0.759\n",
      "Mediane des résultat sur la val :  0.6499999999999999\n",
      "\n",
      "########### Models rsnet_maxpool_7_to_8_64 ###########\n",
      "(7, 26)\n",
      "Pire résultat sur le train :  0.45421999999999996\n",
      "Pire Résultat sur la val :  0.4409\n",
      "Meilleur résultat sur le train :  0.95276\n",
      "Meilleur résultat sur la val :  0.7121\n",
      "Moyenne des résultats sur le train :  0.77388\n",
      "Moyenne des résultats sur la val :  0.6221285714285715\n",
      "Mediane des résultat sur le train :  0.81004\n",
      "Mediane des résultat sur la val :  0.6403\n",
      "\n",
      "########### Models rsnet_maxpool_9_32 ###########\n",
      "(4, 26)\n",
      "Pire résultat sur le train :  0.3847\n",
      "Pire Résultat sur la val :  0.3813\n",
      "Meilleur résultat sur le train :  0.64646\n",
      "Meilleur résultat sur la val :  0.6228\n",
      "Moyenne des résultats sur le train :  0.5488\n",
      "Moyenne des résultats sur la val :  0.527175\n",
      "Mediane des résultat sur le train :  0.58202\n",
      "Mediane des résultat sur la val :  0.5523\n",
      "\n",
      "########### Models rsnet_maxpool_9_64 ###########\n",
      "(2, 26)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.8421\n",
      "Meilleur résultat sur la val :  0.6114\n",
      "Moyenne des résultats sur le train :  0.47104999999999997\n",
      "Moyenne des résultats sur la val :  0.3557\n",
      "Mediane des résultat sur le train :  0.47104999999999997\n",
      "Mediane des résultat sur la val :  0.3557\n"
     ]
    }
   ],
   "source": [
    "# faut lancer des tests sur maxpool 5 to 6 64\n",
    "for i in range(len(results_dataframes_list)):\n",
    "    history = results_dataframes_list[i]\n",
    "    history_desc = results_dataframes_desc[i]\n",
    "    print_statistics(history, history_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On ne garde que les modèles dont les résultats sur la validations sont supérieurs à la moyenne des résultats de tous les modèles (d'une même architecture) testés "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_results_dataframes = filter_on_mean_val_accuracy(results_dataframes_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection des meilleurs modèles sur la val sur les modèles selectionnés:\n",
    "    Pour cela, nous n'allons prendre que les modèles dont les résultats sur l'entraînement sont supérieurs à la moyenne des résultats de tous les modèles compris (toutes arachitectures confondues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models rsnet_maxpool_5_to_6_32 ###########\n",
      "(4, 26)\n",
      "Pire résultat sur le train :  0.5791\n",
      "Pire Résultat sur la val :  0.5602\n",
      "Meilleur résultat sur le train :  0.8593799999999999\n",
      "Meilleur résultat sur la val :  0.6222\n",
      "Moyenne des résultats sur le train :  0.7702\n",
      "Moyenne des résultats sur la val :  0.597375\n",
      "Mediane des résultat sur le train :  0.8211600000000001\n",
      "Mediane des résultat sur la val :  0.60355\n",
      "\n",
      "########### Models rsnet_maxpool_5_to_6_64 ###########\n",
      "(1, 26)\n",
      "Pire résultat sur le train :  0.8658600000000001\n",
      "Pire Résultat sur la val :  0.6229\n",
      "Meilleur résultat sur le train :  0.8658600000000001\n",
      "Meilleur résultat sur la val :  0.6229\n",
      "Moyenne des résultats sur le train :  0.8658600000000001\n",
      "Moyenne des résultats sur la val :  0.6229\n",
      "Mediane des résultat sur le train :  0.8658600000000001\n",
      "Mediane des résultat sur la val :  0.6229\n",
      "\n",
      "########### Models rsnet_maxpool_7_to_8_32 ###########\n",
      "(3, 26)\n",
      "Pire résultat sur le train :  0.6956\n",
      "Pire Résultat sur la val :  0.6314\n",
      "Meilleur résultat sur le train :  0.8873200000000001\n",
      "Meilleur résultat sur la val :  0.6757\n",
      "Moyenne des résultats sur le train :  0.8017733333333333\n",
      "Moyenne des résultats sur la val :  0.6585666666666666\n",
      "Mediane des résultat sur le train :  0.8224\n",
      "Mediane des résultat sur la val :  0.6686\n",
      "\n",
      "########### Models rsnet_maxpool_7_to_8_64 ###########\n",
      "(5, 26)\n",
      "Pire résultat sur le train :  0.74526\n",
      "Pire Résultat sur la val :  0.6358\n",
      "Meilleur résultat sur le train :  0.8501200000000001\n",
      "Meilleur résultat sur la val :  0.7121\n",
      "Moyenne des résultats sur le train :  0.802036\n",
      "Moyenne des résultats sur la val :  0.66716\n",
      "Mediane des résultat sur le train :  0.81004\n",
      "Mediane des résultat sur la val :  0.6511\n",
      "\n",
      "########### Models rsnet_maxpool_9_32 ###########\n",
      "(2, 26)\n",
      "Pire résultat sur le train :  0.62734\n",
      "Pire Résultat sur la val :  0.586\n",
      "Meilleur résultat sur le train :  0.64646\n",
      "Meilleur résultat sur la val :  0.6228\n",
      "Moyenne des résultats sur le train :  0.6369\n",
      "Moyenne des résultats sur la val :  0.6044\n",
      "Mediane des résultat sur le train :  0.6369\n",
      "Mediane des résultat sur la val :  0.6044\n",
      "\n",
      "########### Models rsnet_maxpool_9_64 ###########\n",
      "(1, 26)\n",
      "Pire résultat sur le train :  0.8421\n",
      "Pire Résultat sur la val :  0.6114\n",
      "Meilleur résultat sur le train :  0.8421\n",
      "Meilleur résultat sur la val :  0.6114\n",
      "Moyenne des résultats sur le train :  0.8421\n",
      "Moyenne des résultats sur la val :  0.6114\n",
      "Mediane des résultat sur le train :  0.8421\n",
      "Mediane des résultat sur la val :  0.6114\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(filtered_results_dataframes)):\n",
    "    filtered_history = filtered_results_dataframes[i]\n",
    "    filtered_history_desc = results_dataframes_desc[i]\n",
    "    print_statistics(filtered_history, filtered_history_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On fusionne tous les dataframes en une seule (étant donné qu'il y en a une par structure de modèle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = concat_list_of_dataframes(filtered_results_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models Rsnet_with_maxpool_regularisation ###########\n",
      "(16, 26)\n",
      "Pire résultat sur le train :  0.5791\n",
      "Pire Résultat sur la val :  0.5602\n",
      "Meilleur résultat sur le train :  0.8873200000000001\n",
      "Meilleur résultat sur la val :  0.7121\n",
      "Moyenne des résultats sur le train :  0.77987875\n",
      "Moyenne des résultats sur la val :  0.63400625\n",
      "Mediane des résultat sur le train :  0.8160700000000001\n",
      "Mediane des résultat sur la val :  0.62715\n"
     ]
    }
   ],
   "source": [
    "print_statistics(merged_df, \"Rsnet_with_maxpool_regularisation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models Best Rsnet Maxpool Regularisation models ###########\n",
      "(7, 26)\n",
      "Pire résultat sur le train :  0.74526\n",
      "Pire Résultat sur la val :  0.6358\n",
      "Meilleur résultat sur le train :  0.8873200000000001\n",
      "Meilleur résultat sur la val :  0.7121\n",
      "Moyenne des résultats sur le train :  0.8171285714285715\n",
      "Moyenne des résultats sur la val :  0.6685857142857142\n",
      "Mediane des résultat sur le train :  0.8221\n",
      "Mediane des résultat sur la val :  0.6686\n"
     ]
    }
   ],
   "source": [
    "best_val_models = filter_on_mean_val_accuracy([merged_df])[0]\n",
    "best_val_models = best_val_models.sort_values('val_accuracy', ascending=False)\n",
    "print_statistics(best_val_models, \"Best Rsnet Maxpool Regularisation models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_hidden_layers</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>layers_activation</th>\n",
       "      <th>output_activation</th>\n",
       "      <th>use_skip</th>\n",
       "      <th>nb_skip</th>\n",
       "      <th>use_dropout</th>\n",
       "      <th>...</th>\n",
       "      <th>regulization_indexes</th>\n",
       "      <th>loss</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>metrics</th>\n",
       "      <th>padding</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>dossier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>9851172</td>\n",
       "      <td>0.82210</td>\n",
       "      <td>0.7121</td>\n",
       "      <td>20200209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2 2 7</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>1250532</td>\n",
       "      <td>0.78266</td>\n",
       "      <td>0.6965</td>\n",
       "      <td>20200208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2 4</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>5097248</td>\n",
       "      <td>0.82240</td>\n",
       "      <td>0.6757</td>\n",
       "      <td>20200209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2 4</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>7628417</td>\n",
       "      <td>0.88732</td>\n",
       "      <td>0.6686</td>\n",
       "      <td>20200209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2 7</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>638853</td>\n",
       "      <td>0.74526</td>\n",
       "      <td>0.6511</td>\n",
       "      <td>20200209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>4 6</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>4666378</td>\n",
       "      <td>0.81004</td>\n",
       "      <td>0.6403</td>\n",
       "      <td>20200206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>4 6</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>2279421</td>\n",
       "      <td>0.85012</td>\n",
       "      <td>0.6358</td>\n",
       "      <td>20200206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_hidden_layers  filters kernel_size  batch_size input_shape  \\\n",
       "6                 7       64         3 3         128     32 32 3   \n",
       "2                 7       64         3 3         128     32 32 3   \n",
       "3                 7       32         3 3         128     32 32 3   \n",
       "2                 7       32         3 3         128     32 32 3   \n",
       "5                 7       64         3 3         128     32 32 3   \n",
       "3                 7       64         3 3         128     32 32 3   \n",
       "4                 7       64         3 3         128     32 32 3   \n",
       "\n",
       "  layers_activation output_activation  use_skip  nb_skip  use_dropout  ...  \\\n",
       "6              selu           softmax      True        2         True  ...   \n",
       "2              selu           softmax      True        2         True  ...   \n",
       "3              relu           softmax      True        2         True  ...   \n",
       "2              selu           softmax      True        2         True  ...   \n",
       "5              selu           softmax      True        2         True  ...   \n",
       "3              relu           softmax      True        2         True  ...   \n",
       "4              relu           softmax      True        2         True  ...   \n",
       "\n",
       "  regulization_indexes                      loss  optimizer  \\\n",
       "6                  NaN  categorical_crossentropy       Adam   \n",
       "2                2 2 7  categorical_crossentropy       Adam   \n",
       "3                  2 4  categorical_crossentropy       Adam   \n",
       "2                  2 4  categorical_crossentropy       Adam   \n",
       "5                  2 7  categorical_crossentropy       Adam   \n",
       "3                  4 6  categorical_crossentropy       Adam   \n",
       "4                  4 6  categorical_crossentropy       Adam   \n",
       "\n",
       "                metrics  padding  epochs model_id train_accuracy val_accuracy  \\\n",
       "6  categorical_accuracy     same      50  9851172        0.82210       0.7121   \n",
       "2  categorical_accuracy     same      50  1250532        0.78266       0.6965   \n",
       "3  categorical_accuracy     same      50  5097248        0.82240       0.6757   \n",
       "2  categorical_accuracy     same      50  7628417        0.88732       0.6686   \n",
       "5  categorical_accuracy     same      50   638853        0.74526       0.6511   \n",
       "3  categorical_accuracy     same      50  4666378        0.81004       0.6403   \n",
       "4  categorical_accuracy     same      50  2279421        0.85012       0.6358   \n",
       "\n",
       "    dossier  \n",
       "6  20200209  \n",
       "2  20200208  \n",
       "3  20200209  \n",
       "2  20200209  \n",
       "5  20200209  \n",
       "3  20200206  \n",
       "4  20200206  \n",
       "\n",
       "[7 rows x 26 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_models.to_csv(\"{}best_Rsnet_with_Maxpool_regularisation.csv\".format(root_csv_folder), sep=';',header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple  d'un Rsnet avec du Maxpooling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rsnet Maxpool](Rsnet_Maxpool.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L'image ci-dessous décrit l'evolution d'un Rsnet avec Maxpooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rsnet MaxPool Log](Rsnet_Maxpool_log.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effectivement avec le Maxpooling combiné avec de la regularisation (L1L2 et Dropout)  on est arrivé à de meilleurs résultats, soit une val accuracy près de 70%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maintenant on vas recupperer tous nos bests models (avec / sans regularisation, dropout, les deux ou maxpool), pour en sortir les meilleurs des meilleurs !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframes_list = []\n",
    "results_dataframes_desc = []\n",
    "root_csv_folder = \"..\\\\historique_tests\\\\\"\n",
    "\n",
    "\n",
    "# Rsnet best  without regularisation .\n",
    "df = pd.read_csv(\"{}best_Rsnet_without_regularisation.csv\".format(root_csv_folder), sep=\";\")\n",
    "results_dataframes_list.append(df)\n",
    "results_dataframes_desc.append(\"best_Rsnet_without_regularisation\")\n",
    "\n",
    "#Rsnet best with dropout regularisation.\n",
    "df = pd.read_csv(\"{}best_Rsnet_with_dropout_regularisation.csv\".format(root_csv_folder), sep=\";\")\n",
    "results_dataframes_list.append(df)\n",
    "results_dataframes_desc.append(\"best_Rsnet_with_dropout_regularisation\")\n",
    "\n",
    "#Rsnet best with L1L2 regularisation.\n",
    "df = pd.read_csv(\"{}best_Rsnet_with_L1L2_regularisation.csv\".format(root_csv_folder), sep=\";\")\n",
    "results_dataframes_list.append(df)\n",
    "results_dataframes_desc.append(\"best_Rsnet_with_L1L2_regularisation\")\n",
    "\n",
    "#Rsnet best with Dropout and L1L2 regularisation.\n",
    "df = pd.read_csv(\"{}best_Rsnet_with_Dropout_L1L2_regularisation.csv\".format(root_csv_folder), sep=\";\")\n",
    "results_dataframes_list.append(df)\n",
    "results_dataframes_desc.append(\"best_Rsnet_with_Dropout_L1L2_regularisation\")\n",
    "\n",
    "#Rsnet best with Maxpooling regularisation.\n",
    "df = pd.read_csv(\"{}best_Rsnet_with_Maxpool_regularisation.csv\".format(root_csv_folder), sep=\";\")\n",
    "results_dataframes_list.append(df)\n",
    "results_dataframes_desc.append(\"best_Rsnet_with_Maxpool_regularisation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models best_Rsnet_without_regularisation ###########\n",
      "(12, 26)\n",
      "Pire résultat sur le train :  0.7682\n",
      "Pire Résultat sur la val :  0.5387\n",
      "Meilleur résultat sur le train :  0.97862\n",
      "Meilleur résultat sur la val :  0.6023\n",
      "Moyenne des résultats sur le train :  0.9164833333333334\n",
      "Moyenne des résultats sur la val :  0.571975\n",
      "Mediane des résultat sur le train :  0.95653\n",
      "Mediane des résultat sur la val :  0.5767\n",
      "\n",
      "########### Models best_Rsnet_with_dropout_regularisation ###########\n",
      "(5, 26)\n",
      "Pire résultat sur le train :  0.85782\n",
      "Pire Résultat sur la val :  0.5601\n",
      "Meilleur résultat sur le train :  0.98716\n",
      "Meilleur résultat sur la val :  0.6014\n",
      "Moyenne des résultats sur le train :  0.9387239999999999\n",
      "Moyenne des résultats sur la val :  0.585\n",
      "Mediane des résultat sur le train :  0.96056\n",
      "Mediane des résultat sur la val :  0.5847\n",
      "\n",
      "########### Models best_Rsnet_with_L1L2_regularisation ###########\n",
      "(6, 26)\n",
      "Pire résultat sur le train :  0.43358\n",
      "Pire Résultat sur la val :  0.4288\n",
      "Meilleur résultat sur le train :  0.67912\n",
      "Meilleur résultat sur la val :  0.6259\n",
      "Moyenne des résultats sur le train :  0.5425833333333333\n",
      "Moyenne des résultats sur la val :  0.5190666666666667\n",
      "Mediane des résultat sur le train :  0.5432\n",
      "Mediane des résultat sur la val :  0.5182\n",
      "\n",
      "########### Models best_Rsnet_with_Dropout_L1L2_regularisation ###########\n",
      "(15, 26)\n",
      "Pire résultat sur le train :  0.54138\n",
      "Pire Résultat sur la val :  0.5274\n",
      "Meilleur résultat sur le train :  0.97076\n",
      "Meilleur résultat sur la val :  0.6512\n",
      "Moyenne des résultats sur le train :  0.762348\n",
      "Moyenne des résultats sur la val :  0.5899666666666668\n",
      "Mediane des résultat sur le train :  0.75864\n",
      "Mediane des résultat sur la val :  0.5894\n",
      "\n",
      "########### Models best_Rsnet_with_Maxpool_regularisation ###########\n",
      "(7, 26)\n",
      "Pire résultat sur le train :  0.74526\n",
      "Pire Résultat sur la val :  0.6358\n",
      "Meilleur résultat sur le train :  0.8873200000000001\n",
      "Meilleur résultat sur la val :  0.7121\n",
      "Moyenne des résultats sur le train :  0.8171285714285715\n",
      "Moyenne des résultats sur la val :  0.6685857142857142\n",
      "Mediane des résultat sur le train :  0.8221\n",
      "Mediane des résultat sur la val :  0.6686\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results_dataframes_list)):\n",
    "    history = results_dataframes_list[i]\n",
    "    history_desc = results_dataframes_desc[i]\n",
    "    print_statistics(history, history_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On ne garde que les modèles dont les résultats sur la validations sont supérieurs à la moyenne des résultats de tous les modèles (d'une même architecture) testés "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_results_dataframes = filter_on_mean_val_accuracy(results_dataframes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models best_Rsnet_without_regularisation ###########\n",
      "(6, 26)\n",
      "Pire résultat sur le train :  0.7682\n",
      "Pire Résultat sur la val :  0.5828\n",
      "Meilleur résultat sur le train :  0.97862\n",
      "Meilleur résultat sur la val :  0.6023\n",
      "Moyenne des résultats sur le train :  0.9066200000000002\n",
      "Moyenne des résultats sur la val :  0.5918666666666667\n",
      "Mediane des résultat sur le train :  0.9715\n",
      "Mediane des résultat sur la val :  0.5909500000000001\n",
      "\n",
      "########### Models best_Rsnet_with_dropout_regularisation ###########\n",
      "(2, 26)\n",
      "Pire résultat sur le train :  0.97288\n",
      "Pire Résultat sur la val :  0.5942\n",
      "Meilleur résultat sur le train :  0.98716\n",
      "Meilleur résultat sur la val :  0.6014\n",
      "Moyenne des résultats sur le train :  0.98002\n",
      "Moyenne des résultats sur la val :  0.5978\n",
      "Mediane des résultat sur le train :  0.98002\n",
      "Mediane des résultat sur la val :  0.5978\n",
      "\n",
      "########### Models best_Rsnet_with_L1L2_regularisation ###########\n",
      "(3, 26)\n",
      "Pire résultat sur le train :  0.60044\n",
      "Pire Résultat sur la val :  0.5635\n",
      "Meilleur résultat sur le train :  0.67912\n",
      "Meilleur résultat sur la val :  0.6259\n",
      "Moyenne des résultats sur le train :  0.63162\n",
      "Moyenne des résultats sur la val :  0.5923333333333334\n",
      "Mediane des résultat sur le train :  0.6153\n",
      "Mediane des résultat sur la val :  0.5876\n",
      "\n",
      "########### Models best_Rsnet_with_Dropout_L1L2_regularisation ###########\n",
      "(7, 26)\n",
      "Pire résultat sur le train :  0.71808\n",
      "Pire Résultat sur la val :  0.5905\n",
      "Meilleur résultat sur le train :  0.97076\n",
      "Meilleur résultat sur la val :  0.6512\n",
      "Moyenne des résultats sur le train :  0.7952314285714286\n",
      "Moyenne des résultats sur la val :  0.6246571428571429\n",
      "Mediane des résultat sur le train :  0.7611399999999999\n",
      "Mediane des résultat sur la val :  0.638\n",
      "\n",
      "########### Models best_Rsnet_with_Maxpool_regularisation ###########\n",
      "(4, 26)\n",
      "Pire résultat sur le train :  0.78266\n",
      "Pire Résultat sur la val :  0.6686\n",
      "Meilleur résultat sur le train :  0.8873200000000001\n",
      "Meilleur résultat sur la val :  0.7121\n",
      "Moyenne des résultats sur le train :  0.8286200000000001\n",
      "Moyenne des résultats sur la val :  0.688225\n",
      "Mediane des résultat sur le train :  0.82225\n",
      "Mediane des résultat sur la val :  0.6860999999999999\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(filtered_results_dataframes)):\n",
    "    filtered_history = filtered_results_dataframes[i]\n",
    "    filtered_history_desc = results_dataframes_desc[i]\n",
    "    print_statistics(filtered_history, filtered_history_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On fusionne tous les dataframes en une seule (étant donné qu'il y en a une par structure de modèle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = concat_list_of_dataframes(filtered_results_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models Best_Rsnet ###########\n",
      "(22, 26)\n",
      "Pire résultat sur le train :  0.60044\n",
      "Pire Résultat sur la val :  0.5635\n",
      "Meilleur résultat sur le train :  0.98716\n",
      "Meilleur résultat sur la val :  0.7121\n",
      "Moyenne des résultats sur le train :  0.826169090909091\n",
      "Moyenne des résultats sur la val :  0.6204227272727274\n",
      "Mediane des résultat sur le train :  0.8023800000000001\n",
      "Mediane des résultat sur la val :  0.60185\n"
     ]
    }
   ],
   "source": [
    "print_statistics(merged_df, \"Best_Rsnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models Best Rsnet Maxpool Regularisation models ###########\n",
      "(9, 26)\n",
      "Pire résultat sur le train :  0.67912\n",
      "Pire Résultat sur la val :  0.6259\n",
      "Meilleur résultat sur le train :  0.8873200000000001\n",
      "Meilleur résultat sur la val :  0.7121\n",
      "Moyenne des résultats sur le train :  0.7932200000000001\n",
      "Moyenne des résultats sur la val :  0.661111111111111\n",
      "Mediane des résultat sur le train :  0.78266\n",
      "Mediane des résultat sur la val :  0.6512\n"
     ]
    }
   ],
   "source": [
    "best_val_models = filter_on_mean_val_accuracy([merged_df])[0]\n",
    "best_val_models = best_val_models.sort_values('val_accuracy', ascending=False)\n",
    "print_statistics(best_val_models, \"Best Rsnet Maxpool Regularisation models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_hidden_layers</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>layers_activation</th>\n",
       "      <th>output_activation</th>\n",
       "      <th>use_skip</th>\n",
       "      <th>nb_skip</th>\n",
       "      <th>use_dropout</th>\n",
       "      <th>...</th>\n",
       "      <th>regulization_indexes</th>\n",
       "      <th>loss</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>metrics</th>\n",
       "      <th>padding</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>dossier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>9851172</td>\n",
       "      <td>0.82210</td>\n",
       "      <td>0.7121</td>\n",
       "      <td>20200209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2 2 7</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>1250532</td>\n",
       "      <td>0.78266</td>\n",
       "      <td>0.6965</td>\n",
       "      <td>20200208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2 4</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>5097248</td>\n",
       "      <td>0.82240</td>\n",
       "      <td>0.6757</td>\n",
       "      <td>20200209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2 4</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>7628417</td>\n",
       "      <td>0.88732</td>\n",
       "      <td>0.6686</td>\n",
       "      <td>20200209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2 4</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>45286</td>\n",
       "      <td>0.87504</td>\n",
       "      <td>0.6512</td>\n",
       "      <td>20200209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>2599981</td>\n",
       "      <td>0.76114</td>\n",
       "      <td>0.6438</td>\n",
       "      <td>20200203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>7171554</td>\n",
       "      <td>0.77956</td>\n",
       "      <td>0.6382</td>\n",
       "      <td>20200203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>3 6</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>4893841</td>\n",
       "      <td>0.72964</td>\n",
       "      <td>0.6380</td>\n",
       "      <td>20200202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>128</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>50</td>\n",
       "      <td>1477028</td>\n",
       "      <td>0.67912</td>\n",
       "      <td>0.6259</td>\n",
       "      <td>20200209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_hidden_layers  filters kernel_size  batch_size input_shape  \\\n",
       "0                 7       64         3 3         128     32 32 3   \n",
       "1                 7       64         3 3         128     32 32 3   \n",
       "2                 7       32         3 3         128     32 32 3   \n",
       "3                 7       32         3 3         128     32 32 3   \n",
       "0                 8       64         3 3         128     32 32 3   \n",
       "1                 6      128         3 3         128     32 32 3   \n",
       "2                 6      128         3 3         128     32 32 3   \n",
       "3                 6      128         3 3         128     32 32 3   \n",
       "0                 8       32         3 3         128     32 32 3   \n",
       "\n",
       "  layers_activation output_activation  use_skip  nb_skip  use_dropout  ...  \\\n",
       "0              selu           softmax      True        2         True  ...   \n",
       "1              selu           softmax      True        2         True  ...   \n",
       "2              relu           softmax      True        2         True  ...   \n",
       "3              selu           softmax      True        2         True  ...   \n",
       "0              relu           softmax      True        2         True  ...   \n",
       "1              relu           softmax      True        2         True  ...   \n",
       "2              relu           softmax      True        2         True  ...   \n",
       "3              relu           softmax      True        2         True  ...   \n",
       "0              relu           softmax      True        2        False  ...   \n",
       "\n",
       "  regulization_indexes                      loss  optimizer  \\\n",
       "0                  NaN  categorical_crossentropy       Adam   \n",
       "1                2 2 7  categorical_crossentropy       Adam   \n",
       "2                  2 4  categorical_crossentropy       Adam   \n",
       "3                  2 4  categorical_crossentropy       Adam   \n",
       "0                  2 4  categorical_crossentropy       Adam   \n",
       "1                    2  categorical_crossentropy       Adam   \n",
       "2                    2  categorical_crossentropy       Adam   \n",
       "3                  3 6  categorical_crossentropy       Adam   \n",
       "0                    5  categorical_crossentropy       Adam   \n",
       "\n",
       "                metrics  padding  epochs model_id train_accuracy val_accuracy  \\\n",
       "0  categorical_accuracy     same      50  9851172        0.82210       0.7121   \n",
       "1  categorical_accuracy     same      50  1250532        0.78266       0.6965   \n",
       "2  categorical_accuracy     same      50  5097248        0.82240       0.6757   \n",
       "3  categorical_accuracy     same      50  7628417        0.88732       0.6686   \n",
       "0  categorical_accuracy     same      50    45286        0.87504       0.6512   \n",
       "1  categorical_accuracy     same      50  2599981        0.76114       0.6438   \n",
       "2  categorical_accuracy     same      50  7171554        0.77956       0.6382   \n",
       "3  categorical_accuracy     same      50  4893841        0.72964       0.6380   \n",
       "0  categorical_accuracy     same      50  1477028        0.67912       0.6259   \n",
       "\n",
       "    dossier  \n",
       "0  20200209  \n",
       "1  20200208  \n",
       "2  20200209  \n",
       "3  20200209  \n",
       "0  20200209  \n",
       "1  20200203  \n",
       "2  20200203  \n",
       "3  20200202  \n",
       "0  20200209  \n",
       "\n",
       "[9 rows x 26 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_models.to_csv(\"{}best_Rsnet_last.csv\".format(root_csv_folder), sep=';',header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ci-dessous notre meilleurs modèle obtenu  Est le premier modèle dans le classement ci-dessus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion RSNET:\n",
    "\n",
    "### Résumé de résultats obtenus:\n",
    "\n",
    "#### Sur les premiers tests réalisés, on a obtenue un max val de 60% mais avec beaucoup d'overfiting, ensuite grâce aux techniques de régularisation on a pu résoudre tant bien que mal le problème de l'overfiting (bien entendu en ajustant nos tests après chaque resultats obtenus) c'est ainsi qu'on est arrivé vers les 64% avec un overfiting moins important. Puis, en vue du non évolutivité de la val accuracy, on a testé nos modèles avec du MaxPooling combiné avec de la L1L2 et du Dropout. Chose qui s'est avéré très fructueuse en vue de l'augmentation de la val acccuray qui avoisine maintenant les 71%.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
