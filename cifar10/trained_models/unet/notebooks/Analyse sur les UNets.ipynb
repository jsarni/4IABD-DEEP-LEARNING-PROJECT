{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des resultats des test de différentes structures de UNets sur le dataset Cifar-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;Dans ce notebook, nous allons analyser les resultats obtenus sur les tests de différentes structures et hyperparametres de UNets. Nous avons mené des tests pour des UNets de tailles variants entre 3 et 11 couches cahchées de type Conv2D (le modèle à 11 couches étant le plus gros qu'on ai pu tester), en plus des différentes couches qu'on aurait ajouté pour étudier leurs effet (Maxpool, dropout etc..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation des outils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNets Sans régularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests réalisés :\n",
    "&emsp;Pour ces premiers tests, nous avons testé des modèles de UNets constitués de la manière suivante:\n",
    "        - Tailles de 3 à 11 couches cachées\n",
    "        - Tests avec un nombre d'epochs fixe (40 epochs)\n",
    "        - Pas de régularisation\n",
    "        - Différentes fonctions d'activation pour les couches cachées (relu, selu, softmax, softplus)\n",
    "        - Différentes couches de connexion pour créer la structure UNet (Layers de type Average, Add) \n",
    "        \n",
    "        \n",
    "&emsp;Nous avons ensuite enregistré les résultats obtenus dans des fichiers CSV, en plus des logs générés par tensorflow, pour étudier les résultats obtenus.\n",
    "    \n",
    "&emsp;Nous allons donc charger ces statistiques et voir ce que ce genre de modèles peut donner sur le Dataset v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des résultats obtenus sur les modèles avec des couches Average et Avec couche Add:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_csv_folder = \"..\\\\historique_tests\\\\\"\n",
    "\n",
    "results_unet_avg = pd.read_csv(\"{}tested_unet_history.csv\".format(root_csv_folder), sep=\";\")\n",
    "results_unet_avg = results_unet_avg.sort_values(\"accuracy_val\",ascending=False)\n",
    "\n",
    "results_unet_add = pd.read_csv(\"{}tested_unet_add_history.csv\".format(root_csv_folder), sep=\";\")\n",
    "results_unet_add = results_unet_add.sort_values(\"accuracy_val\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affichage et premiere analyse des résultats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_couches</th>\n",
       "      <th>filter</th>\n",
       "      <th>kernel</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>activation_couches</th>\n",
       "      <th>activation_output</th>\n",
       "      <th>maxpool</th>\n",
       "      <th>indexes_maxpool</th>\n",
       "      <th>dropout</th>\n",
       "      <th>indexes_dropout</th>\n",
       "      <th>...</th>\n",
       "      <th>indexes_l1l2</th>\n",
       "      <th>loss</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>metrics</th>\n",
       "      <th>padding</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model_id</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_val</th>\n",
       "      <th>dossier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>7318436</td>\n",
       "      <td>0.95690</td>\n",
       "      <td>0.6059</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>3928073</td>\n",
       "      <td>0.95738</td>\n",
       "      <td>0.5968</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>6067132</td>\n",
       "      <td>0.95094</td>\n",
       "      <td>0.5963</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>5525695</td>\n",
       "      <td>0.87162</td>\n",
       "      <td>0.5948</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>3589055</td>\n",
       "      <td>0.94418</td>\n",
       "      <td>0.5925</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>7451129</td>\n",
       "      <td>0.81018</td>\n",
       "      <td>0.5919</td>\n",
       "      <td>20200125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>6561474</td>\n",
       "      <td>0.92546</td>\n",
       "      <td>0.5890</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>1185352</td>\n",
       "      <td>0.88028</td>\n",
       "      <td>0.5861</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>3482495</td>\n",
       "      <td>0.87388</td>\n",
       "      <td>0.5849</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>3710044</td>\n",
       "      <td>0.84126</td>\n",
       "      <td>0.5801</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>9058613</td>\n",
       "      <td>0.85294</td>\n",
       "      <td>0.5792</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>7982485</td>\n",
       "      <td>0.95870</td>\n",
       "      <td>0.5772</td>\n",
       "      <td>20200125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>8474210</td>\n",
       "      <td>0.82866</td>\n",
       "      <td>0.5736</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>4738072</td>\n",
       "      <td>0.97144</td>\n",
       "      <td>0.5718</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>3979387</td>\n",
       "      <td>0.98030</td>\n",
       "      <td>0.5265</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>8739752</td>\n",
       "      <td>0.97328</td>\n",
       "      <td>0.5216</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>2367066</td>\n",
       "      <td>0.97968</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>1360206</td>\n",
       "      <td>0.99472</td>\n",
       "      <td>0.5091</td>\n",
       "      <td>20200125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>2466510</td>\n",
       "      <td>0.98460</td>\n",
       "      <td>0.4986</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>5408600</td>\n",
       "      <td>0.88544</td>\n",
       "      <td>0.4888</td>\n",
       "      <td>20200125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>401271</td>\n",
       "      <td>0.96422</td>\n",
       "      <td>0.4886</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>9317203</td>\n",
       "      <td>0.95512</td>\n",
       "      <td>0.4788</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>5089488</td>\n",
       "      <td>0.92638</td>\n",
       "      <td>0.4552</td>\n",
       "      <td>20200125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_couches filter  kernel input_shape activation_couches  \\\n",
       "9           32    3 3      32     32 32 3               selu   \n",
       "11          32    3 3      32     32 32 3               selu   \n",
       "11          32    3 3      32     32 32 3               selu   \n",
       "9           32    3 3      32     32 32 3            softmax   \n",
       "9           32    3 3      32     32 32 3               selu   \n",
       "3           32    3 3      32     32 32 3            softmax   \n",
       "7           32    3 3      32     32 32 3               selu   \n",
       "5           32    3 3      32     32 32 3            softmax   \n",
       "9           32    3 3      32     32 32 3            softmax   \n",
       "9           32    3 3      32     32 32 3            softmax   \n",
       "9           32    3 3      32     32 32 3            softmax   \n",
       "5           32    3 3      32     32 32 3               selu   \n",
       "9           32    3 3      32     32 32 3            softmax   \n",
       "11          32    3 3      32     32 32 3            softmax   \n",
       "7           32    3 3      32     32 32 3           softplus   \n",
       "9           32    3 3      32     32 32 3               relu   \n",
       "11          32    3 3      32     32 32 3           softplus   \n",
       "3           32    3 3      32     32 32 3           softplus   \n",
       "7           32    3 3      32     32 32 3               relu   \n",
       "5           32    3 3      32     32 32 3               relu   \n",
       "9           32    3 3      32     32 32 3               relu   \n",
       "5           32    3 3      32     32 32 3           softplus   \n",
       "3           32    3 3      32     32 32 3               relu   \n",
       "\n",
       "   activation_output  maxpool  indexes_maxpool  dropout  indexes_dropout  ...  \\\n",
       "9            softmax    False              NaN    False              NaN  ...   \n",
       "11           softmax    False              NaN    False              NaN  ...   \n",
       "11           softmax    False              NaN    False              NaN  ...   \n",
       "9            softmax    False              NaN    False              NaN  ...   \n",
       "9            softmax    False              NaN    False              NaN  ...   \n",
       "3            softmax    False              NaN    False              NaN  ...   \n",
       "7            softmax    False              NaN    False              NaN  ...   \n",
       "5            softmax    False              NaN    False              NaN  ...   \n",
       "9            softmax    False              NaN    False              NaN  ...   \n",
       "9            softmax    False              NaN    False              NaN  ...   \n",
       "9            softmax    False              NaN    False              NaN  ...   \n",
       "5            softmax    False              NaN    False              NaN  ...   \n",
       "9            softmax    False              NaN    False              NaN  ...   \n",
       "11           softmax    False              NaN    False              NaN  ...   \n",
       "7            softmax    False              NaN    False              NaN  ...   \n",
       "9            softmax    False              NaN    False              NaN  ...   \n",
       "11           softmax    False              NaN    False              NaN  ...   \n",
       "3            softmax    False              NaN    False              NaN  ...   \n",
       "7            softmax    False              NaN    False              NaN  ...   \n",
       "5            softmax    False              NaN    False              NaN  ...   \n",
       "9            softmax    False              NaN    False              NaN  ...   \n",
       "5            softmax    False              NaN    False              NaN  ...   \n",
       "3            softmax    False              NaN    False              NaN  ...   \n",
       "\n",
       "    indexes_l1l2                             loss  optimizer  \\\n",
       "9            NaN  sparse_categorical_crossentropy       Adam   \n",
       "11           NaN  sparse_categorical_crossentropy       Adam   \n",
       "11           NaN  sparse_categorical_crossentropy       Adam   \n",
       "9            NaN  sparse_categorical_crossentropy       Adam   \n",
       "9            NaN  sparse_categorical_crossentropy       Adam   \n",
       "3            NaN  sparse_categorical_crossentropy       Adam   \n",
       "7            NaN  sparse_categorical_crossentropy       Adam   \n",
       "5            NaN  sparse_categorical_crossentropy       Adam   \n",
       "9            NaN  sparse_categorical_crossentropy       Adam   \n",
       "9            NaN  sparse_categorical_crossentropy       Adam   \n",
       "9            NaN  sparse_categorical_crossentropy       Adam   \n",
       "5            NaN  sparse_categorical_crossentropy       Adam   \n",
       "9            NaN  sparse_categorical_crossentropy       Adam   \n",
       "11           NaN  sparse_categorical_crossentropy       Adam   \n",
       "7            NaN  sparse_categorical_crossentropy       Adam   \n",
       "9            NaN  sparse_categorical_crossentropy       Adam   \n",
       "11           NaN  sparse_categorical_crossentropy       Adam   \n",
       "3            NaN  sparse_categorical_crossentropy       Adam   \n",
       "7            NaN  sparse_categorical_crossentropy       Adam   \n",
       "5            NaN  sparse_categorical_crossentropy       Adam   \n",
       "9            NaN  sparse_categorical_crossentropy       Adam   \n",
       "5            NaN  sparse_categorical_crossentropy       Adam   \n",
       "3            NaN  sparse_categorical_crossentropy       Adam   \n",
       "\n",
       "                        metrics  padding  epochs model_id accuracy_train  \\\n",
       "9   sparse_categorical_accuracy     same      40  7318436        0.95690   \n",
       "11  sparse_categorical_accuracy     same      40  3928073        0.95738   \n",
       "11  sparse_categorical_accuracy     same      40  6067132        0.95094   \n",
       "9   sparse_categorical_accuracy     same      40  5525695        0.87162   \n",
       "9   sparse_categorical_accuracy     same      40  3589055        0.94418   \n",
       "3   sparse_categorical_accuracy     same      40  7451129        0.81018   \n",
       "7   sparse_categorical_accuracy     same      40  6561474        0.92546   \n",
       "5   sparse_categorical_accuracy     same      40  1185352        0.88028   \n",
       "9   sparse_categorical_accuracy     same      40  3482495        0.87388   \n",
       "9   sparse_categorical_accuracy     same      40  3710044        0.84126   \n",
       "9   sparse_categorical_accuracy     same      40  9058613        0.85294   \n",
       "5   sparse_categorical_accuracy     same      40  7982485        0.95870   \n",
       "9   sparse_categorical_accuracy     same      40  8474210        0.82866   \n",
       "11  sparse_categorical_accuracy     same      40  4738072        0.97144   \n",
       "7   sparse_categorical_accuracy     same      40  3979387        0.98030   \n",
       "9   sparse_categorical_accuracy     same      40  8739752        0.97328   \n",
       "11  sparse_categorical_accuracy     same      40  2367066        0.97968   \n",
       "3   sparse_categorical_accuracy     same      40  1360206        0.99472   \n",
       "7   sparse_categorical_accuracy     same      40  2466510        0.98460   \n",
       "5   sparse_categorical_accuracy     same      40  5408600        0.88544   \n",
       "9   sparse_categorical_accuracy     same      40   401271        0.96422   \n",
       "5   sparse_categorical_accuracy     same      40  9317203        0.95512   \n",
       "3   sparse_categorical_accuracy     same      40  5089488        0.92638   \n",
       "\n",
       "   accuracy_val   dossier  \n",
       "9        0.6059  20200126  \n",
       "11       0.5968  20200127  \n",
       "11       0.5963  20200127  \n",
       "9        0.5948  20200126  \n",
       "9        0.5925  20200127  \n",
       "3        0.5919  20200125  \n",
       "7        0.5890  20200126  \n",
       "5        0.5861  20200126  \n",
       "9        0.5849  20200126  \n",
       "9        0.5801  20200126  \n",
       "9        0.5792  20200127  \n",
       "5        0.5772  20200125  \n",
       "9        0.5736  20200127  \n",
       "11       0.5718  20200127  \n",
       "7        0.5265  20200126  \n",
       "9        0.5216  20200126  \n",
       "11       0.5150  20200126  \n",
       "3        0.5091  20200125  \n",
       "7        0.4986  20200126  \n",
       "5        0.4888  20200125  \n",
       "9        0.4886  20200126  \n",
       "5        0.4788  20200126  \n",
       "3        0.4552  20200125  \n",
       "\n",
       "[23 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_couches</th>\n",
       "      <th>filter</th>\n",
       "      <th>kernel</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>activation_couches</th>\n",
       "      <th>activation_output</th>\n",
       "      <th>maxpool</th>\n",
       "      <th>indexes_maxpool</th>\n",
       "      <th>dropout</th>\n",
       "      <th>indexes_dropout</th>\n",
       "      <th>...</th>\n",
       "      <th>indexes_l1l2</th>\n",
       "      <th>loss</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>metrics</th>\n",
       "      <th>padding</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model_id</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_val</th>\n",
       "      <th>dossier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>3568266</td>\n",
       "      <td>0.95096</td>\n",
       "      <td>0.5813</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>9230533</td>\n",
       "      <td>0.99646</td>\n",
       "      <td>0.5705</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>3696804</td>\n",
       "      <td>0.95534</td>\n",
       "      <td>0.5675</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>7915611</td>\n",
       "      <td>0.89546</td>\n",
       "      <td>0.5388</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>1500229</td>\n",
       "      <td>0.97280</td>\n",
       "      <td>0.5059</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>3978437</td>\n",
       "      <td>0.96484</td>\n",
       "      <td>0.4805</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>160055</td>\n",
       "      <td>0.96818</td>\n",
       "      <td>0.4721</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>3005369</td>\n",
       "      <td>0.95494</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>6522794</td>\n",
       "      <td>0.94068</td>\n",
       "      <td>0.4586</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>485416</td>\n",
       "      <td>0.95150</td>\n",
       "      <td>0.4330</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_couches filter  kernel input_shape activation_couches activation_output  \\\n",
       "7          32    3 3      32     32 32 3               selu           softmax   \n",
       "9          32    3 3      32     32 32 3            softmax           softmax   \n",
       "3          32    3 3      32     32 32 3            softmax           softmax   \n",
       "3          32    3 3      32     32 32 3               selu           softmax   \n",
       "7          32    3 3      32     32 32 3           softplus           softmax   \n",
       "5          32    3 3      32     32 32 3           softplus           softmax   \n",
       "5          32    3 3      32     32 32 3           softplus           softmax   \n",
       "5          32    3 3      32     32 32 3               relu           softmax   \n",
       "7          32    3 3      32     32 32 3               relu           softmax   \n",
       "3          32    3 3      32     32 32 3           softplus           softmax   \n",
       "\n",
       "   maxpool  indexes_maxpool  dropout  indexes_dropout  ...  indexes_l1l2  \\\n",
       "7    False              NaN    False              NaN  ...           NaN   \n",
       "9    False              NaN    False              NaN  ...           NaN   \n",
       "3    False              NaN    False              NaN  ...           NaN   \n",
       "3    False              NaN    False              NaN  ...           NaN   \n",
       "7    False              NaN    False              NaN  ...           NaN   \n",
       "5    False              NaN    False              NaN  ...           NaN   \n",
       "5    False              NaN    False              NaN  ...           NaN   \n",
       "5    False              NaN    False              NaN  ...           NaN   \n",
       "7    False              NaN    False              NaN  ...           NaN   \n",
       "3    False              NaN    False              NaN  ...           NaN   \n",
       "\n",
       "                              loss  optimizer                      metrics  \\\n",
       "7  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "9  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "7  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "5  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "5  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "5  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "7  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "\n",
       "   padding  epochs model_id accuracy_train accuracy_val   dossier  \n",
       "7     same      40  3568266        0.95096       0.5813  20200126  \n",
       "9     same      40  9230533        0.99646       0.5705  20200126  \n",
       "3     same      40  3696804        0.95534       0.5675  20200126  \n",
       "3     same      40  7915611        0.89546       0.5388  20200126  \n",
       "7     same      40  1500229        0.97280       0.5059  20200126  \n",
       "5     same      40  3978437        0.96484       0.4805  20200126  \n",
       "5     same      40   160055        0.96818       0.4721  20200126  \n",
       "5     same      40  3005369        0.95494       0.4609  20200126  \n",
       "7     same      40  6522794        0.94068       0.4586  20200126  \n",
       "3     same      40   485416        0.95150       0.4330  20200126  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results_unet_avg)\n",
    "display(results_unet_add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Premières Constatations:\n",
    "&emsp;La première constatation qu'on peut faire, c'est que les résultats obtenus avec les fonctions d'activation \"relu\" et \"softplus\", que ce soit sur les modèles avec des couches Average ou des couches Add, ne sont pas très intéressantes comparées au fonctions \"selu\" et \"softplus\": pour les deux première des résultats qui tournent autours des 50% sur la validation, contre 58% environs sur les deux dernières.\n",
    "    \n",
    "&emsp;Nous allons donc nous focaliser sur les fonctions d'activation \"softplus\" et \"selu\" dans nos prochains tests et analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_couches</th>\n",
       "      <th>filter</th>\n",
       "      <th>kernel</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>activation_couches</th>\n",
       "      <th>activation_output</th>\n",
       "      <th>maxpool</th>\n",
       "      <th>indexes_maxpool</th>\n",
       "      <th>dropout</th>\n",
       "      <th>indexes_dropout</th>\n",
       "      <th>...</th>\n",
       "      <th>indexes_l1l2</th>\n",
       "      <th>loss</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>metrics</th>\n",
       "      <th>padding</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model_id</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_val</th>\n",
       "      <th>dossier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>3568266</td>\n",
       "      <td>0.95096</td>\n",
       "      <td>0.5813</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>7915611</td>\n",
       "      <td>0.89546</td>\n",
       "      <td>0.5388</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>1500229</td>\n",
       "      <td>0.97280</td>\n",
       "      <td>0.5059</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>3978437</td>\n",
       "      <td>0.96484</td>\n",
       "      <td>0.4805</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>160055</td>\n",
       "      <td>0.96818</td>\n",
       "      <td>0.4721</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>485416</td>\n",
       "      <td>0.95150</td>\n",
       "      <td>0.4330</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_couches filter  kernel input_shape activation_couches activation_output  \\\n",
       "7          32    3 3      32     32 32 3               selu           softmax   \n",
       "3          32    3 3      32     32 32 3               selu           softmax   \n",
       "7          32    3 3      32     32 32 3           softplus           softmax   \n",
       "5          32    3 3      32     32 32 3           softplus           softmax   \n",
       "5          32    3 3      32     32 32 3           softplus           softmax   \n",
       "3          32    3 3      32     32 32 3           softplus           softmax   \n",
       "\n",
       "   maxpool  indexes_maxpool  dropout  indexes_dropout  ...  indexes_l1l2  \\\n",
       "7    False              NaN    False              NaN  ...           NaN   \n",
       "3    False              NaN    False              NaN  ...           NaN   \n",
       "7    False              NaN    False              NaN  ...           NaN   \n",
       "5    False              NaN    False              NaN  ...           NaN   \n",
       "5    False              NaN    False              NaN  ...           NaN   \n",
       "3    False              NaN    False              NaN  ...           NaN   \n",
       "\n",
       "                              loss  optimizer                      metrics  \\\n",
       "7  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "7  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "5  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "5  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "\n",
       "   padding  epochs model_id accuracy_train accuracy_val   dossier  \n",
       "7     same      40  3568266        0.95096       0.5813  20200126  \n",
       "3     same      40  7915611        0.89546       0.5388  20200126  \n",
       "7     same      40  1500229        0.97280       0.5059  20200126  \n",
       "5     same      40  3978437        0.96484       0.4805  20200126  \n",
       "5     same      40   160055        0.96818       0.4721  20200126  \n",
       "3     same      40   485416        0.95150       0.4330  20200126  \n",
       "\n",
       "[6 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_couches</th>\n",
       "      <th>filter</th>\n",
       "      <th>kernel</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>activation_couches</th>\n",
       "      <th>activation_output</th>\n",
       "      <th>maxpool</th>\n",
       "      <th>indexes_maxpool</th>\n",
       "      <th>dropout</th>\n",
       "      <th>indexes_dropout</th>\n",
       "      <th>...</th>\n",
       "      <th>indexes_l1l2</th>\n",
       "      <th>loss</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>metrics</th>\n",
       "      <th>padding</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model_id</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_val</th>\n",
       "      <th>dossier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>7318436</td>\n",
       "      <td>0.95690</td>\n",
       "      <td>0.6059</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>3928073</td>\n",
       "      <td>0.95738</td>\n",
       "      <td>0.5968</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>6067132</td>\n",
       "      <td>0.95094</td>\n",
       "      <td>0.5963</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>3589055</td>\n",
       "      <td>0.94418</td>\n",
       "      <td>0.5925</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>6561474</td>\n",
       "      <td>0.92546</td>\n",
       "      <td>0.5890</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>7982485</td>\n",
       "      <td>0.95870</td>\n",
       "      <td>0.5772</td>\n",
       "      <td>20200125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>3979387</td>\n",
       "      <td>0.98030</td>\n",
       "      <td>0.5265</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>2367066</td>\n",
       "      <td>0.97968</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>1360206</td>\n",
       "      <td>0.99472</td>\n",
       "      <td>0.5091</td>\n",
       "      <td>20200125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>9317203</td>\n",
       "      <td>0.95512</td>\n",
       "      <td>0.4788</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_couches filter  kernel input_shape activation_couches  \\\n",
       "9           32    3 3      32     32 32 3               selu   \n",
       "11          32    3 3      32     32 32 3               selu   \n",
       "11          32    3 3      32     32 32 3               selu   \n",
       "9           32    3 3      32     32 32 3               selu   \n",
       "7           32    3 3      32     32 32 3               selu   \n",
       "5           32    3 3      32     32 32 3               selu   \n",
       "7           32    3 3      32     32 32 3           softplus   \n",
       "11          32    3 3      32     32 32 3           softplus   \n",
       "3           32    3 3      32     32 32 3           softplus   \n",
       "5           32    3 3      32     32 32 3           softplus   \n",
       "\n",
       "   activation_output  maxpool  indexes_maxpool  dropout  indexes_dropout  ...  \\\n",
       "9            softmax    False              NaN    False              NaN  ...   \n",
       "11           softmax    False              NaN    False              NaN  ...   \n",
       "11           softmax    False              NaN    False              NaN  ...   \n",
       "9            softmax    False              NaN    False              NaN  ...   \n",
       "7            softmax    False              NaN    False              NaN  ...   \n",
       "5            softmax    False              NaN    False              NaN  ...   \n",
       "7            softmax    False              NaN    False              NaN  ...   \n",
       "11           softmax    False              NaN    False              NaN  ...   \n",
       "3            softmax    False              NaN    False              NaN  ...   \n",
       "5            softmax    False              NaN    False              NaN  ...   \n",
       "\n",
       "    indexes_l1l2                             loss  optimizer  \\\n",
       "9            NaN  sparse_categorical_crossentropy       Adam   \n",
       "11           NaN  sparse_categorical_crossentropy       Adam   \n",
       "11           NaN  sparse_categorical_crossentropy       Adam   \n",
       "9            NaN  sparse_categorical_crossentropy       Adam   \n",
       "7            NaN  sparse_categorical_crossentropy       Adam   \n",
       "5            NaN  sparse_categorical_crossentropy       Adam   \n",
       "7            NaN  sparse_categorical_crossentropy       Adam   \n",
       "11           NaN  sparse_categorical_crossentropy       Adam   \n",
       "3            NaN  sparse_categorical_crossentropy       Adam   \n",
       "5            NaN  sparse_categorical_crossentropy       Adam   \n",
       "\n",
       "                        metrics  padding  epochs model_id accuracy_train  \\\n",
       "9   sparse_categorical_accuracy     same      40  7318436        0.95690   \n",
       "11  sparse_categorical_accuracy     same      40  3928073        0.95738   \n",
       "11  sparse_categorical_accuracy     same      40  6067132        0.95094   \n",
       "9   sparse_categorical_accuracy     same      40  3589055        0.94418   \n",
       "7   sparse_categorical_accuracy     same      40  6561474        0.92546   \n",
       "5   sparse_categorical_accuracy     same      40  7982485        0.95870   \n",
       "7   sparse_categorical_accuracy     same      40  3979387        0.98030   \n",
       "11  sparse_categorical_accuracy     same      40  2367066        0.97968   \n",
       "3   sparse_categorical_accuracy     same      40  1360206        0.99472   \n",
       "5   sparse_categorical_accuracy     same      40  9317203        0.95512   \n",
       "\n",
       "   accuracy_val   dossier  \n",
       "9        0.6059  20200126  \n",
       "11       0.5968  20200127  \n",
       "11       0.5963  20200127  \n",
       "9        0.5925  20200127  \n",
       "7        0.5890  20200126  \n",
       "5        0.5772  20200125  \n",
       "7        0.5265  20200126  \n",
       "11       0.5150  20200126  \n",
       "3        0.5091  20200125  \n",
       "5        0.4788  20200126  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filtre sur les fonctions d'activation et affichage des resultats\n",
    "results_unet_avg = results_unet_avg[results_unet_avg.activation_couches.isin([\"selu\", \"softplus\"])]\n",
    "results_unet_add = results_unet_add[results_unet_add.activation_couches.isin([\"selu\", \"softplus\"])]\n",
    "\n",
    "display(results_unet_add)\n",
    "display(results_unet_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deuxièmes Constatations:\n",
    "&emsp;Ici, on peut faire deux constations de plus:\n",
    "\n",
    "&emsp;- En comparant les résultats obtenus pour les modèles utilisant des couches Average et des modèles avec des couches Add, on se rend compte que le premier type de modèles est bien plus interessants que le deuxième en terme de résultats (avec des \n",
    "add, on tourne autours des 50% sur la validation, contre près de 60% avec des Average.\n",
    "\n",
    "&emsp;- En remarque aussi que les meilleurs modèles sont ceux qui utilisent la fonction d'activation \"selu\".\n",
    "    \n",
    "&emsp;Nous allons donc continuer les tests sur des modèles utilisant des couches Average et la fonction d'activation \"selu\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_couches</th>\n",
       "      <th>filter</th>\n",
       "      <th>kernel</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>activation_couches</th>\n",
       "      <th>activation_output</th>\n",
       "      <th>maxpool</th>\n",
       "      <th>indexes_maxpool</th>\n",
       "      <th>dropout</th>\n",
       "      <th>indexes_dropout</th>\n",
       "      <th>...</th>\n",
       "      <th>indexes_l1l2</th>\n",
       "      <th>loss</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>metrics</th>\n",
       "      <th>padding</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model_id</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_val</th>\n",
       "      <th>dossier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>7318436</td>\n",
       "      <td>0.95690</td>\n",
       "      <td>0.6059</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>3928073</td>\n",
       "      <td>0.95738</td>\n",
       "      <td>0.5968</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>6067132</td>\n",
       "      <td>0.95094</td>\n",
       "      <td>0.5963</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>3589055</td>\n",
       "      <td>0.94418</td>\n",
       "      <td>0.5925</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>6561474</td>\n",
       "      <td>0.92546</td>\n",
       "      <td>0.5890</td>\n",
       "      <td>20200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>7982485</td>\n",
       "      <td>0.95870</td>\n",
       "      <td>0.5772</td>\n",
       "      <td>20200125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_couches filter  kernel input_shape activation_couches  \\\n",
       "9           32    3 3      32     32 32 3               selu   \n",
       "11          32    3 3      32     32 32 3               selu   \n",
       "11          32    3 3      32     32 32 3               selu   \n",
       "9           32    3 3      32     32 32 3               selu   \n",
       "7           32    3 3      32     32 32 3               selu   \n",
       "5           32    3 3      32     32 32 3               selu   \n",
       "\n",
       "   activation_output  maxpool  indexes_maxpool  dropout  indexes_dropout  ...  \\\n",
       "9            softmax    False              NaN    False              NaN  ...   \n",
       "11           softmax    False              NaN    False              NaN  ...   \n",
       "11           softmax    False              NaN    False              NaN  ...   \n",
       "9            softmax    False              NaN    False              NaN  ...   \n",
       "7            softmax    False              NaN    False              NaN  ...   \n",
       "5            softmax    False              NaN    False              NaN  ...   \n",
       "\n",
       "    indexes_l1l2                             loss  optimizer  \\\n",
       "9            NaN  sparse_categorical_crossentropy       Adam   \n",
       "11           NaN  sparse_categorical_crossentropy       Adam   \n",
       "11           NaN  sparse_categorical_crossentropy       Adam   \n",
       "9            NaN  sparse_categorical_crossentropy       Adam   \n",
       "7            NaN  sparse_categorical_crossentropy       Adam   \n",
       "5            NaN  sparse_categorical_crossentropy       Adam   \n",
       "\n",
       "                        metrics  padding  epochs model_id accuracy_train  \\\n",
       "9   sparse_categorical_accuracy     same      40  7318436        0.95690   \n",
       "11  sparse_categorical_accuracy     same      40  3928073        0.95738   \n",
       "11  sparse_categorical_accuracy     same      40  6067132        0.95094   \n",
       "9   sparse_categorical_accuracy     same      40  3589055        0.94418   \n",
       "7   sparse_categorical_accuracy     same      40  6561474        0.92546   \n",
       "5   sparse_categorical_accuracy     same      40  7982485        0.95870   \n",
       "\n",
       "   accuracy_val   dossier  \n",
       "9        0.6059  20200126  \n",
       "11       0.5968  20200127  \n",
       "11       0.5963  20200127  \n",
       "9        0.5925  20200127  \n",
       "7        0.5890  20200126  \n",
       "5        0.5772  20200125  \n",
       "\n",
       "[6 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_unet_avg = results_unet_avg[results_unet_avg.activation_couches == \"selu\"]\n",
    "\n",
    "display(results_unet_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Conclusion premiers tests:\n",
    "&emsp;Ces premiers tests nous ont permis de cibler le type de modèle le plus interessant: Modèle utilisant des couches Average et une fonction d'activation \"selu\" pour ses couches cachées dont les résultats tournent autours des 60% en validation sans tenir compte de la taille du modèle.\n",
    "\n",
    "\n",
    "&emsp;On remarque aussi que tous ces modèles overfittent très fortement, en arrivant à 95% en train. Nous allons donc poursuivre les tests sur ce type de modèles en utilisant des techniques de régularisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNets Avec régularisation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests réalisés :\n",
    "&emsp;Pour nouveaux tests, nous avons testé des modèles de UNets constitués de la manière suivante:\n",
    "        - Tailles de 3 à 11 couches cachées\n",
    "        - Tests avec un nombre d'epochs fixe (40 epochs)\n",
    "        - Utilisation de techniques de régularisation \n",
    "        - Fonctions d'activation pour les couches cachées \"selu\"\n",
    "        - Couches de connexion de type Average pour créer la structure UNet \n",
    "        \n",
    "        \n",
    "&emsp;Comme pour les premiers tests, nous avons ensuite enregistré les résultats obtenus dans des fichiers CSV, en plus des logs générés par tensorflow, et nous allons charger ces statistiques et voir ce que ce genre de modèles peut donner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèles de différentes tailles avec régularisation L2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_couches</th>\n",
       "      <th>filter</th>\n",
       "      <th>kernel</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>activation_couches</th>\n",
       "      <th>activation_output</th>\n",
       "      <th>maxpool</th>\n",
       "      <th>indexes_maxpool</th>\n",
       "      <th>dropout</th>\n",
       "      <th>indexes_dropout</th>\n",
       "      <th>dropout_value</th>\n",
       "      <th>l1l2_couches</th>\n",
       "      <th>l1l2_output</th>\n",
       "      <th>l1_value</th>\n",
       "      <th>l2_value</th>\n",
       "      <th>indexes_l1l2</th>\n",
       "      <th>loss</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>metrics</th>\n",
       "      <th>padding</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model_id</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_val</th>\n",
       "      <th>dossier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1 2 3</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>7370110</td>\n",
       "      <td>0.90556</td>\n",
       "      <td>0.5436</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1 2 3</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>3175983</td>\n",
       "      <td>0.87782</td>\n",
       "      <td>0.5527</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1 2 3</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>7582707</td>\n",
       "      <td>0.93636</td>\n",
       "      <td>0.5585</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1 2 3</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>6678443</td>\n",
       "      <td>0.94014</td>\n",
       "      <td>0.5766</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1 2 3</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>7541851</td>\n",
       "      <td>0.92092</td>\n",
       "      <td>0.5560</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1 2 3</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>4422449</td>\n",
       "      <td>0.95198</td>\n",
       "      <td>0.5876</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1 2 3</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>9920102</td>\n",
       "      <td>0.95534</td>\n",
       "      <td>0.5763</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1 2 3</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>8927483</td>\n",
       "      <td>0.94220</td>\n",
       "      <td>0.5729</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>5889267</td>\n",
       "      <td>0.83082</td>\n",
       "      <td>0.5529</td>\n",
       "      <td>20200128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>402805</td>\n",
       "      <td>0.84520</td>\n",
       "      <td>0.5688</td>\n",
       "      <td>20200128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>5167656</td>\n",
       "      <td>0.84338</td>\n",
       "      <td>0.5519</td>\n",
       "      <td>20200128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1 2 3</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>7394589</td>\n",
       "      <td>0.82610</td>\n",
       "      <td>0.5816</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1 2 3</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>2681965</td>\n",
       "      <td>0.86624</td>\n",
       "      <td>0.5788</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>6571884</td>\n",
       "      <td>0.83692</td>\n",
       "      <td>0.5439</td>\n",
       "      <td>20200128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1 2 3 4 5 6 7</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>2292716</td>\n",
       "      <td>0.78150</td>\n",
       "      <td>0.5420</td>\n",
       "      <td>20200128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1 2 3 4 5 6 7</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>1689481</td>\n",
       "      <td>0.76472</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>20200128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1 2 3 4 5 6 7</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>7987980</td>\n",
       "      <td>0.76636</td>\n",
       "      <td>0.5420</td>\n",
       "      <td>20200128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1 2 3</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>5971779</td>\n",
       "      <td>0.69850</td>\n",
       "      <td>0.5735</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1 2 3</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>833852</td>\n",
       "      <td>0.72004</td>\n",
       "      <td>0.5934</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1 2 3</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>6722666</td>\n",
       "      <td>0.69060</td>\n",
       "      <td>0.5617</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3 3</td>\n",
       "      <td>32</td>\n",
       "      <td>32 32 3</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1 2 3</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>same</td>\n",
       "      <td>40</td>\n",
       "      <td>4888832</td>\n",
       "      <td>0.61042</td>\n",
       "      <td>0.5501</td>\n",
       "      <td>20200127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_couches filter  kernel input_shape activation_couches activation_output  \\\n",
       "3          32    3 3      32     32 32 3               selu           softmax   \n",
       "3          32    3 3      32     32 32 3               selu           softmax   \n",
       "3          32    3 3      32     32 32 3               selu           softmax   \n",
       "3          32    3 3      32     32 32 3               selu           softmax   \n",
       "3          32    3 3      32     32 32 3               selu           softmax   \n",
       "3          32    3 3      32     32 32 3               selu           softmax   \n",
       "3          32    3 3      32     32 32 3               selu           softmax   \n",
       "3          32    3 3      32     32 32 3               selu           softmax   \n",
       "9          32    3 3      32     32 32 3               selu           softmax   \n",
       "9          32    3 3      32     32 32 3               selu           softmax   \n",
       "9          32    3 3      32     32 32 3               selu           softmax   \n",
       "3          32    3 3      32     32 32 3               selu           softmax   \n",
       "3          32    3 3      32     32 32 3               selu           softmax   \n",
       "9          32    3 3      32     32 32 3               selu           softmax   \n",
       "7          32    3 3      32     32 32 3               selu           softmax   \n",
       "7          32    3 3      32     32 32 3               selu           softmax   \n",
       "7          32    3 3      32     32 32 3               selu           softmax   \n",
       "3          32    3 3      32     32 32 3               selu           softmax   \n",
       "3          32    3 3      32     32 32 3               selu           softmax   \n",
       "3          32    3 3      32     32 32 3               selu           softmax   \n",
       "3          32    3 3      32     32 32 3               selu           softmax   \n",
       "\n",
       "   maxpool  indexes_maxpool  dropout  indexes_dropout  dropout_value  \\\n",
       "3    False              NaN    False              NaN            0.0   \n",
       "3    False              NaN    False              NaN            0.0   \n",
       "3    False              NaN    False              NaN            0.0   \n",
       "3    False              NaN    False              NaN            0.0   \n",
       "3    False              NaN    False              NaN            0.0   \n",
       "3    False              NaN    False              NaN            0.0   \n",
       "3    False              NaN    False              NaN            0.0   \n",
       "3    False              NaN    False              NaN            0.0   \n",
       "9    False              NaN    False              NaN            0.0   \n",
       "9    False              NaN    False              NaN            0.0   \n",
       "9    False              NaN    False              NaN            0.0   \n",
       "3    False              NaN    False              NaN            0.0   \n",
       "3    False              NaN    False              NaN            0.0   \n",
       "9    False              NaN    False              NaN            0.0   \n",
       "7    False              NaN    False              NaN            0.0   \n",
       "7    False              NaN    False              NaN            0.0   \n",
       "7    False              NaN    False              NaN            0.0   \n",
       "3    False              NaN    False              NaN            0.0   \n",
       "3    False              NaN    False              NaN            0.0   \n",
       "3    False              NaN    False              NaN            0.0   \n",
       "3    False              NaN    False              NaN            0.0   \n",
       "\n",
       "   l1l2_couches  l1l2_output  l1_value  l2_value       indexes_l1l2  \\\n",
       "3          True        False       0.0     0.001              1 2 3   \n",
       "3          True        False       0.0     0.001              1 2 3   \n",
       "3          True        False       0.0     0.001              1 2 3   \n",
       "3          True        False       0.0     0.010              1 2 3   \n",
       "3          True        False       0.0     0.010              1 2 3   \n",
       "3          True        False       0.0     0.010              1 2 3   \n",
       "3          True         True       0.0     0.010              1 2 3   \n",
       "3          True         True       0.0     0.010              1 2 3   \n",
       "9          True        False       0.0     0.100  1 2 3 4 5 6 7 8 9   \n",
       "9          True        False       0.0     0.100  1 2 3 4 5 6 7 8 9   \n",
       "9          True        False       0.0     0.100  1 2 3 4 5 6 7 8 9   \n",
       "3          True        False       0.0     0.100              1 2 3   \n",
       "3          True         True       0.0     0.100              1 2 3   \n",
       "9          True        False       0.0     0.100  1 2 3 4 5 6 7 8 9   \n",
       "7          True        False       0.0     0.200      1 2 3 4 5 6 7   \n",
       "7          True        False       0.0     0.200      1 2 3 4 5 6 7   \n",
       "7          True        False       0.0     0.200      1 2 3 4 5 6 7   \n",
       "3          True        False       0.0     0.500              1 2 3   \n",
       "3          True         True       0.0     0.500              1 2 3   \n",
       "3          True        False       0.0     0.500              1 2 3   \n",
       "3          True        False       0.0     1.000              1 2 3   \n",
       "\n",
       "                              loss optimizer                      metrics  \\\n",
       "3  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "9  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "9  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "9  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "9  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "7  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "7  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "7  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy      Adam  sparse_categorical_accuracy   \n",
       "\n",
       "  padding  epochs  model_id  accuracy_train  accuracy_val   dossier  \n",
       "3    same      40   7370110         0.90556        0.5436  20200127  \n",
       "3    same      40   3175983         0.87782        0.5527  20200127  \n",
       "3    same      40   7582707         0.93636        0.5585  20200127  \n",
       "3    same      40   6678443         0.94014        0.5766  20200127  \n",
       "3    same      40   7541851         0.92092        0.5560  20200127  \n",
       "3    same      40   4422449         0.95198        0.5876  20200127  \n",
       "3    same      40   9920102         0.95534        0.5763  20200127  \n",
       "3    same      40   8927483         0.94220        0.5729  20200127  \n",
       "9    same      40   5889267         0.83082        0.5529  20200128  \n",
       "9    same      40    402805         0.84520        0.5688  20200128  \n",
       "9    same      40   5167656         0.84338        0.5519  20200128  \n",
       "3    same      40   7394589         0.82610        0.5816  20200127  \n",
       "3    same      40   2681965         0.86624        0.5788  20200127  \n",
       "9    same      40   6571884         0.83692        0.5439  20200128  \n",
       "7    same      40   2292716         0.78150        0.5420  20200128  \n",
       "7    same      40   1689481         0.76472        0.5317  20200128  \n",
       "7    same      40   7987980         0.76636        0.5420  20200128  \n",
       "3    same      40   5971779         0.69850        0.5735  20200127  \n",
       "3    same      40    833852         0.72004        0.5934  20200127  \n",
       "3    same      40   6722666         0.69060        0.5617  20200127  \n",
       "3    same      40   4888832         0.61042        0.5501  20200127  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root_csv_folder = \"..\\\\historique_tests\\\\\"\n",
    "\n",
    "# Organisation sur la valeur de la L2\n",
    "results_unet_avg_selu_l2 = pd.read_csv(\"{}tested_unet_selu_l2_history.csv\".format(root_csv_folder), sep=\";\")\n",
    "results_unet_avg_selu_l2 = results_unet_avg_selu_l2.sort_values(\"l2_value\",ascending=True)\n",
    "\n",
    "display(results_unet_avg_selu_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constatations:\n",
    "&emsp;Pour ces tests, nous avons testé différentes valeurs pour la régularisation l2: 0.001, 0.01, 0.1, 0.02, 0.5 et 1.\n",
    "\n",
    "&emsp;Au début, nous avons lancé des tests avec des valeurs pour la L2 assez petites, mais nous avons été surpris de remarquer que ces petites valeurs n'avaient pas beaucoup d'effet de régularisation sur notre modèle. \n",
    "\n",
    "&emsp;Nous avons lancé des tests avec des valeurs plus grands (0.5 ou encore 1), et effectivement, ces grandes valeurs régularisent beaucoup mieux. Par exemple sur un seul type de modèle (même nombre de couches), avec une valeur de 0.001, on a toujours plus de 90% de résultat sur le train, alors qu'avec une valeur de 0.5, on arrive à descendre à 72% sur le train, avec toujours 59% sur la validation. \n",
    "\n",
    "&emsp;Nous allons donc jouer sur ces valeurs pour la suite, mais sur de plus gros modèles (étant donné que la majorité de cette vague de tests a été réalisée sur des modèles à 3 couches cachées. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(history_df, history_df_desc):\n",
    "    # Calculating statistics on all models\n",
    "    if(not history_df.empty):\n",
    "        sorted_train_accuracy = np.sort(history_df.train_accuracy)\n",
    "        sorted_val_accuracy = np.sort(history_df.val_accuracy)\n",
    "\n",
    "        max_val_accuracy = sorted_val_accuracy[-1]\n",
    "        second_max_val_accuracy = sorted_val_accuracy[-2]\n",
    "        min_val_accuracy = history_df.val_accuracy.min()\n",
    "        mean_val_accuracy = history_df.val_accuracy.mean()\n",
    "        median_val_accuracy = history_df.val_accuracy.median()\n",
    "\n",
    "        max_train_accuracy = sorted_train_accuracy[-1]\n",
    "        second_max_train_accuracy = sorted_train_accuracy[-2]\n",
    "        min_train_accuracy = history_df.train_accuracy.min()\n",
    "        mean_train_accuracy = history_df.train_accuracy.mean()\n",
    "        median_train_accuracy = history_df.train_accuracy.median()\n",
    "\n",
    "        # Printing models statistics\n",
    "        print()\n",
    "        print(\"########### Models {} ###########\".format(history_df_desc))\n",
    "        print(history_df.shape)\n",
    "        print(\"Pire résultat sur le train : \", min_train_accuracy)\n",
    "        print(\"Pire Résultat sur la val : \", min_val_accuracy)\n",
    "\n",
    "        print(\"Meilleur résultat sur le train : \", max_train_accuracy)\n",
    "        print(\"Meilleur résultat sur la val : \", max_val_accuracy)\n",
    "\n",
    "        print(\"Moyenne des résultats sur le train : \", mean_train_accuracy)\n",
    "        print(\"Moyenne des résultats sur la val : \", mean_val_accuracy)\n",
    "\n",
    "        print(\"Mediane des résultat sur le train : \", median_train_accuracy)\n",
    "        print(\"Mediane des résultat sur la val : \", median_val_accuracy)\n",
    "\n",
    "def filter_on_median_val_accuracy(results_dataframes_list):\n",
    "    filtered_results_dataframes = []\n",
    "    \n",
    "    for i in range(len(results_dataframes_list)):\n",
    "\n",
    "        # Calculating statistics on all models\n",
    "        history_df = results_dataframes_list[i]\n",
    "        history_df_desc = results_dataframes_desc[i]\n",
    "\n",
    "        median_val_accuracy = history_df.val_accuracy.median()\n",
    "        mean_val_accuracy = history_df.val_accuracy.mean()\n",
    "        # Filtering models to get the best ones (those whose val accuracy is higher then the median)\n",
    "        \n",
    "        # Si la médiane est inférieure à la moyenne on enlève cette archi, car la majorité des modèles on une mauvaise\n",
    "        # accuracy, et la moyenne est gonflée par seulement une petite partie des modèles. Ce qui indique que que l'archi\n",
    "        # choisie n'est pas interessante\n",
    "#         if(mean_val_accuracy < median_val_accuracy):\n",
    "        filtered_history = history_df[history_df.val_accuracy > median_val_accuracy]\n",
    "#         else:\n",
    "#         filtered_history = pd.DataFrame(columns=history_df.columns)\n",
    "        filtered_results_dataframes.append(filtered_history)\n",
    "        \n",
    "    \n",
    "    return filtered_results_dataframes\n",
    "\n",
    "\n",
    "def filter_on_mean_train_accuracy(results_dataframes_list):\n",
    "    filtered_results_dataframes = []\n",
    "    \n",
    "    for i in range(len(results_dataframes_list)):\n",
    "\n",
    "        # Calculating statistics on all models\n",
    "        history_df = results_dataframes_list[i]\n",
    "        history_df_desc = results_dataframes_desc[i]\n",
    "\n",
    "#         median_train_accuracy = history_df.train_accuracy.median()\n",
    "        mean_train_accuracy = history_df.train_accuracy.mean()\n",
    "        # Filtering models to get the best ones (those whose val accuracy is higher then the median)\n",
    "        \n",
    "        # Si la médiane est inférieure à la moyenne on enlève cette archi, car la majorité des modèles on une mauvaise\n",
    "        # accuracy, et la moyenne est gonflée par seulement une petite partie des modèles. Ce qui indique que que l'archi\n",
    "        # choisie n'est pas interessante\n",
    "        filtered_history = history_df[history_df.train_accuracy > mean_train_accuracy]\n",
    "        filtered_results_dataframes.append(filtered_history)\n",
    "        \n",
    "    \n",
    "    return filtered_results_dataframes\n",
    "\n",
    "def concat_list_of_dataframes(list_df):\n",
    "    return pd.concat(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models mlp_5_10_64 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.52582\n",
      "Meilleur résultat sur la val :  0.4642\n",
      "Moyenne des résultats sur le train :  0.299574\n",
      "Moyenne des résultats sur la val :  0.27585000000000004\n",
      "Mediane des résultat sur le train :  0.28749\n",
      "Mediane des résultat sur la val :  0.2706\n",
      "\n",
      "########### Models mlp_5_10_128 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.6802199999999999\n",
      "Meilleur résultat sur la val :  0.4826\n",
      "Moyenne des résultats sur le train :  0.48029599999999995\n",
      "Moyenne des résultats sur la val :  0.39284\n",
      "Mediane des résultat sur le train :  0.54654\n",
      "Mediane des résultat sur la val :  0.46055\n",
      "\n",
      "########### Models mlp_5_10_256 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.8409200000000001\n",
      "Meilleur résultat sur la val :  0.4902\n",
      "Moyenne des résultats sur le train :  0.4958260000000001\n",
      "Moyenne des résultats sur la val :  0.35764999999999997\n",
      "Mediane des résultat sur le train :  0.57433\n",
      "Mediane des résultat sur la val :  0.4596\n",
      "\n",
      "########### Models mlp_5_10_512 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.9803200000000001\n",
      "Meilleur résultat sur la val :  0.4825\n",
      "Moyenne des résultats sur le train :  0.565704\n",
      "Moyenne des résultats sur la val :  0.35232\n",
      "Mediane des résultat sur le train :  0.65747\n",
      "Mediane des résultat sur la val :  0.45194999999999996\n",
      "\n",
      "########### Models mlp_10_15_64 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.6055\n",
      "Meilleur résultat sur la val :  0.4593\n",
      "Moyenne des résultats sur le train :  0.318992\n",
      "Moyenne des résultats sur la val :  0.27311\n",
      "Mediane des résultat sur le train :  0.30539\n",
      "Mediane des résultat sur la val :  0.26655\n",
      "\n",
      "########### Models mlp_10_15_128 ###########\n",
      "(9, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.85744\n",
      "Meilleur résultat sur la val :  0.4682\n",
      "Moyenne des résultats sur le train :  0.60546\n",
      "Moyenne des résultats sur la val :  0.3716777777777778\n",
      "Mediane des résultat sur le train :  0.68012\n",
      "Mediane des résultat sur la val :  0.4473\n",
      "\n",
      "########### Models mlp_10_15_256 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.9092399999999999\n",
      "Meilleur résultat sur la val :  0.4735\n",
      "Moyenne des résultats sur le train :  0.565902\n",
      "Moyenne des résultats sur la val :  0.38822999999999996\n",
      "Mediane des résultat sur le train :  0.59807\n",
      "Mediane des résultat sur la val :  0.45565\n",
      "\n",
      "########### Models mlp_10_15_512 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.9886799999999999\n",
      "Meilleur résultat sur la val :  0.4735\n",
      "Moyenne des résultats sur le train :  0.5353539999999999\n",
      "Moyenne des résultats sur la val :  0.34212\n",
      "Mediane des résultat sur le train :  0.5113099999999999\n",
      "Mediane des résultat sur la val :  0.43000000000000005\n",
      "\n",
      "########### Models mlp_15_20_64 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.6226\n",
      "Meilleur résultat sur la val :  0.4629\n",
      "Moyenne des résultats sur le train :  0.43040200000000006\n",
      "Moyenne des résultats sur la val :  0.34848\n",
      "Mediane des résultat sur le train :  0.55543\n",
      "Mediane des résultat sur la val :  0.45245\n",
      "\n",
      "########### Models mlp_15_20_128 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.93324\n",
      "Meilleur résultat sur la val :  0.4647\n",
      "Moyenne des résultats sur le train :  0.6550020000000001\n",
      "Moyenne des résultats sur la val :  0.36858\n",
      "Mediane des résultat sur le train :  0.76006\n",
      "Mediane des résultat sur la val :  0.4309\n",
      "\n",
      "########### Models mlp_15_20_256 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.9973\n",
      "Meilleur résultat sur la val :  0.4586\n",
      "Moyenne des résultats sur le train :  0.7692979999999999\n",
      "Moyenne des résultats sur la val :  0.41084000000000004\n",
      "Mediane des résultat sur le train :  0.8834\n",
      "Mediane des résultat sur la val :  0.44715000000000005\n",
      "\n",
      "########### Models mlp_15_20_512 ###########\n",
      "(9, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  1.0\n",
      "Meilleur résultat sur la val :  0.473\n",
      "Moyenne des résultats sur le train :  0.6177111111111111\n",
      "Moyenne des résultats sur la val :  0.3494111111111111\n",
      "Mediane des résultat sur le train :  0.7299\n",
      "Mediane des résultat sur la val :  0.4267\n",
      "\n",
      "########### Models mlp_20_30_64 ###########\n",
      "(12, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.6379199999999999\n",
      "Meilleur résultat sur la val :  0.4609\n",
      "Moyenne des résultats sur le train :  0.5055416666666667\n",
      "Moyenne des résultats sur la val :  0.3866500000000001\n",
      "Mediane des résultat sur le train :  0.5883700000000001\n",
      "Mediane des résultat sur la val :  0.4437\n",
      "\n",
      "########### Models mlp_20_30_128 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.9053\n",
      "Meilleur résultat sur la val :  0.4402\n",
      "Moyenne des résultats sur le train :  0.6131439999999999\n",
      "Moyenne des résultats sur la val :  0.34551\n",
      "Mediane des résultat sur le train :  0.8131999999999999\n",
      "Mediane des résultat sur la val :  0.41935\n",
      "\n",
      "########### Models mlp_20_30_256 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.9858399999999999\n",
      "Meilleur résultat sur la val :  0.4631\n",
      "Moyenne des résultats sur le train :  0.46791799999999995\n",
      "Moyenne des résultats sur la val :  0.27877\n",
      "Mediane des résultat sur le train :  0.30689\n",
      "Mediane des résultat sur la val :  0.30574999999999997\n",
      "\n",
      "########### Models mlp_20_30_512 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.9965799999999999\n",
      "Meilleur résultat sur la val :  0.4556\n",
      "Moyenne des résultats sur le train :  0.40037399999999995\n",
      "Moyenne des résultats sur la val :  0.26157\n",
      "Mediane des résultat sur le train :  0.24258\n",
      "Mediane des résultat sur la val :  0.24309999999999998\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results_dataframes_list)):\n",
    "    history = results_dataframes_list[i]\n",
    "    history_desc = results_dataframes_desc[i]\n",
    "    print_statistics(history, history_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On ne garde que les modèles dont les résultats sur la validations sont supérieurs à la médiane des résultats de tous les modèles (d'une même architecture) testés "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_results_dataframes = filter_on_median_val_accuracy(results_dataframes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models mlp_5_10_64 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.47498\n",
      "Pire Résultat sur la val :  0.4412\n",
      "Meilleur résultat sur le train :  0.52582\n",
      "Meilleur résultat sur la val :  0.4642\n",
      "Moyenne des résultats sur le train :  0.4991479999999999\n",
      "Moyenne des résultats sur la val :  0.45170000000000005\n",
      "Mediane des résultat sur le train :  0.49518\n",
      "Mediane des résultat sur la val :  0.4499\n",
      "\n",
      "########### Models mlp_5_10_128 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.5391600000000001\n",
      "Pire Résultat sur la val :  0.4661\n",
      "Meilleur résultat sur le train :  0.6382\n",
      "Meilleur résultat sur la val :  0.4826\n",
      "Moyenne des résultats sur le train :  0.5760759999999999\n",
      "Moyenne des résultats sur la val :  0.47286\n",
      "Mediane des résultat sur le train :  0.5705399999999999\n",
      "Mediane des résultat sur la val :  0.4698\n",
      "\n",
      "########### Models mlp_5_10_256 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.5229600000000001\n",
      "Pire Résultat sur la val :  0.4604\n",
      "Meilleur résultat sur le train :  0.77586\n",
      "Meilleur résultat sur la val :  0.4902\n",
      "Moyenne des résultats sur le train :  0.648712\n",
      "Moyenne des résultats sur la val :  0.4728\n",
      "Mediane des résultat sur le train :  0.6612399999999999\n",
      "Mediane des résultat sur la val :  0.4683\n",
      "\n",
      "########### Models mlp_5_10_512 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.6165\n",
      "Pire Résultat sur la val :  0.4582\n",
      "Meilleur résultat sur le train :  0.9803200000000001\n",
      "Meilleur résultat sur la val :  0.4825\n",
      "Moyenne des résultats sur le train :  0.757244\n",
      "Moyenne des résultats sur la val :  0.4673\n",
      "Mediane des résultat sur le train :  0.68112\n",
      "Mediane des résultat sur la val :  0.4657\n",
      "\n",
      "########### Models mlp_10_15_64 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.51078\n",
      "Pire Résultat sur la val :  0.4331\n",
      "Meilleur résultat sur le train :  0.6055\n",
      "Meilleur résultat sur la val :  0.4593\n",
      "Moyenne des résultats sur le train :  0.537984\n",
      "Moyenne des résultats sur la val :  0.44621999999999995\n",
      "Mediane des résultat sur le train :  0.51266\n",
      "Mediane des résultat sur la val :  0.4451\n",
      "\n",
      "########### Models mlp_10_15_128 ###########\n",
      "(4, 22)\n",
      "Pire résultat sur le train :  0.6252\n",
      "Pire Résultat sur la val :  0.4506\n",
      "Meilleur résultat sur le train :  0.82526\n",
      "Meilleur résultat sur la val :  0.4682\n",
      "Moyenne des résultats sur le train :  0.69503\n",
      "Moyenne des résultats sur la val :  0.456725\n",
      "Mediane des résultat sur le train :  0.66483\n",
      "Mediane des résultat sur la val :  0.45405\n",
      "\n",
      "########### Models mlp_10_15_256 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.5061\n",
      "Pire Résultat sur la val :  0.4565\n",
      "Meilleur résultat sur le train :  0.69438\n",
      "Meilleur résultat sur la val :  0.4735\n",
      "Moyenne des résultats sur le train :  0.5912\n",
      "Moyenne des résultats sur la val :  0.46799999999999997\n",
      "Mediane des résultat sur le train :  0.59632\n",
      "Mediane des résultat sur la val :  0.4699\n",
      "\n",
      "########### Models mlp_10_15_512 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.5031\n",
      "Pire Résultat sur la val :  0.4308\n",
      "Meilleur résultat sur le train :  0.9886799999999999\n",
      "Meilleur résultat sur la val :  0.4735\n",
      "Moyenne des résultats sur le train :  0.72768\n",
      "Moyenne des résultats sur la val :  0.45375999999999994\n",
      "Mediane des résultat sur le train :  0.7145199999999999\n",
      "Mediane des résultat sur la val :  0.4555\n",
      "\n",
      "########### Models mlp_15_20_64 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.54594\n",
      "Pire Résultat sur la val :  0.4552\n",
      "Meilleur résultat sur le train :  0.6226\n",
      "Meilleur résultat sur la val :  0.4629\n",
      "Moyenne des résultats sur le train :  0.572824\n",
      "Moyenne des résultats sur la val :  0.45968\n",
      "Mediane des résultat sur le train :  0.56286\n",
      "Mediane des résultat sur la val :  0.4594\n",
      "\n",
      "########### Models mlp_15_20_128 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.6640199999999999\n",
      "Pire Résultat sur la val :  0.4345\n",
      "Meilleur résultat sur le train :  0.93324\n",
      "Meilleur résultat sur la val :  0.4647\n",
      "Moyenne des résultats sur le train :  0.795196\n",
      "Moyenne des résultats sur la val :  0.4423\n",
      "Mediane des résultat sur le train :  0.79438\n",
      "Mediane des résultat sur la val :  0.4371\n",
      "\n",
      "########### Models mlp_15_20_256 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.5657399999999999\n",
      "Pire Résultat sur la val :  0.4489\n",
      "Meilleur résultat sur le train :  0.9973\n",
      "Meilleur résultat sur la val :  0.4586\n",
      "Moyenne des résultats sur le train :  0.903924\n",
      "Moyenne des résultats sur la val :  0.45408\n",
      "Mediane des résultat sur le train :  0.9907600000000001\n",
      "Mediane des résultat sur la val :  0.4541\n",
      "\n",
      "########### Models mlp_15_20_512 ###########\n",
      "(4, 22)\n",
      "Pire résultat sur le train :  0.93114\n",
      "Pire Résultat sur la val :  0.4319\n",
      "Meilleur résultat sur le train :  1.0\n",
      "Meilleur résultat sur la val :  0.473\n",
      "Moyenne des résultats sur le train :  0.979155\n",
      "Moyenne des résultats sur la val :  0.456875\n",
      "Mediane des résultat sur le train :  0.9927400000000001\n",
      "Mediane des résultat sur la val :  0.4613\n",
      "\n",
      "########### Models mlp_20_30_64 ###########\n",
      "(6, 22)\n",
      "Pire résultat sur le train :  0.58334\n",
      "Pire Résultat sur la val :  0.4446\n",
      "Meilleur résultat sur le train :  0.6379199999999999\n",
      "Meilleur résultat sur la val :  0.4609\n",
      "Moyenne des résultats sur le train :  0.61013\n",
      "Moyenne des résultats sur la val :  0.4513333333333333\n",
      "Mediane des résultat sur le train :  0.60942\n",
      "Mediane des résultat sur la val :  0.45075\n",
      "\n",
      "########### Models mlp_20_30_128 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.56072\n",
      "Pire Résultat sur la val :  0.4203\n",
      "Meilleur résultat sur le train :  0.9053\n",
      "Meilleur résultat sur la val :  0.4402\n",
      "Moyenne des résultats sur le train :  0.7967359999999999\n",
      "Moyenne des résultats sur la val :  0.43172\n",
      "Mediane des résultat sur le train :  0.83178\n",
      "Mediane des résultat sur la val :  0.43799999999999994\n",
      "\n",
      "########### Models mlp_20_30_256 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.33626\n",
      "Pire Résultat sur la val :  0.3321\n",
      "Meilleur résultat sur le train :  0.9858399999999999\n",
      "Meilleur résultat sur la val :  0.4631\n",
      "Moyenne des résultats sur le train :  0.800332\n",
      "Moyenne des résultats sur la val :  0.42166\n",
      "Mediane des résultat sur le train :  0.86408\n",
      "Mediane des résultat sur la val :  0.4347\n",
      "\n",
      "########### Models mlp_20_30_512 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.24884\n",
      "Pire Résultat sur la val :  0.2473\n",
      "Meilleur résultat sur le train :  0.9965799999999999\n",
      "Meilleur résultat sur la val :  0.4556\n",
      "Moyenne des résultats sur le train :  0.65218\n",
      "Moyenne des résultats sur la val :  0.37442\n",
      "Mediane des résultat sur le train :  0.74456\n",
      "Mediane des résultat sur la val :  0.4328\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(filtered_results_dataframes)):\n",
    "    filtered_history = filtered_results_dataframes[i]\n",
    "    filtered_history_desc = results_dataframes_desc[i]\n",
    "    print_statistics(filtered_history, filtered_history_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On fusionne tous les dataframes en une seule (étant donné qu'il y en a une par structure de modèle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = concat_list_of_dataframes(filtered_results_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models mlp_without_regularisation ###########\n",
      "(79, 22)\n",
      "Pire résultat sur le train :  0.24884\n",
      "Pire Résultat sur la val :  0.2473\n",
      "Meilleur résultat sur le train :  1.0\n",
      "Meilleur résultat sur la val :  0.4902\n",
      "Moyenne des résultats sur le train :  0.6918189873417723\n",
      "Moyenne des résultats sur la val :  0.4486696202531646\n",
      "Mediane des résultat sur le train :  0.6338199999999999\n",
      "Mediane des résultat sur la val :  0.4556\n"
     ]
    }
   ],
   "source": [
    "print_statistics(merged_df, \"mlp_without_regularisation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Première analyse des résultats obtenus :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nous remarquons donc sur les 79 meilleurs modèles, nous tournons autours des 45% de résultat sur la validation, et 65% sur le train. De plus, nous avons atteint une limite de taille à lancer, étant donné que nos fits crashent pour manque de mémoire GPU quand on essaye de s'attaquer à des modèles d'environs 30 couches cachées. \n",
    "\n",
    "#### Ces résultats nous montrent que les meilleurs modèles overfittent. Nous allons donc essayer d'appliquer des techniques de régularisation dessus, en prenant les meilleurs sur ces 33 modèles selectionnés. Mais avant cela, nous allons essayer de réduire le nombre de modèles à tester on ne prenant que les plus intéressants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection des meilleurs modèles sur la val sur les 79 selectionnés:\n",
    "    Pour cela, nous n'allons prendre que les modèles dont les résultats sur l'entraînement sont supérieurs à la médiane des résultats de tous les modèles compris (toutes arachitectures confondues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models Best MLP models ###########\n",
      "(39, 22)\n",
      "Pire résultat sur le train :  0.49518\n",
      "Pire Résultat sur la val :  0.4557\n",
      "Meilleur résultat sur le train :  1.0\n",
      "Meilleur résultat sur la val :  0.4902\n",
      "Moyenne des résultats sur le train :  0.67856\n",
      "Moyenne des résultats sur la val :  0.466625641025641\n",
      "Mediane des résultat sur le train :  0.6226\n",
      "Mediane des résultat sur la val :  0.4661\n"
     ]
    }
   ],
   "source": [
    "best_val_models = filter_on_median_val_accuracy([merged_df])[0]\n",
    "best_val_models = best_val_models.sort_values('activation_couches', ascending=False)\n",
    "print_statistics(best_val_models, \"Best MLP models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On voit donc que nous avons 39 modèles qui pourrait être intéressants sur la validation, mais nous allons maintenant en selectionné, entre ceux là, les meilleurs sur le train. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection des meilleurs modèles sur le train sur les 39 restants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models Best MLP models ###########\n",
      "(15, 22)\n",
      "Pire résultat sur le train :  0.68012\n",
      "Pire Résultat sur la val :  0.4557\n",
      "Meilleur résultat sur le train :  1.0\n",
      "Meilleur résultat sur la val :  0.4735\n",
      "Moyenne des résultats sur le train :  0.842788\n",
      "Moyenne des résultats sur la val :  0.46584\n",
      "Mediane des résultat sur le train :  0.8357600000000001\n",
      "Mediane des résultat sur la val :  0.4669\n"
     ]
    }
   ],
   "source": [
    "best_models = filter_on_mean_train_accuracy([best_val_models])[0]\n",
    "best_models = best_models.sort_values('val_accuracy', ascending=False)\n",
    "print_statistics(best_models, \"Best MLP models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Nous avons donc 14 modèles interessants qui semblent intéressants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_couches</th>\n",
       "      <th>profondeurs_couches</th>\n",
       "      <th>activation_couches</th>\n",
       "      <th>activation_output</th>\n",
       "      <th>dropout</th>\n",
       "      <th>nb_dropout</th>\n",
       "      <th>indexes_dropout</th>\n",
       "      <th>valeur_dropout</th>\n",
       "      <th>l1l2_couches</th>\n",
       "      <th>l1l2_output</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_l1l2</th>\n",
       "      <th>indexes_l1l2</th>\n",
       "      <th>loss</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>metrics</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>dossier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>512 512 512 512 512 512 512 512 512 512 512</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>5762652</td>\n",
       "      <td>0.71452</td>\n",
       "      <td>0.4735</td>\n",
       "      <td>20200123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16</td>\n",
       "      <td>512 512 512 512 512 512 512 512 512 512 512 51...</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>4143798</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.4730</td>\n",
       "      <td>20200123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>256 256 256 256 256 256 256 256 256 256 256 25...</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>7574331</td>\n",
       "      <td>0.69438</td>\n",
       "      <td>0.4704</td>\n",
       "      <td>20200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>512 512 512 512 512 512 512 512 512 512 512 51...</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>2810928</td>\n",
       "      <td>0.98868</td>\n",
       "      <td>0.4694</td>\n",
       "      <td>20200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>256 256 256 256 256 256 256 256 256</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>9815569</td>\n",
       "      <td>0.70862</td>\n",
       "      <td>0.4683</td>\n",
       "      <td>20200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>128 128 128 128 128 128 128 128 128 128 128 12...</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>568701</td>\n",
       "      <td>0.68012</td>\n",
       "      <td>0.4682</td>\n",
       "      <td>20200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>512 512 512 512 512 512 512 512 512</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>1855666</td>\n",
       "      <td>0.68112</td>\n",
       "      <td>0.4676</td>\n",
       "      <td>20200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>512 512 512 512 512 512 512 512 512 512 512 51...</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>2811332</td>\n",
       "      <td>0.99686</td>\n",
       "      <td>0.4669</td>\n",
       "      <td>20200123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>256 256 256 256 256 256 256 256</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>6310408</td>\n",
       "      <td>0.77586</td>\n",
       "      <td>0.4668</td>\n",
       "      <td>20200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>512 512 512 512 512 512 512</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>4390588</td>\n",
       "      <td>0.98032</td>\n",
       "      <td>0.4657</td>\n",
       "      <td>20200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>128 128 128 128 128 128 128 128 128 128 128 12...</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>8063621</td>\n",
       "      <td>0.72574</td>\n",
       "      <td>0.4647</td>\n",
       "      <td>20200123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>256 256 256 256 256 256 256 256 256 256 256 25...</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>8027726</td>\n",
       "      <td>0.83576</td>\n",
       "      <td>0.4631</td>\n",
       "      <td>20200123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>512 512 512 512 512</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>3082596</td>\n",
       "      <td>0.87446</td>\n",
       "      <td>0.4582</td>\n",
       "      <td>20200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>256 256 256 256 256 256 256 256 256 256 256 25...</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>1678598</td>\n",
       "      <td>0.99676</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>20200123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>512 512 512 512 512 512 512 512 512 512 512 51...</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>383142</td>\n",
       "      <td>0.98862</td>\n",
       "      <td>0.4557</td>\n",
       "      <td>20200123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_couches                                profondeurs_couches  \\\n",
       "6          11        512 512 512 512 512 512 512 512 512 512 512   \n",
       "7          16  512 512 512 512 512 512 512 512 512 512 512 51...   \n",
       "0          14  256 256 256 256 256 256 256 256 256 256 256 25...   \n",
       "2          14  512 512 512 512 512 512 512 512 512 512 512 51...   \n",
       "5           9                256 256 256 256 256 256 256 256 256   \n",
       "7          15  128 128 128 128 128 128 128 128 128 128 128 12...   \n",
       "8           9                512 512 512 512 512 512 512 512 512   \n",
       "4          18  512 512 512 512 512 512 512 512 512 512 512 51...   \n",
       "4           8                    256 256 256 256 256 256 256 256   \n",
       "9           7                        512 512 512 512 512 512 512   \n",
       "2          16  128 128 128 128 128 128 128 128 128 128 128 12...   \n",
       "3          23  256 256 256 256 256 256 256 256 256 256 256 25...   \n",
       "2           5                                512 512 512 512 512   \n",
       "5          17  256 256 256 256 256 256 256 256 256 256 256 25...   \n",
       "8          15  512 512 512 512 512 512 512 512 512 512 512 51...   \n",
       "\n",
       "  activation_couches activation_output  dropout  nb_dropout  indexes_dropout  \\\n",
       "6           softplus           softmax    False           0              NaN   \n",
       "7           softplus           softmax    False           0              NaN   \n",
       "0               selu           softmax    False           0              NaN   \n",
       "2               relu           softmax    False           0              NaN   \n",
       "5               selu           softmax    False           0              NaN   \n",
       "7               selu           softmax    False           0              NaN   \n",
       "8               relu           softmax    False           0              NaN   \n",
       "4               relu           softmax    False           0              NaN   \n",
       "4               relu           softmax    False           0              NaN   \n",
       "9               relu           softmax    False           0              NaN   \n",
       "2               selu           softmax    False           0              NaN   \n",
       "3               selu           softmax    False           0              NaN   \n",
       "2               relu           softmax    False           0              NaN   \n",
       "5           softplus           softmax    False           0              NaN   \n",
       "8           softplus           softmax    False           0              NaN   \n",
       "\n",
       "   valeur_dropout  l1l2_couches  l1l2_output  ...  nb_l1l2  indexes_l1l2  \\\n",
       "6             0.0         False        False  ...        0           NaN   \n",
       "7             0.0         False        False  ...        0           NaN   \n",
       "0             0.0         False        False  ...        0           NaN   \n",
       "2             0.0         False        False  ...        0           NaN   \n",
       "5             0.0         False        False  ...        0           NaN   \n",
       "7             0.0         False        False  ...        0           NaN   \n",
       "8             0.0         False        False  ...        0           NaN   \n",
       "4             0.0         False        False  ...        0           NaN   \n",
       "4             0.0         False        False  ...        0           NaN   \n",
       "9             0.0         False        False  ...        0           NaN   \n",
       "2             0.0         False        False  ...        0           NaN   \n",
       "3             0.0         False        False  ...        0           NaN   \n",
       "2             0.0         False        False  ...        0           NaN   \n",
       "5             0.0         False        False  ...        0           NaN   \n",
       "8             0.0         False        False  ...        0           NaN   \n",
       "\n",
       "                              loss  optimizer                      metrics  \\\n",
       "6  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "7  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "0  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "2  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "5  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "7  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "8  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "4  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "4  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "9  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "2  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "2  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "5  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "8  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "\n",
       "  epochs model_id  train_accuracy  val_accuracy   dossier  \n",
       "6    400  5762652         0.71452        0.4735  20200123  \n",
       "7    400  4143798         1.00000        0.4730  20200123  \n",
       "0    400  7574331         0.69438        0.4704  20200122  \n",
       "2    400  2810928         0.98868        0.4694  20200122  \n",
       "5    400  9815569         0.70862        0.4683  20200122  \n",
       "7    400   568701         0.68012        0.4682  20200122  \n",
       "8    400  1855666         0.68112        0.4676  20200122  \n",
       "4    400  2811332         0.99686        0.4669  20200123  \n",
       "4    400  6310408         0.77586        0.4668  20200122  \n",
       "9    400  4390588         0.98032        0.4657  20200122  \n",
       "2    400  8063621         0.72574        0.4647  20200123  \n",
       "3    400  8027726         0.83576        0.4631  20200123  \n",
       "2    400  3082596         0.87446        0.4582  20200122  \n",
       "5    400  1678598         0.99676        0.4561  20200123  \n",
       "8    400   383142         0.98862        0.4557  20200123  \n",
       "\n",
       "[15 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models.to_csv(\"{}best_mlp_without_regularisation.csv\".format(root_csv_folder), sep=';',header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions premiers tests:\n",
    "\n",
    "##### Avec cette première vague de tests, nous avons vu que des MLP, mêmes assez gros (du moins, les plus gros qu'on a pu lancer (Maximum 25 à 30 couches à 512 neurones par couches)) ne donnent pas de résultats intéressant sur la validation (un maximum de 48%).\n",
    "\n",
    "##### Cependant, on a aussi remarqué que tous ces modèles on tendance à overfitter. Du coup on va essayer d'appliquer des techniques de régulatisation pour voir si on peu tirer de meilleurs résultats avec les meilleurs modèles qu'on a réussi à avoir.\n",
    "\n",
    "##### Nous avons selectionnés deux modèles pour poursuivre les tests : le meilleur modèle qu'on a obtenu (11 couches à 512 neuronnes par couche avec une softplus pour l'activation des couches cachées et une softmax pour l'output) et un modèle qui overfitte beaucoup  (5 couches à 512 neurones par couche, avec la relu pour les couches cachées et la softmax pour l'output). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests MLP avec techniques de régularisations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle à 5 couches:\n",
    "###### Résultats sans régularisation : 0.46 en validation et 0.87 en train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec Régularisation L2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L2 à 0.0005 : 0.45 sur la validation et 0.9 sur le train => même résultat que sans régularisation\n",
    "- L2 à 0.01: 0.5 sur la validation et 0.75 sur le train (qui était à 0.87 sans régularisation) mais on a toujour un overfitting => Un peu mieux, mais on peu essaye de régulariser encore plus\n",
    "- L2 à 0.2: 0.31 sur la validation et le train => on a trop pénalisé les poids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec Régularisation L1 + L2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L2 à 0.01 et L1 à 0.01: 0.31 sur la validation et le train => on a trop pénalisé les poids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle à 11 couches:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Résultats sans régularisation : 0.4735 en validation et 0.71 en train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec Régularisation L2 sur les couches cachées:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L2 à 0.01: 0.37 en validation et 0.38 en train => Trop pénalisé\n",
    "- L2 à 0.001: 0.58 sur le train, et sur la validation monte jusqu'à 0.53 sur certaine epochs. par contre, tout le long du train, l'accuracy s'effondre à plusieurs reprises pour ensuite remonter (comme le montre le logs du fit). On retrouvera ce comportement sur plusieurs autres entrau=inement du même modèle avec d'autres hyperparamètres(comme avecla l2 à 0.0005). On n'arrive pas à expliquer cela.\n",
    "- L2 à 0.0005: Monte jusqu'à 0.54 en validation sur certaines epochs et à 0.95 sur le train. => Overfit, nous avons donc essayé d'ajouter une L1 à ce même modèle.\n",
    "- L2 à 0.002: Validation à 0.53 et 0.6 sur le train, Accuracy retombe de temps en temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 4396."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"..\\\\logs\\\\mlp_best_models_with_l2_2848849.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec Régularisation L2 et L1 sur les couches cachées:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- l2 à 0.0005 et L1 à 0.0001: 0.5 en validation et 0.54 ssur le train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec Régularisation L2 sur les couches cachées et output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L2 à 0.001: 0.5 sur la validation et 0.55 sur le train\n",
    "- L2 à 0.0005: 0.5 sur la validation et 0.55 sur le train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec Régularisation L2 sur les couches cachées et Dropout:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L2 à 0.001 et dropout à 0.1: 0.43 sur la validation et 0.47 sur le train\n",
    "- L2 à 0.001 et dropout à 0.2: 0.29 sur la validation et le train\n",
    "- L2 à 0.001 et dropout à 0.3: 0.27 sur la validation et le train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec Régularisation Dropout sur les inputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dropout à 0.2: 0.89 sur le train et 0.45 sur la val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion MLP:\n",
    "\n",
    "### Résumé de résultats obtenus:\n",
    "\n",
    "##### Même en utilisations différents hyperparamètres et techniques de régularisation, avec de simples MLP, nous avons vu que l'accuracy maximale que nous avons pu atteindre sur la validation se situe autours des 54%. Etant donné que nous avons atteint nos limites en matière de ressources matérielles, nous allons essayer d'utiliser d'autres types de modèles sur le dataset pour voir ce que cela va donner. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
