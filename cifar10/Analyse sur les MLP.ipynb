{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des resultats des test de différentes structures de MLP sur le dataset Cifar-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous allons analyser les resultats obtenus sur la première vague de tests de différentes structures et hyperparametres de MLP. Pour chaque un des tests menés, entre 10 et 20 modèles on été testés. 2tant donné la grande quantité d'architectures testées, nous allons mettre seulement un ou deux examples de nos méthodes d'analyse des résutat, et Présenter les résultat définitifs, pour ne pas surcharger le notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation des outils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Sans régularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests réalisés :\n",
    "    Pour ce début de tests, nous avons essayé d'entrainer différents MLP en jouant sur le nombre de couches ainsi que leur profondeur. Pour cela, on a lancé des tests comme suit (plusieurs fois sur la même structure) :\n",
    "    - Des modèles de 5 à 10 couches, des profondeurs entre 64 et 512 neurones.\n",
    "    - Des modèles de 10 à 15 couches, des profondeurs entre 64 et 512 neurones.\n",
    "    - Des modèles de 15 à 20 couches, des profondeurs entre 64 et 512 neurones.\n",
    "    - Des modèles de 20 à 30 couches, des profondeurs entre 64 et 512 neurones.\n",
    "    \n",
    "    Nous avons ensuite enregistré les résultats obtenus dans des fichiers CSV, en plus des logs générés par tensorflow, pour étudier les résultats obtenus.\n",
    "    \n",
    "    Nous allons donc charger ces statistiques et voir ce que ce genre de modèles peut donner sur le Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des résultats obtenus pour chaque configuration de modèle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframes_list = []\n",
    "results_dataframes_desc = []\n",
    "root_csv_folder = \".\\\\trained_models\\\\mlp\\\\\"\n",
    "\n",
    "# MLP Without regularisation results 5 to 10 Layers\n",
    "for i in [64, 128, 256, 512]:\n",
    "    df = pd.read_csv(\"{}tested_mlp_5_10_{}_history.csv\".format(root_csv_folder,i), sep=\";\")\n",
    "    df = df[df.epochs == 400]\n",
    "    results_dataframes_list.append(df)\n",
    "    results_dataframes_desc.append(\"mlp_5_10_{}\".format(i))\n",
    "\n",
    "# MLP Without regularisation results 10 to 15 Layers\n",
    "for i in [64, 128, 256, 512]:\n",
    "    df = pd.read_csv(\"{}tested_mlp_10_15_{}_history.csv\".format(root_csv_folder,i), sep=\";\")\n",
    "    df = df[df.epochs == 400]\n",
    "    results_dataframes_list.append(df)\n",
    "    results_dataframes_desc.append(\"mlp_10_15_{}\".format(i))\n",
    "\n",
    "# MLP Without regularisation results 15 to 20 Layers\n",
    "for i in [64, 128, 256, 512]:\n",
    "    df = pd.read_csv(\"{}tested_mlp_15_20_{}_history.csv\".format(root_csv_folder, i), sep=\";\")\n",
    "    df = df[df.epochs == 400]\n",
    "    results_dataframes_list.append(df)\n",
    "    results_dataframes_desc.append(\"mlp_15_20_{}\".format(i))\n",
    "\n",
    "# MLP Without regularisation results 15 to 20 Layers\n",
    "for i in [64, 128, 256, 512]:\n",
    "    df = pd.read_csv(\"{}tested_mlp_20_30_{}_history.csv\".format(root_csv_folder, i), sep=\";\")\n",
    "    df = df[df.epochs == 400]\n",
    "    results_dataframes_list.append(df)\n",
    "    results_dataframes_desc.append(\"mlp_20_30_{}\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des informations interessantes :\n",
    "- Pire résultat sur le train\n",
    "- Pire résultat sur la val\n",
    "- Meilleur résultat sur le train\n",
    "- Meilleur résultat sur la val \n",
    "- Moyenne des résultats sur le train \n",
    "- Moyenne des résultats sur la val \n",
    "- Mediane des résultat sur le train \n",
    "- Mediane des résultat sur la val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(history_df, history_df_desc):\n",
    "    # Calculating statistics on all models\n",
    "    if(not history_df.empty):\n",
    "        sorted_train_accuracy = np.sort(history_df.train_accuracy)\n",
    "        sorted_val_accuracy = np.sort(history_df.val_accuracy)\n",
    "\n",
    "        max_val_accuracy = sorted_val_accuracy[-1]\n",
    "        second_max_val_accuracy = sorted_val_accuracy[-2]\n",
    "        min_val_accuracy = history_df.val_accuracy.min()\n",
    "        mean_val_accuracy = history_df.val_accuracy.mean()\n",
    "        median_val_accuracy = history_df.val_accuracy.median()\n",
    "\n",
    "        max_train_accuracy = sorted_train_accuracy[-1]\n",
    "        second_max_train_accuracy = sorted_train_accuracy[-2]\n",
    "        min_train_accuracy = history_df.train_accuracy.min()\n",
    "        mean_train_accuracy = history_df.train_accuracy.mean()\n",
    "        median_train_accuracy = history_df.train_accuracy.median()\n",
    "\n",
    "        # Printing models statistics\n",
    "        print()\n",
    "        print(\"########### Models {} ###########\".format(history_df_desc))\n",
    "        print(history_df.shape)\n",
    "        print(\"Pire résultat sur le train : \", min_train_accuracy)\n",
    "        print(\"Pire Résultat sur la val : \", min_val_accuracy)\n",
    "\n",
    "        print(\"Meilleur résultat sur le train : \", max_train_accuracy)\n",
    "        print(\"Meilleur résultat sur la val : \", max_val_accuracy)\n",
    "\n",
    "        print(\"Moyenne des résultats sur le train : \", mean_train_accuracy)\n",
    "        print(\"Moyenne des résultats sur la val : \", mean_val_accuracy)\n",
    "\n",
    "        print(\"Mediane des résultat sur le train : \", median_train_accuracy)\n",
    "        print(\"Mediane des résultat sur la val : \", median_val_accuracy)\n",
    "\n",
    "def filter_on_median_val_accuracy(results_dataframes_list):\n",
    "    filtered_results_dataframes = []\n",
    "    \n",
    "    for i in range(len(results_dataframes_list)):\n",
    "\n",
    "        # Calculating statistics on all models\n",
    "        history_df = results_dataframes_list[i]\n",
    "        history_df_desc = results_dataframes_desc[i]\n",
    "\n",
    "        median_val_accuracy = history_df.val_accuracy.median()\n",
    "        mean_val_accuracy = history_df.val_accuracy.mean()\n",
    "        # Filtering models to get the best ones (those whose val accuracy is higher then the median)\n",
    "        \n",
    "        # Si la médiane est inférieure à la moyenne on enlève cette archi, car la majorité des modèles on une mauvaise\n",
    "        # accuracy, et la moyenne est gonflée par seulement une petite partie des modèles. Ce qui indique que que l'archi\n",
    "        # choisie n'est pas interessante\n",
    "#         if(mean_val_accuracy < median_val_accuracy):\n",
    "        filtered_history = history_df[history_df.val_accuracy > median_val_accuracy]\n",
    "#         else:\n",
    "#         filtered_history = pd.DataFrame(columns=history_df.columns)\n",
    "        filtered_results_dataframes.append(filtered_history)\n",
    "        \n",
    "    \n",
    "    return filtered_results_dataframes\n",
    "\n",
    "\n",
    "def filter_on_mean_train_accuracy(results_dataframes_list):\n",
    "    filtered_results_dataframes = []\n",
    "    \n",
    "    for i in range(len(results_dataframes_list)):\n",
    "\n",
    "        # Calculating statistics on all models\n",
    "        history_df = results_dataframes_list[i]\n",
    "        history_df_desc = results_dataframes_desc[i]\n",
    "\n",
    "#         median_train_accuracy = history_df.train_accuracy.median()\n",
    "        mean_train_accuracy = history_df.train_accuracy.mean()\n",
    "        # Filtering models to get the best ones (those whose val accuracy is higher then the median)\n",
    "        \n",
    "        # Si la médiane est inférieure à la moyenne on enlève cette archi, car la majorité des modèles on une mauvaise\n",
    "        # accuracy, et la moyenne est gonflée par seulement une petite partie des modèles. Ce qui indique que que l'archi\n",
    "        # choisie n'est pas interessante\n",
    "        filtered_history = history_df[history_df.train_accuracy > mean_train_accuracy]\n",
    "        filtered_results_dataframes.append(filtered_history)\n",
    "        \n",
    "    \n",
    "    return filtered_results_dataframes\n",
    "\n",
    "def concat_list_of_dataframes(list_df):\n",
    "    return pd.concat(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models mlp_5_10_64 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.52582\n",
      "Meilleur résultat sur la val :  0.4642\n",
      "Moyenne des résultats sur le train :  0.299574\n",
      "Moyenne des résultats sur la val :  0.27585000000000004\n",
      "Mediane des résultat sur le train :  0.28749\n",
      "Mediane des résultat sur la val :  0.2706\n",
      "\n",
      "########### Models mlp_5_10_128 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.6802199999999999\n",
      "Meilleur résultat sur la val :  0.4826\n",
      "Moyenne des résultats sur le train :  0.48029599999999995\n",
      "Moyenne des résultats sur la val :  0.39284\n",
      "Mediane des résultat sur le train :  0.54654\n",
      "Mediane des résultat sur la val :  0.46055\n",
      "\n",
      "########### Models mlp_5_10_256 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.8409200000000001\n",
      "Meilleur résultat sur la val :  0.4902\n",
      "Moyenne des résultats sur le train :  0.4958260000000001\n",
      "Moyenne des résultats sur la val :  0.35764999999999997\n",
      "Mediane des résultat sur le train :  0.57433\n",
      "Mediane des résultat sur la val :  0.4596\n",
      "\n",
      "########### Models mlp_5_10_512 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.9803200000000001\n",
      "Meilleur résultat sur la val :  0.4825\n",
      "Moyenne des résultats sur le train :  0.565704\n",
      "Moyenne des résultats sur la val :  0.35232\n",
      "Mediane des résultat sur le train :  0.65747\n",
      "Mediane des résultat sur la val :  0.45194999999999996\n",
      "\n",
      "########### Models mlp_10_15_64 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.6055\n",
      "Meilleur résultat sur la val :  0.4593\n",
      "Moyenne des résultats sur le train :  0.318992\n",
      "Moyenne des résultats sur la val :  0.27311\n",
      "Mediane des résultat sur le train :  0.30539\n",
      "Mediane des résultat sur la val :  0.26655\n",
      "\n",
      "########### Models mlp_10_15_128 ###########\n",
      "(9, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.85744\n",
      "Meilleur résultat sur la val :  0.4682\n",
      "Moyenne des résultats sur le train :  0.60546\n",
      "Moyenne des résultats sur la val :  0.3716777777777778\n",
      "Mediane des résultat sur le train :  0.68012\n",
      "Mediane des résultat sur la val :  0.4473\n",
      "\n",
      "########### Models mlp_10_15_256 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.9092399999999999\n",
      "Meilleur résultat sur la val :  0.4735\n",
      "Moyenne des résultats sur le train :  0.565902\n",
      "Moyenne des résultats sur la val :  0.38822999999999996\n",
      "Mediane des résultat sur le train :  0.59807\n",
      "Mediane des résultat sur la val :  0.45565\n",
      "\n",
      "########### Models mlp_10_15_512 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.9886799999999999\n",
      "Meilleur résultat sur la val :  0.4735\n",
      "Moyenne des résultats sur le train :  0.5353539999999999\n",
      "Moyenne des résultats sur la val :  0.34212\n",
      "Mediane des résultat sur le train :  0.5113099999999999\n",
      "Mediane des résultat sur la val :  0.43000000000000005\n",
      "\n",
      "########### Models mlp_15_20_64 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.6226\n",
      "Meilleur résultat sur la val :  0.4629\n",
      "Moyenne des résultats sur le train :  0.43040200000000006\n",
      "Moyenne des résultats sur la val :  0.34848\n",
      "Mediane des résultat sur le train :  0.55543\n",
      "Mediane des résultat sur la val :  0.45245\n",
      "\n",
      "########### Models mlp_15_20_128 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.93324\n",
      "Meilleur résultat sur la val :  0.4647\n",
      "Moyenne des résultats sur le train :  0.6550020000000001\n",
      "Moyenne des résultats sur la val :  0.36858\n",
      "Mediane des résultat sur le train :  0.76006\n",
      "Mediane des résultat sur la val :  0.4309\n",
      "\n",
      "########### Models mlp_15_20_256 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.9973\n",
      "Meilleur résultat sur la val :  0.4586\n",
      "Moyenne des résultats sur le train :  0.7692979999999999\n",
      "Moyenne des résultats sur la val :  0.41084000000000004\n",
      "Mediane des résultat sur le train :  0.8834\n",
      "Mediane des résultat sur la val :  0.44715000000000005\n",
      "\n",
      "########### Models mlp_15_20_512 ###########\n",
      "(9, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  1.0\n",
      "Meilleur résultat sur la val :  0.473\n",
      "Moyenne des résultats sur le train :  0.6177111111111111\n",
      "Moyenne des résultats sur la val :  0.3494111111111111\n",
      "Mediane des résultat sur le train :  0.7299\n",
      "Mediane des résultat sur la val :  0.4267\n",
      "\n",
      "########### Models mlp_20_30_64 ###########\n",
      "(12, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.6379199999999999\n",
      "Meilleur résultat sur la val :  0.4609\n",
      "Moyenne des résultats sur le train :  0.5055416666666667\n",
      "Moyenne des résultats sur la val :  0.3866500000000001\n",
      "Mediane des résultat sur le train :  0.5883700000000001\n",
      "Mediane des résultat sur la val :  0.4437\n",
      "\n",
      "########### Models mlp_20_30_128 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.9053\n",
      "Meilleur résultat sur la val :  0.4402\n",
      "Moyenne des résultats sur le train :  0.6131439999999999\n",
      "Moyenne des résultats sur la val :  0.34551\n",
      "Mediane des résultat sur le train :  0.8131999999999999\n",
      "Mediane des résultat sur la val :  0.41935\n",
      "\n",
      "########### Models mlp_20_30_256 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.9858399999999999\n",
      "Meilleur résultat sur la val :  0.4631\n",
      "Moyenne des résultats sur le train :  0.46791799999999995\n",
      "Moyenne des résultats sur la val :  0.27877\n",
      "Mediane des résultat sur le train :  0.30689\n",
      "Mediane des résultat sur la val :  0.30574999999999997\n",
      "\n",
      "########### Models mlp_20_30_512 ###########\n",
      "(10, 22)\n",
      "Pire résultat sur le train :  0.1\n",
      "Pire Résultat sur la val :  0.1\n",
      "Meilleur résultat sur le train :  0.9965799999999999\n",
      "Meilleur résultat sur la val :  0.4556\n",
      "Moyenne des résultats sur le train :  0.40037399999999995\n",
      "Moyenne des résultats sur la val :  0.26157\n",
      "Mediane des résultat sur le train :  0.24258\n",
      "Mediane des résultat sur la val :  0.24309999999999998\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results_dataframes_list)):\n",
    "    history = results_dataframes_list[i]\n",
    "    history_desc = results_dataframes_desc[i]\n",
    "    print_statistics(history, history_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On ne garde que les modèles dont les résultats sur la validations sont supérieurs à la médiane des résultats de tous les modèles (d'une même architecture) testés "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_results_dataframes = filter_on_median_val_accuracy(results_dataframes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models mlp_5_10_64 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.47498\n",
      "Pire Résultat sur la val :  0.4412\n",
      "Meilleur résultat sur le train :  0.52582\n",
      "Meilleur résultat sur la val :  0.4642\n",
      "Moyenne des résultats sur le train :  0.4991479999999999\n",
      "Moyenne des résultats sur la val :  0.45170000000000005\n",
      "Mediane des résultat sur le train :  0.49518\n",
      "Mediane des résultat sur la val :  0.4499\n",
      "\n",
      "########### Models mlp_5_10_128 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.5391600000000001\n",
      "Pire Résultat sur la val :  0.4661\n",
      "Meilleur résultat sur le train :  0.6382\n",
      "Meilleur résultat sur la val :  0.4826\n",
      "Moyenne des résultats sur le train :  0.5760759999999999\n",
      "Moyenne des résultats sur la val :  0.47286\n",
      "Mediane des résultat sur le train :  0.5705399999999999\n",
      "Mediane des résultat sur la val :  0.4698\n",
      "\n",
      "########### Models mlp_5_10_256 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.5229600000000001\n",
      "Pire Résultat sur la val :  0.4604\n",
      "Meilleur résultat sur le train :  0.77586\n",
      "Meilleur résultat sur la val :  0.4902\n",
      "Moyenne des résultats sur le train :  0.648712\n",
      "Moyenne des résultats sur la val :  0.4728\n",
      "Mediane des résultat sur le train :  0.6612399999999999\n",
      "Mediane des résultat sur la val :  0.4683\n",
      "\n",
      "########### Models mlp_5_10_512 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.6165\n",
      "Pire Résultat sur la val :  0.4582\n",
      "Meilleur résultat sur le train :  0.9803200000000001\n",
      "Meilleur résultat sur la val :  0.4825\n",
      "Moyenne des résultats sur le train :  0.757244\n",
      "Moyenne des résultats sur la val :  0.4673\n",
      "Mediane des résultat sur le train :  0.68112\n",
      "Mediane des résultat sur la val :  0.4657\n",
      "\n",
      "########### Models mlp_10_15_64 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.51078\n",
      "Pire Résultat sur la val :  0.4331\n",
      "Meilleur résultat sur le train :  0.6055\n",
      "Meilleur résultat sur la val :  0.4593\n",
      "Moyenne des résultats sur le train :  0.537984\n",
      "Moyenne des résultats sur la val :  0.44621999999999995\n",
      "Mediane des résultat sur le train :  0.51266\n",
      "Mediane des résultat sur la val :  0.4451\n",
      "\n",
      "########### Models mlp_10_15_128 ###########\n",
      "(4, 22)\n",
      "Pire résultat sur le train :  0.6252\n",
      "Pire Résultat sur la val :  0.4506\n",
      "Meilleur résultat sur le train :  0.82526\n",
      "Meilleur résultat sur la val :  0.4682\n",
      "Moyenne des résultats sur le train :  0.69503\n",
      "Moyenne des résultats sur la val :  0.456725\n",
      "Mediane des résultat sur le train :  0.66483\n",
      "Mediane des résultat sur la val :  0.45405\n",
      "\n",
      "########### Models mlp_10_15_256 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.5061\n",
      "Pire Résultat sur la val :  0.4565\n",
      "Meilleur résultat sur le train :  0.69438\n",
      "Meilleur résultat sur la val :  0.4735\n",
      "Moyenne des résultats sur le train :  0.5912\n",
      "Moyenne des résultats sur la val :  0.46799999999999997\n",
      "Mediane des résultat sur le train :  0.59632\n",
      "Mediane des résultat sur la val :  0.4699\n",
      "\n",
      "########### Models mlp_10_15_512 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.5031\n",
      "Pire Résultat sur la val :  0.4308\n",
      "Meilleur résultat sur le train :  0.9886799999999999\n",
      "Meilleur résultat sur la val :  0.4735\n",
      "Moyenne des résultats sur le train :  0.72768\n",
      "Moyenne des résultats sur la val :  0.45375999999999994\n",
      "Mediane des résultat sur le train :  0.7145199999999999\n",
      "Mediane des résultat sur la val :  0.4555\n",
      "\n",
      "########### Models mlp_15_20_64 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.54594\n",
      "Pire Résultat sur la val :  0.4552\n",
      "Meilleur résultat sur le train :  0.6226\n",
      "Meilleur résultat sur la val :  0.4629\n",
      "Moyenne des résultats sur le train :  0.572824\n",
      "Moyenne des résultats sur la val :  0.45968\n",
      "Mediane des résultat sur le train :  0.56286\n",
      "Mediane des résultat sur la val :  0.4594\n",
      "\n",
      "########### Models mlp_15_20_128 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.6640199999999999\n",
      "Pire Résultat sur la val :  0.4345\n",
      "Meilleur résultat sur le train :  0.93324\n",
      "Meilleur résultat sur la val :  0.4647\n",
      "Moyenne des résultats sur le train :  0.795196\n",
      "Moyenne des résultats sur la val :  0.4423\n",
      "Mediane des résultat sur le train :  0.79438\n",
      "Mediane des résultat sur la val :  0.4371\n",
      "\n",
      "########### Models mlp_15_20_256 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.5657399999999999\n",
      "Pire Résultat sur la val :  0.4489\n",
      "Meilleur résultat sur le train :  0.9973\n",
      "Meilleur résultat sur la val :  0.4586\n",
      "Moyenne des résultats sur le train :  0.903924\n",
      "Moyenne des résultats sur la val :  0.45408\n",
      "Mediane des résultat sur le train :  0.9907600000000001\n",
      "Mediane des résultat sur la val :  0.4541\n",
      "\n",
      "########### Models mlp_15_20_512 ###########\n",
      "(4, 22)\n",
      "Pire résultat sur le train :  0.93114\n",
      "Pire Résultat sur la val :  0.4319\n",
      "Meilleur résultat sur le train :  1.0\n",
      "Meilleur résultat sur la val :  0.473\n",
      "Moyenne des résultats sur le train :  0.979155\n",
      "Moyenne des résultats sur la val :  0.456875\n",
      "Mediane des résultat sur le train :  0.9927400000000001\n",
      "Mediane des résultat sur la val :  0.4613\n",
      "\n",
      "########### Models mlp_20_30_64 ###########\n",
      "(6, 22)\n",
      "Pire résultat sur le train :  0.58334\n",
      "Pire Résultat sur la val :  0.4446\n",
      "Meilleur résultat sur le train :  0.6379199999999999\n",
      "Meilleur résultat sur la val :  0.4609\n",
      "Moyenne des résultats sur le train :  0.61013\n",
      "Moyenne des résultats sur la val :  0.4513333333333333\n",
      "Mediane des résultat sur le train :  0.60942\n",
      "Mediane des résultat sur la val :  0.45075\n",
      "\n",
      "########### Models mlp_20_30_128 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.56072\n",
      "Pire Résultat sur la val :  0.4203\n",
      "Meilleur résultat sur le train :  0.9053\n",
      "Meilleur résultat sur la val :  0.4402\n",
      "Moyenne des résultats sur le train :  0.7967359999999999\n",
      "Moyenne des résultats sur la val :  0.43172\n",
      "Mediane des résultat sur le train :  0.83178\n",
      "Mediane des résultat sur la val :  0.43799999999999994\n",
      "\n",
      "########### Models mlp_20_30_256 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.33626\n",
      "Pire Résultat sur la val :  0.3321\n",
      "Meilleur résultat sur le train :  0.9858399999999999\n",
      "Meilleur résultat sur la val :  0.4631\n",
      "Moyenne des résultats sur le train :  0.800332\n",
      "Moyenne des résultats sur la val :  0.42166\n",
      "Mediane des résultat sur le train :  0.86408\n",
      "Mediane des résultat sur la val :  0.4347\n",
      "\n",
      "########### Models mlp_20_30_512 ###########\n",
      "(5, 22)\n",
      "Pire résultat sur le train :  0.24884\n",
      "Pire Résultat sur la val :  0.2473\n",
      "Meilleur résultat sur le train :  0.9965799999999999\n",
      "Meilleur résultat sur la val :  0.4556\n",
      "Moyenne des résultats sur le train :  0.65218\n",
      "Moyenne des résultats sur la val :  0.37442\n",
      "Mediane des résultat sur le train :  0.74456\n",
      "Mediane des résultat sur la val :  0.4328\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(filtered_results_dataframes)):\n",
    "    filtered_history = filtered_results_dataframes[i]\n",
    "    filtered_history_desc = results_dataframes_desc[i]\n",
    "    print_statistics(filtered_history, filtered_history_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On fusionne tous les dataframes en une seule (étant donné qu'il y en a une par structure de modèle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = concat_list_of_dataframes(filtered_results_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models mlp_without_regularisation ###########\n",
      "(79, 22)\n",
      "Pire résultat sur le train :  0.24884\n",
      "Pire Résultat sur la val :  0.2473\n",
      "Meilleur résultat sur le train :  1.0\n",
      "Meilleur résultat sur la val :  0.4902\n",
      "Moyenne des résultats sur le train :  0.6918189873417723\n",
      "Moyenne des résultats sur la val :  0.4486696202531646\n",
      "Mediane des résultat sur le train :  0.6338199999999999\n",
      "Mediane des résultat sur la val :  0.4556\n"
     ]
    }
   ],
   "source": [
    "print_statistics(merged_df, \"mlp_without_regularisation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Première analyse des résultats obtenus :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nous remarquons donc sur les 78 meilleurs modèles, nous tournons autours des 45% de résultat sur la validation, et 65% sur le train. De plus, nous avons atteint une limite de taille à lancer, étant donné que nos fits crashent pour manque de mémoire GPU quand on essaye de s'attaquer à des modèles d'environs 30 couches cachées. \n",
    "\n",
    "#### Ces résultats nous montrent que les meilleurs modèles overfittent. Nous allons donc essayer d'appliquer des techniques de régularisation dessus, en prenant les meilleurs sur ces 33 modèles selectionnés. Mais avant cela, nous allons essayer de réduire le nombre de modèles à tester on ne prenant que les plus intéressants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection des meilleurs modèles sur la val sur les 64 selectionnés:\n",
    "    Pour cela, nous n'allons prendre que les modèles dont les résultats sur l'entraînement sont supérieurs à la médiane des résultats de tous les modèles compris (toutes arachitectures confondues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models Best MLP models ###########\n",
      "(39, 22)\n",
      "Pire résultat sur le train :  0.49518\n",
      "Pire Résultat sur la val :  0.4557\n",
      "Meilleur résultat sur le train :  1.0\n",
      "Meilleur résultat sur la val :  0.4902\n",
      "Moyenne des résultats sur le train :  0.67856\n",
      "Moyenne des résultats sur la val :  0.466625641025641\n",
      "Mediane des résultat sur le train :  0.6226\n",
      "Mediane des résultat sur la val :  0.4661\n"
     ]
    }
   ],
   "source": [
    "best_val_models = filter_on_median_val_accuracy([merged_df])[0]\n",
    "best_val_models = best_val_models.sort_values('activation_couches', ascending=False)\n",
    "print_statistics(best_val_models, \"Best MLP models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On voit donc que nous avons 38 modèles qui pourrait être intéressants sur la validation, mais nous allons maintenant en selectionné, entre ceux là, les meilleurs sur le train. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection des meilleurs modèles sur le train sur les 32 restants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### Models Best MLP models ###########\n",
      "(15, 22)\n",
      "Pire résultat sur le train :  0.68012\n",
      "Pire Résultat sur la val :  0.4557\n",
      "Meilleur résultat sur le train :  1.0\n",
      "Meilleur résultat sur la val :  0.4735\n",
      "Moyenne des résultats sur le train :  0.842788\n",
      "Moyenne des résultats sur la val :  0.46584\n",
      "Mediane des résultat sur le train :  0.8357600000000001\n",
      "Mediane des résultat sur la val :  0.4669\n"
     ]
    }
   ],
   "source": [
    "best_models = filter_on_mean_train_accuracy([best_val_models])[0]\n",
    "best_models = best_models.sort_values('val_accuracy', ascending=False)\n",
    "print_statistics(best_models, \"Best MLP models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Nous avons donc 14 modèles interessants qui semblent intéressants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_couches</th>\n",
       "      <th>profondeurs_couches</th>\n",
       "      <th>activation_couches</th>\n",
       "      <th>activation_output</th>\n",
       "      <th>dropout</th>\n",
       "      <th>nb_dropout</th>\n",
       "      <th>indexes_dropout</th>\n",
       "      <th>valeur_dropout</th>\n",
       "      <th>l1l2_couches</th>\n",
       "      <th>l1l2_output</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_l1l2</th>\n",
       "      <th>indexes_l1l2</th>\n",
       "      <th>loss</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>metrics</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>dossier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>512 512 512 512 512 512 512 512 512 512 512</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>5762652</td>\n",
       "      <td>0.71452</td>\n",
       "      <td>0.4735</td>\n",
       "      <td>20200123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16</td>\n",
       "      <td>512 512 512 512 512 512 512 512 512 512 512 51...</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>4143798</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.4730</td>\n",
       "      <td>20200123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>256 256 256 256 256 256 256 256 256 256 256 25...</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>7574331</td>\n",
       "      <td>0.69438</td>\n",
       "      <td>0.4704</td>\n",
       "      <td>20200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>512 512 512 512 512 512 512 512 512 512 512 51...</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>2810928</td>\n",
       "      <td>0.98868</td>\n",
       "      <td>0.4694</td>\n",
       "      <td>20200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>256 256 256 256 256 256 256 256 256</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>9815569</td>\n",
       "      <td>0.70862</td>\n",
       "      <td>0.4683</td>\n",
       "      <td>20200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>128 128 128 128 128 128 128 128 128 128 128 12...</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>568701</td>\n",
       "      <td>0.68012</td>\n",
       "      <td>0.4682</td>\n",
       "      <td>20200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>512 512 512 512 512 512 512 512 512</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>1855666</td>\n",
       "      <td>0.68112</td>\n",
       "      <td>0.4676</td>\n",
       "      <td>20200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>512 512 512 512 512 512 512 512 512 512 512 51...</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>2811332</td>\n",
       "      <td>0.99686</td>\n",
       "      <td>0.4669</td>\n",
       "      <td>20200123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>256 256 256 256 256 256 256 256</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>6310408</td>\n",
       "      <td>0.77586</td>\n",
       "      <td>0.4668</td>\n",
       "      <td>20200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>512 512 512 512 512 512 512</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>4390588</td>\n",
       "      <td>0.98032</td>\n",
       "      <td>0.4657</td>\n",
       "      <td>20200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>128 128 128 128 128 128 128 128 128 128 128 12...</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>8063621</td>\n",
       "      <td>0.72574</td>\n",
       "      <td>0.4647</td>\n",
       "      <td>20200123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>256 256 256 256 256 256 256 256 256 256 256 25...</td>\n",
       "      <td>selu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>8027726</td>\n",
       "      <td>0.83576</td>\n",
       "      <td>0.4631</td>\n",
       "      <td>20200123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>512 512 512 512 512</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>3082596</td>\n",
       "      <td>0.87446</td>\n",
       "      <td>0.4582</td>\n",
       "      <td>20200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>256 256 256 256 256 256 256 256 256 256 256 25...</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>1678598</td>\n",
       "      <td>0.99676</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>20200123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>512 512 512 512 512 512 512 512 512 512 512 51...</td>\n",
       "      <td>softplus</td>\n",
       "      <td>softmax</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>sparse_categorical_accuracy</td>\n",
       "      <td>400</td>\n",
       "      <td>383142</td>\n",
       "      <td>0.98862</td>\n",
       "      <td>0.4557</td>\n",
       "      <td>20200123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_couches                                profondeurs_couches  \\\n",
       "6          11        512 512 512 512 512 512 512 512 512 512 512   \n",
       "7          16  512 512 512 512 512 512 512 512 512 512 512 51...   \n",
       "0          14  256 256 256 256 256 256 256 256 256 256 256 25...   \n",
       "2          14  512 512 512 512 512 512 512 512 512 512 512 51...   \n",
       "5           9                256 256 256 256 256 256 256 256 256   \n",
       "7          15  128 128 128 128 128 128 128 128 128 128 128 12...   \n",
       "8           9                512 512 512 512 512 512 512 512 512   \n",
       "4          18  512 512 512 512 512 512 512 512 512 512 512 51...   \n",
       "4           8                    256 256 256 256 256 256 256 256   \n",
       "9           7                        512 512 512 512 512 512 512   \n",
       "2          16  128 128 128 128 128 128 128 128 128 128 128 12...   \n",
       "3          23  256 256 256 256 256 256 256 256 256 256 256 25...   \n",
       "2           5                                512 512 512 512 512   \n",
       "5          17  256 256 256 256 256 256 256 256 256 256 256 25...   \n",
       "8          15  512 512 512 512 512 512 512 512 512 512 512 51...   \n",
       "\n",
       "  activation_couches activation_output  dropout  nb_dropout  indexes_dropout  \\\n",
       "6           softplus           softmax    False           0              NaN   \n",
       "7           softplus           softmax    False           0              NaN   \n",
       "0               selu           softmax    False           0              NaN   \n",
       "2               relu           softmax    False           0              NaN   \n",
       "5               selu           softmax    False           0              NaN   \n",
       "7               selu           softmax    False           0              NaN   \n",
       "8               relu           softmax    False           0              NaN   \n",
       "4               relu           softmax    False           0              NaN   \n",
       "4               relu           softmax    False           0              NaN   \n",
       "9               relu           softmax    False           0              NaN   \n",
       "2               selu           softmax    False           0              NaN   \n",
       "3               selu           softmax    False           0              NaN   \n",
       "2               relu           softmax    False           0              NaN   \n",
       "5           softplus           softmax    False           0              NaN   \n",
       "8           softplus           softmax    False           0              NaN   \n",
       "\n",
       "   valeur_dropout  l1l2_couches  l1l2_output  ...  nb_l1l2  indexes_l1l2  \\\n",
       "6             0.0         False        False  ...        0           NaN   \n",
       "7             0.0         False        False  ...        0           NaN   \n",
       "0             0.0         False        False  ...        0           NaN   \n",
       "2             0.0         False        False  ...        0           NaN   \n",
       "5             0.0         False        False  ...        0           NaN   \n",
       "7             0.0         False        False  ...        0           NaN   \n",
       "8             0.0         False        False  ...        0           NaN   \n",
       "4             0.0         False        False  ...        0           NaN   \n",
       "4             0.0         False        False  ...        0           NaN   \n",
       "9             0.0         False        False  ...        0           NaN   \n",
       "2             0.0         False        False  ...        0           NaN   \n",
       "3             0.0         False        False  ...        0           NaN   \n",
       "2             0.0         False        False  ...        0           NaN   \n",
       "5             0.0         False        False  ...        0           NaN   \n",
       "8             0.0         False        False  ...        0           NaN   \n",
       "\n",
       "                              loss  optimizer                      metrics  \\\n",
       "6  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "7  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "0  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "2  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "5  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "7  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "8  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "4  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "4  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "9  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "2  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "3  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "2  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "5  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "8  sparse_categorical_crossentropy       Adam  sparse_categorical_accuracy   \n",
       "\n",
       "  epochs model_id  train_accuracy  val_accuracy   dossier  \n",
       "6    400  5762652         0.71452        0.4735  20200123  \n",
       "7    400  4143798         1.00000        0.4730  20200123  \n",
       "0    400  7574331         0.69438        0.4704  20200122  \n",
       "2    400  2810928         0.98868        0.4694  20200122  \n",
       "5    400  9815569         0.70862        0.4683  20200122  \n",
       "7    400   568701         0.68012        0.4682  20200122  \n",
       "8    400  1855666         0.68112        0.4676  20200122  \n",
       "4    400  2811332         0.99686        0.4669  20200123  \n",
       "4    400  6310408         0.77586        0.4668  20200122  \n",
       "9    400  4390588         0.98032        0.4657  20200122  \n",
       "2    400  8063621         0.72574        0.4647  20200123  \n",
       "3    400  8027726         0.83576        0.4631  20200123  \n",
       "2    400  3082596         0.87446        0.4582  20200122  \n",
       "5    400  1678598         0.99676        0.4561  20200123  \n",
       "8    400   383142         0.98862        0.4557  20200123  \n",
       "\n",
       "[15 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models.to_csv(\"{}best_mlp_without_regularisation.csv\".format(root_csv_folder), sep=';',header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions premiers tests:\n",
    "\n",
    "##### Avec cette première vague de tests, nous avons vu que des MLP, mêmes assez gros (du moins, les plus gros qu'on a pu lancer (Maximum 25 à 30 couches à 512 neurones par couches)) ne donnent pas de résultats intéressant sur la validation (un maximum de 48%).\n",
    "\n",
    "##### Cependant, on a aussi remarqué que tous ces modèles on tendance à overfitter. Du coup on va essayer d'appliquer des techniques de régulatisation pour voir si on peu tirer de meilleurs résultats avec les meilleurs modèles qu'on a réussi à avoir.\n",
    "\n",
    "##### Nous avons selectionnés deux modèles pour poursuivre les tests : le meilleur modèle qu'on a obtenu (11 couches à 512 neuronnes par couche avec une softplus pour l'activation des couches cachées et une softmax pour l'output) et un modèle qui overfitte beaucoup  (5 couches à 512 neurones par couche, avec la relu pour les couches cachées et la softmax pour l'output). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests MLP avec techniques de régularisations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle à 5 couches:\n",
    "###### Résultats sans régularisation : 0.46 en validation et 0.87 en train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec Régularisation L2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L2 à 0.0005 : 0.45 sur la validation et 0.9 sur le train => même résultat que sans régularisation\n",
    "- L2 à 0.01: 0.5 sur la validation et 0.75 sur le train (qui était à 0.87 sans régularisation) mais on a toujour un overfitting => Un peu mieux, mais on peu essaye de régulariser encore plus\n",
    "- L2 à 0.2: 0.31 sur la validation et le train => on a trop pénalisé les poids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec Régularisation L1 + L2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L2 à 0.01 et L1 à 0.01: 0.31 sur la validation et le train => on a trop pénalisé les poids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle à 11 couches:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Résultats sans régularisation : 0.4735 en validation et 0.71 en train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec Régularisation L2 sur les couches cachées:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L2 à 0.01: 0.37 en validation et 0.38 en train => Trop pénalisé\n",
    "- L2 à 0.001: 0.58 sur le train, et sur la validation monte jusqu'à 0.53 sur certaine epochs. par contre, tout le long du train, l'accuracy s'effondre à plusieurs reprises pour ensuite remonter (comme le montre le logs du fit). On retrouvera ce comportement sur plusieurs autres entrau=inement du même modèle avec d'autres hyperparamètres(comme avecla l2 à 0.0005). On n'arrive pas à expliquer cela.\n",
    "- L2 à 0.0005: Monte jusqu'à 0.54 en validation sur certaines epochs et à 0.95 sur le train. => Overfit, nous avons donc essayé d'ajouter une L1 à ce même modèle.\n",
    "- L2 à 0.002: Validation à 0.53 et 0.6 sur le train, Accuracy retombe de temps en temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 4396."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \".\\\\logs\\\\mlp_best_models_with_l2\\\\20200124\\\\mlp_best_models_with_l2_2848849.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec Régularisation L2 et L1 sur les couches cachées:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- l2 à 0.0005 et L1 à 0.0001: 0.5 en validation et 0.54 ssur le train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec Régularisation L2 sur les couches cachées et output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L2 à 0.001: 0.5 sur la validation et 0.55 sur le train\n",
    "- L2 à 0.0005: 0.5 sur la validation et 0.55 sur le train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec Régularisation L2 sur les couches cachées et Dropout:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L2 à 0.001 et dropout à 0.1: 0.43 sur la validation et 0.47 sur le train\n",
    "- L2 à 0.001 et dropout à 0.2: 0.29 sur la validation et le train\n",
    "- L2 à 0.001 et dropout à 0.3: 0.27 sur la validation et le train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec Régularisation Dropout sur les inputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dropout à 0.2: 0.89 sur le train et 0.45 sur la val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion MLP:\n",
    "\n",
    "### Résumé de résultats obtenus:\n",
    "\n",
    "##### Même en utilisations différents hyperparamètres et techniques de régularisation, avec de simples MLP, nous avons vu que l'accuracy maximale que nous avons pu atteindre sur la validation se situe autours des 54%. Etant donné que nous avons atteint nos limites en matière de ressources matérielles, nous allons essayer d'utiliser d'autres types de modèles sur le dataset pour voir ce que cela va donner. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
